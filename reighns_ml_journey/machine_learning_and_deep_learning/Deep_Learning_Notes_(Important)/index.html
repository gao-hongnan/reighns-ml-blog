
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://gao-hongnan.github.io/reighns-ml-blog/reighns_ml_journey/machine_learning_and_deep_learning/Deep_Learning_Notes_%28Important%29/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.0, mkdocs-material-8.2.13">
    
    
      
        <title>Deep Learning Notes (Important) - Hongnan G. Machine Learning Blog</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.e411adfe.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.cc9b2e1e.min.css">
        
      
    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../css/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="" data-md-color-primary="none" data-md-color-accent="none">
  
    
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#config" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../.." title="Hongnan G. Machine Learning Blog" class="md-header__button md-logo" aria-label="Hongnan G. Machine Learning Blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Hongnan G. Machine Learning Blog
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Deep Learning Notes (Important)
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/gao-hongnan" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M400 32H48C21.5 32 0 53.5 0 80v352c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V80c0-26.5-21.5-48-48-48zM277.3 415.7c-8.4 1.5-11.5-3.7-11.5-8 0-5.4.2-33 .2-55.3 0-15.6-5.2-25.5-11.3-30.7 37-4.1 76-9.2 76-73.1 0-18.2-6.5-27.3-17.1-39 1.7-4.3 7.4-22-1.7-45-13.9-4.3-45.7 17.9-45.7 17.9-13.2-3.7-27.5-5.6-41.6-5.6-14.1 0-28.4 1.9-41.6 5.6 0 0-31.8-22.2-45.7-17.9-9.1 22.9-3.5 40.6-1.7 45-10.6 11.7-15.6 20.8-15.6 39 0 63.6 37.3 69 74.3 73.1-4.8 4.3-9.1 11.7-10.6 22.3-9.5 4.3-33.8 11.7-48.3-13.9-9.1-15.8-25.5-17.1-25.5-17.1-16.2-.2-1.1 10.2-1.1 10.2 10.8 5 18.4 24.2 18.4 24.2 9.7 29.7 56.1 19.7 56.1 19.7 0 13.9.2 36.5.2 40.6 0 4.3-3 9.5-11.5 8-66-22.1-112.2-84.9-112.2-158.3 0-91.8 70.2-161.5 162-161.5S388 165.6 388 257.4c.1 73.4-44.7 136.3-110.7 158.3zm-98.1-61.1c-1.9.4-3.7-.4-3.9-1.7-.2-1.5 1.1-2.8 3-3.2 1.9-.2 3.7.6 3.9 1.9.3 1.3-1 2.6-3 3zm-9.5-.9c0 1.3-1.5 2.4-3.5 2.4-2.2.2-3.7-.9-3.7-2.4 0-1.3 1.5-2.4 3.5-2.4 1.9-.2 3.7.9 3.7 2.4zm-13.7-1.1c-.4 1.3-2.4 1.9-4.1 1.3-1.9-.4-3.2-1.9-2.8-3.2.4-1.3 2.4-1.9 4.1-1.5 2 .6 3.3 2.1 2.8 3.4zm-12.3-5.4c-.9 1.1-2.8.9-4.3-.6-1.5-1.3-1.9-3.2-.9-4.1.9-1.1 2.8-.9 4.3.6 1.3 1.3 1.8 3.3.9 4.1zm-9.1-9.1c-.9.6-2.6 0-3.7-1.5s-1.1-3.2 0-3.9c1.1-.9 2.8-.2 3.7 1.3 1.1 1.5 1.1 3.3 0 4.1zm-6.5-9.7c-.9.9-2.4.4-3.5-.6-1.1-1.3-1.3-2.8-.4-3.5.9-.9 2.4-.4 3.5.6 1.1 1.3 1.3 2.8.4 3.5zm-6.7-7.4c-.4.9-1.7 1.1-2.8.4-1.3-.6-1.9-1.7-1.5-2.6.4-.6 1.5-.9 2.8-.4 1.3.7 1.9 1.8 1.5 2.6z"/></svg>
  </div>
  <div class="md-source__repository">
    gao-hongnan
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="Hongnan G. Machine Learning Blog" class="md-nav__button md-logo" aria-label="Hongnan G. Machine Learning Blog" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    Hongnan G. Machine Learning Blog
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/gao-hongnan" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M400 32H48C21.5 32 0 53.5 0 80v352c0 26.5 21.5 48 48 48h352c26.5 0 48-21.5 48-48V80c0-26.5-21.5-48-48-48zM277.3 415.7c-8.4 1.5-11.5-3.7-11.5-8 0-5.4.2-33 .2-55.3 0-15.6-5.2-25.5-11.3-30.7 37-4.1 76-9.2 76-73.1 0-18.2-6.5-27.3-17.1-39 1.7-4.3 7.4-22-1.7-45-13.9-4.3-45.7 17.9-45.7 17.9-13.2-3.7-27.5-5.6-41.6-5.6-14.1 0-28.4 1.9-41.6 5.6 0 0-31.8-22.2-45.7-17.9-9.1 22.9-3.5 40.6-1.7 45-10.6 11.7-15.6 20.8-15.6 39 0 63.6 37.3 69 74.3 73.1-4.8 4.3-9.1 11.7-10.6 22.3-9.5 4.3-33.8 11.7-48.3-13.9-9.1-15.8-25.5-17.1-25.5-17.1-16.2-.2-1.1 10.2-1.1 10.2 10.8 5 18.4 24.2 18.4 24.2 9.7 29.7 56.1 19.7 56.1 19.7 0 13.9.2 36.5.2 40.6 0 4.3-3 9.5-11.5 8-66-22.1-112.2-84.9-112.2-158.3 0-91.8 70.2-161.5 162-161.5S388 165.6 388 257.4c.1 73.4-44.7 136.3-110.7 158.3zm-98.1-61.1c-1.9.4-3.7-.4-3.9-1.7-.2-1.5 1.1-2.8 3-3.2 1.9-.2 3.7.6 3.9 1.9.3 1.3-1 2.6-3 3zm-9.5-.9c0 1.3-1.5 2.4-3.5 2.4-2.2.2-3.7-.9-3.7-2.4 0-1.3 1.5-2.4 3.5-2.4 1.9-.2 3.7.9 3.7 2.4zm-13.7-1.1c-.4 1.3-2.4 1.9-4.1 1.3-1.9-.4-3.2-1.9-2.8-3.2.4-1.3 2.4-1.9 4.1-1.5 2 .6 3.3 2.1 2.8 3.4zm-12.3-5.4c-.9 1.1-2.8.9-4.3-.6-1.5-1.3-1.9-3.2-.9-4.1.9-1.1 2.8-.9 4.3.6 1.3 1.3 1.8 3.3.9 4.1zm-9.1-9.1c-.9.6-2.6 0-3.7-1.5s-1.1-3.2 0-3.9c1.1-.9 2.8-.2 3.7 1.3 1.1 1.5 1.1 3.3 0 4.1zm-6.5-9.7c-.9.9-2.4.4-3.5-.6-1.1-1.3-1.3-2.8-.4-3.5.9-.9 2.4-.4 3.5.6 1.1 1.3 1.3 2.8.4 3.5zm-6.7-7.4c-.4.9-1.7 1.1-2.8.4-1.3-.6-1.9-1.7-1.5-2.6.4-.6 1.5-.9 2.8-.4 1.3.7 1.9 1.8 1.5 2.6z"/></svg>
  </div>
  <div class="md-source__repository">
    gao-hongnan
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../about/" class="md-nav__link">
        About
      </a>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../sp_ppe/" class="md-nav__link">
        SP PPE
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          Mathematics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Mathematics" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          Mathematics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/general_mathematical_terms_and_definitions.md" class="md-nav__link">
        General Mathematic Terms and Definitions
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2" type="checkbox" id="__nav_4_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2">
          Linear Algebra
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Linear Algebra" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_2">
          <span class="md-nav__icon md-icon"></span>
          Linear Algebra
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_1" type="checkbox" id="__nav_4_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_1">
          Vectors
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Vectors" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_1">
          <span class="md-nav__icon md-icon"></span>
          Vectors
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_1_1" type="checkbox" id="__nav_4_2_1_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_1_1">
          Vector Products
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Vector Products" data-md-level="4">
        <label class="md-nav__title" for="__nav_4_2_1_1">
          <span class="md-nav__icon md-icon"></span>
          Vector Products
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_outer_product.md" class="md-nav__link">
        Outer Product
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_unit_vector/" class="md-nav__link">
        Unit Vector
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/02_vectors/02_linear_algebra_vectors_exercises/" class="md-nav__link">
        Exercises
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_2" type="checkbox" id="__nav_4_2_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_2">
          Vector Spaces
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Vector Spaces" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_2">
          <span class="md-nav__icon md-icon"></span>
          Vector Spaces
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_subspaces/" class="md-nav__link">
        Vector Space and Subspaces
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_vector_span/" class="md-nav__link">
        Vector Span
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_linear_independence/" class="md-nav__link">
        Linear Independence
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/03_vector_spaces/03_linear_algebra_vector_spaces_basis_dimension/" class="md-nav__link">
        Basis and Dimension
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_3" type="checkbox" id="__nav_4_2_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_3">
          Matrix
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Matrix" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_3">
          <span class="md-nav__icon md-icon"></span>
          Matrix
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix/" class="md-nav__link">
        Matrix
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_matrix_types/" class="md-nav__link">
        Basic Matrix Types
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_basic_operations/" class="md-nav__link">
        Basic Matrix Operations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/04_matrices/04_linear_algebra_matrix_multiplication/" class="md-nav__link">
        Matrix Multiplication
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_4" type="checkbox" id="__nav_4_2_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_4">
          Matrix Theory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Matrix Theory" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_4">
          <span class="md-nav__icon md-icon"></span>
          Matrix Theory
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.01_linear_algebra_systems_of_linear_equations.md" class="md-nav__link">
        System of Linear Equations
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.02_linear_algebra_row_reduction_preserves_rank/" class="md-nav__link">
        Row Reduction Preserves Rank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.03_linear_algebra_matrix_theory_matrix_spaces_row_space/" class="md-nav__link">
        Row Space
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.04_linear_algebra_matrix_theory_matrix_spaces_column_space/" class="md-nav__link">
        Column Space
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.05_linear_algebra_matrix_theory_matrix_spaces_right_nullspace/" class="md-nav__link">
        Right Nullspace (Kernel)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.06_linear_algebra_matrix_theory_matrix_spaces_left_nullspace/" class="md-nav__link">
        Left Nullspace
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.07_linear_algebra_matrix_theory_matrix_rank/" class="md-nav__link">
        Matrix Rank
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/05_system_of_linear_equations_and_matrix_theory/05.08_linear_algebra_matrix_theory_matrix_spaces_summary/" class="md-nav__link">
        The Four Fundamental Subspaces (Summary)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_5" type="checkbox" id="__nav_4_2_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_5">
          Linear Transformation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Linear Transformation" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_5">
          <span class="md-nav__icon md-icon"></span>
          Linear Transformation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/06_linear_transformation/06.01_linear_algebra_linear_transformations/" class="md-nav__link">
        Linear Transformation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/06_linear_transformation/06.02_linear_algebra_linear_transformations_nullspace/" class="md-nav__link">
        Nullspace
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/06_linear_transformation/06.03_linear_algebra_linear_transformations_ranges/" class="md-nav__link">
        Range
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/06_linear_transformation/06.04_linear_algebra_linear_transformations_homomorphism/" class="md-nav__link">
        Homomorphism
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/06_linear_transformation/06.05_linear_algebra_linear_transformations_fundamental_theorem/" class="md-nav__link">
        Fundamental Theorem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/06_linear_transformation/06.06_linear_algebra_linear_transformations_matrix/" class="md-nav__link">
        Linear Transformation and Matrix
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_2_6" type="checkbox" id="__nav_4_2_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_2_6">
          Analytic Geometry
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Analytic Geometry" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_2_6">
          <span class="md-nav__icon md-icon"></span>
          Analytic Geometry
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.01_motivation/" class="md-nav__link">
        Motivation
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.02_norms/" class="md-nav__link">
        Norms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.03_inner_products/" class="md-nav__link">
        Inner Product Spaces
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.04_lengths_and_distances/" class="md-nav__link">
        Lengths and Distances
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.05_angles_and_orthogonality/" class="md-nav__link">
        Angles and Orthogoanlity
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.06_orthogonal_subspaces/" class="md-nav__link">
        Orthogonal Subspace
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.07_orthogonal_projections/" class="md-nav__link">
        Orthogonal Projection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.08_orthogonal_matrices_and_basis/" class="md-nav__link">
        Orthogonal Matrices and Basis
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/08_analytic_geometry/08.09_gram_schmidt_orthogonalization/" class="md-nav__link">
        Gram-Schmidt Orthogonalization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/linear_algebra/linear_algebra_interview_questions/" class="md-nav__link">
        Interview
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3" type="checkbox" id="__nav_4_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3">
          Probability and Statistics
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Probability and Statistics" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_3">
          <span class="md-nav__icon md-icon"></span>
          Probability and Statistics
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/probability_statistics_theory/probability4datascience.md" class="md-nav__link">
        Introduction to Probability for Data Science (Stanley H. Chan)
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_4_3_2" type="checkbox" id="__nav_4_3_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_4_3_2">
          Introduction to Probability
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Introduction to Probability" data-md-level="3">
        <label class="md-nav__title" for="__nav_4_3_2">
          <span class="md-nav__icon md-icon"></span>
          Introduction to Probability
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.01_probability_space.md" class="md-nav__link">
        Probability Space
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.02_probability_axioms.md" class="md-nav__link">
        Probability Axioms
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.03_conditional_probability.md" class="md-nav__link">
        Conditional Probability
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.04_independence.md" class="md-nav__link">
        Independence
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.05_bayes_theorem.md" class="md-nav__link">
        Bayes Theorem
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../mathematics/probability_statistics_theory/02_introduction_to_probability/02.06_summary.md" class="md-nav__link">
        Summary
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Machine Learning and Deep Learning
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Machine Learning and Deep Learning" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning and Deep Learning
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_1" type="checkbox" id="__nav_5_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_1">
          Computer Vision
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Computer Vision" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          Computer Vision
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../computer_vision/" class="md-nav__link">
        README
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_1_2" type="checkbox" id="__nav_5_1_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_1_2">
          Neural Network Interpretation
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Neural Network Interpretation" data-md-level="3">
        <label class="md-nav__title" for="__nav_5_1_2">
          <span class="md-nav__icon md-icon"></span>
          Neural Network Interpretation
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_1_2_1" type="checkbox" id="__nav_5_1_2_1" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_1_2_1">
          Visualization of Feature Map Activations
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Visualization of Feature Map Activations" data-md-level="4">
        <label class="md-nav__title" for="__nav_5_1_2_1">
          <span class="md-nav__icon md-icon"></span>
          Visualization of Feature Map Activations
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation/" class="md-nav__link">
        Feature Map Activations (Part I)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../computer_vision/neural_network_interpretation/01_feature_map_activation/feature_map_activation_reduced/" class="md-nav__link">
        Feature Map Activations (Part II)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../computer_vision/neural_network_interpretation/conv_filters/Visualizing Convolutional Filters.md" class="md-nav__link">
        Visualization of Convolutional Filters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../computer_vision/neural_network_interpretation/salient_map/Salient Map.md" class="md-nav__link">
        Salient Map
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_1_2_4" type="checkbox" id="__nav_5_1_2_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_1_2_4">
          Grad-CAM
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Grad-CAM" data-md-level="4">
        <label class="md-nav__title" for="__nav_5_1_2_4">
          <span class="md-nav__icon md-icon"></span>
          Grad-CAM
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_explained/" class="md-nav__link">
        Grad-CAM Explained
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../computer_vision/neural_network_interpretation/05_gradcam_and_variants/gradcam_from_scratch/" class="md-nav__link">
        Grad-CAM from Scratch
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../computer_vision/image_normalization/Image_Normalization_and_Standardization/" class="md-nav__link">
        Image Normalization
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_2" type="checkbox" id="__nav_5_2" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_2">
          Fundamental Concepts
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Fundamental Concepts" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          Fundamental Concepts
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../fundamentals/loss_functions/cross_entropy_loss/cross_entropy_loss_from_scratch.md" class="md-nav__link">
        Cross Entropy Loss
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_5_3" type="checkbox" id="__nav_5_3" >
      
      
      
      
        <label class="md-nav__link" for="__nav_5_3">
          Ensemble Theory
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Ensemble Theory" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          Ensemble Theory
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../ensemble_theory/forward_ensemble/" class="md-nav__link">
        Forward Ensemble (Hill Climbing)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          Machine Learning Projects
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Machine Learning Projects" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          Machine Learning Projects
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/RANZCR%20CLiP%20-%20Catheter%20and%20Line%20Position%20Challenge/notebooks/walkthrough/" class="md-nav__link">
        RANZCR CLiP - Catheter and Line Position Challenge
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/SIIM-ISIC%20Melanoma%20Classification/notebooks/walkthrough/" class="md-nav__link">
        SIIM-ISIC Melanoma Classification
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/LTA_road_cracks_detection/notebooks/walkthrough/" class="md-nav__link">
        LTA
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6_4" type="checkbox" id="__nav_6_4" >
      
      
      
      
        <label class="md-nav__link" for="__nav_6_4">
          Breast Cancer Wisconsin (Supervised Classification)
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Breast Cancer Wisconsin (Supervised Classification)" data-md-level="2">
        <label class="md-nav__title" for="__nav_6_4">
          <span class="md-nav__icon md-icon"></span>
          Breast Cancer Wisconsin (Supervised Classification)
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%200%20-%20Introduction%20and%20Problem%20Statement/" class="md-nav__link">
        Introduction
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%201%20-%20Preliminary%20Data%20Inspection%20and%20Cleaning/" class="md-nav__link">
        Preliminary Data Inspection and Cleaning
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%202%20-%20Preliminary%20EDA/" class="md-nav__link">
        EDA
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%203%20-%20Feature%20Engineering/" class="md-nav__link">
        Feature Engineering
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%204%20-%20Modelling%20%28Metric%20to%20Optimize%29/" class="md-nav__link">
        Modelling (Metrics)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%205%20-%20Modelling%20%28Cross-Validation%20Methodology%29/" class="md-nav__link">
        Modelling (Cross-Validation Schema)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%206%20-%20Modelling%20%28Preprocessing%20and%20Spot%20Checking%29/" class="md-nav__link">
        Modelling (Preprocessing and Spot Checking)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%207%20-%20Modelling%20%28Model%20Selection%20and%20Hyperparameter%20Tuning%29/" class="md-nav__link">
        Modelling (Model Selection)
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../projects/breast_cancer_wisconsin/Stage%208%20-%20Modelling%20%28Model%20Evaluation%20and%20Interpretation%29/" class="md-nav__link">
        Modelling (Model Evaluation)
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content" data-md-component="content">
            <article class="md-content__inner md-typeset">
              
                
  <a href="https://github.com/gao-hongnan/edit/master/docs/reighns_ml_journey/machine_learning_and_deep_learning/Deep_Learning_Notes_(Important).md" title="Edit this page" class="md-content__button md-icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>



<p>16th January 2021: Shifted my notebooks onto GitHub for easier integration, in particular to track changes.</p>
<p>References: </p>
<p><a href="https://stackoverflow.com/questions/59454990/how-to-push-from-colab-to-github">Reference 1</a></p>
<p><a href="https://lalorosas.com/blog/github-colab-drive">Reference 2</a></p>
<p><a href="https://sam-thurman.medium.com/integrating-google-drive-colab-with-github-bffaca97eb5b">Reference 3</a></p>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">google.colab</span> <span class="kn">import</span> <span class="n">drive</span>
<span class="n">drive</span><span class="o">.</span><span class="n">mount</span><span class="p">(</span><span class="s1">&#39;/content/drive/&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Mounted at /content/drive/
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">unzip</span> <span class="s1">&#39;/content/drive/My Drive/Cassava/zip-folder/Cassava-JPEG-128x128.zip&#39;</span> <span class="o">-</span><span class="n">d</span> <span class="s1">&#39;/content/&#39;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[1;30;43mStreaming output truncated to the last 5000 lines.[0m
  inflating: /content/kaggle/train_images_jpeg/3952546193.jpg  
  inflating: /content/kaggle/train_images_jpeg/3952799769.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953140534.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953222407.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953247024.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953327881.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953331047.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953514366.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953530273.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953560426.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953648207.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953857113.jpg  
  inflating: /content/kaggle/train_images_jpeg/3953901317.jpg  
  inflating: /content/kaggle/train_images_jpeg/3954180556.jpg  
  inflating: /content/kaggle/train_images_jpeg/3954239221.jpg  
  inflating: /content/kaggle/train_images_jpeg/3954387963.jpg  
  inflating: /content/kaggle/train_images_jpeg/3954399974.jpg  
  inflating: /content/kaggle/train_images_jpeg/3954487465.jpg  
  inflating: /content/kaggle/train_images_jpeg/3954910918.jpg  
  inflating: /content/kaggle/train_images_jpeg/3955391972.jpg  
  inflating: /content/kaggle/train_images_jpeg/3955442838.jpg  
  inflating: /content/kaggle/train_images_jpeg/3955739563.jpg  
  inflating: /content/kaggle/train_images_jpeg/3955931830.jpg  
  inflating: /content/kaggle/train_images_jpeg/3955972139.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956075690.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956077728.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956155774.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956271103.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956372146.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956407201.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956550570.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956605397.jpg  
  inflating: /content/kaggle/train_images_jpeg/3956778160.jpg  
  inflating: /content/kaggle/train_images_jpeg/3957562076.jpg  
  inflating: /content/kaggle/train_images_jpeg/3957612771.jpg  
  inflating: /content/kaggle/train_images_jpeg/3957807023.jpg  
  inflating: /content/kaggle/train_images_jpeg/3957819631.jpg  
  inflating: /content/kaggle/train_images_jpeg/395820132.jpg  
  inflating: /content/kaggle/train_images_jpeg/3958304403.jpg  
  inflating: /content/kaggle/train_images_jpeg/395852128.jpg  
  inflating: /content/kaggle/train_images_jpeg/395853907.jpg  
  inflating: /content/kaggle/train_images_jpeg/3958714206.jpg  
  inflating: /content/kaggle/train_images_jpeg/3958986545.jpg  
  inflating: /content/kaggle/train_images_jpeg/3959033347.jpg  
  inflating: /content/kaggle/train_images_jpeg/3959151804.jpg  
  inflating: /content/kaggle/train_images_jpeg/3959266436.jpg  
  inflating: /content/kaggle/train_images_jpeg/3959470813.jpg  
  inflating: /content/kaggle/train_images_jpeg/3959970856.jpg  
  inflating: /content/kaggle/train_images_jpeg/3960301906.jpg  
  inflating: /content/kaggle/train_images_jpeg/396042395.jpg  
  inflating: /content/kaggle/train_images_jpeg/396060343.jpg  
  inflating: /content/kaggle/train_images_jpeg/3960669389.jpg  
  inflating: /content/kaggle/train_images_jpeg/3960791119.jpg  
  inflating: /content/kaggle/train_images_jpeg/3961078700.jpg  
  inflating: /content/kaggle/train_images_jpeg/3961117682.jpg  
  inflating: /content/kaggle/train_images_jpeg/3961136833.jpg  
  inflating: /content/kaggle/train_images_jpeg/396152951.jpg  
  inflating: /content/kaggle/train_images_jpeg/3961645455.jpg  
  inflating: /content/kaggle/train_images_jpeg/3962057162.jpg  
  inflating: /content/kaggle/train_images_jpeg/3962294427.jpg  
  inflating: /content/kaggle/train_images_jpeg/3962424026.jpg  
  inflating: /content/kaggle/train_images_jpeg/3962684748.jpg  
  inflating: /content/kaggle/train_images_jpeg/3962830486.jpg  
  inflating: /content/kaggle/train_images_jpeg/3962941156.jpg  
  inflating: /content/kaggle/train_images_jpeg/3962965208.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963041758.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963163426.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963194620.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963293417.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963421928.jpg  
  inflating: /content/kaggle/train_images_jpeg/396350327.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963572251.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963604072.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963914024.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963917355.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963919295.jpg  
  inflating: /content/kaggle/train_images_jpeg/3963996017.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964029612.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964066128.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964069198.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964074425.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964080612.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964124529.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964194408.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964240864.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964316261.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964372330.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964576371.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964588616.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964816822.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964842875.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964876844.jpg  
  inflating: /content/kaggle/train_images_jpeg/3964970132.jpg  
  inflating: /content/kaggle/train_images_jpeg/396499078.jpg  
  inflating: /content/kaggle/train_images_jpeg/3965026649.jpg  
  inflating: /content/kaggle/train_images_jpeg/3965161877.jpg  
  inflating: /content/kaggle/train_images_jpeg/3965169748.jpg  
  inflating: /content/kaggle/train_images_jpeg/396528848.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966039850.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966169079.jpg  
  inflating: /content/kaggle/train_images_jpeg/396625328.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966256467.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966311153.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966397461.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966432707.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966618744.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966914560.jpg  
  inflating: /content/kaggle/train_images_jpeg/3966975834.jpg  
  inflating: /content/kaggle/train_images_jpeg/3967002927.jpg  
  inflating: /content/kaggle/train_images_jpeg/3967037274.jpg  
  inflating: /content/kaggle/train_images_jpeg/3967050100.jpg  
  inflating: /content/kaggle/train_images_jpeg/3967891639.jpg  
  inflating: /content/kaggle/train_images_jpeg/3968048683.jpg  
  inflating: /content/kaggle/train_images_jpeg/3968083899.jpg  
  inflating: /content/kaggle/train_images_jpeg/396829878.jpg  
  inflating: /content/kaggle/train_images_jpeg/3968384941.jpg  
  inflating: /content/kaggle/train_images_jpeg/3968735847.jpg  
  inflating: /content/kaggle/train_images_jpeg/3968955392.jpg  
  inflating: /content/kaggle/train_images_jpeg/3968956447.jpg  
  inflating: /content/kaggle/train_images_jpeg/3969087697.jpg  
  inflating: /content/kaggle/train_images_jpeg/3969288877.jpg  
  inflating: /content/kaggle/train_images_jpeg/3969515.jpg  
  inflating: /content/kaggle/train_images_jpeg/3969588604.jpg  
  inflating: /content/kaggle/train_images_jpeg/3969787615.jpg  
  inflating: /content/kaggle/train_images_jpeg/3969928849.jpg  
  inflating: /content/kaggle/train_images_jpeg/3970119375.jpg  
  inflating: /content/kaggle/train_images_jpeg/397081522.jpg  
  inflating: /content/kaggle/train_images_jpeg/3971043257.jpg  
  inflating: /content/kaggle/train_images_jpeg/3971124978.jpg  
  inflating: /content/kaggle/train_images_jpeg/3971240417.jpg  
  inflating: /content/kaggle/train_images_jpeg/3971401456.jpg  
  inflating: /content/kaggle/train_images_jpeg/3971597689.jpg  
  inflating: /content/kaggle/train_images_jpeg/3971663926.jpg  
  inflating: /content/kaggle/train_images_jpeg/3971676147.jpg  
  inflating: /content/kaggle/train_images_jpeg/3972035105.jpg  
  inflating: /content/kaggle/train_images_jpeg/3972201692.jpg  
  inflating: /content/kaggle/train_images_jpeg/3972207361.jpg  
  inflating: /content/kaggle/train_images_jpeg/397242175.jpg  
  inflating: /content/kaggle/train_images_jpeg/3972834452.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973042447.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973123989.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973350310.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973412468.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973452259.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973659068.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973759314.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973772550.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973846840.jpg  
  inflating: /content/kaggle/train_images_jpeg/3973974283.jpg  
  inflating: /content/kaggle/train_images_jpeg/3974310104.jpg  
  inflating: /content/kaggle/train_images_jpeg/3974406563.jpg  
  inflating: /content/kaggle/train_images_jpeg/3974455402.jpg  
  inflating: /content/kaggle/train_images_jpeg/3974644689.jpg  
  inflating: /content/kaggle/train_images_jpeg/397477697.jpg  
  inflating: /content/kaggle/train_images_jpeg/3975444429.jpg  
  inflating: /content/kaggle/train_images_jpeg/3975487347.jpg  
  inflating: /content/kaggle/train_images_jpeg/3975766951.jpg  
  inflating: /content/kaggle/train_images_jpeg/3975873583.jpg  
  inflating: /content/kaggle/train_images_jpeg/3976044474.jpg  
  inflating: /content/kaggle/train_images_jpeg/3976294368.jpg  
  inflating: /content/kaggle/train_images_jpeg/3976477069.jpg  
  inflating: /content/kaggle/train_images_jpeg/3976765860.jpg  
  inflating: /content/kaggle/train_images_jpeg/3977257761.jpg  
  inflating: /content/kaggle/train_images_jpeg/3977307384.jpg  
  inflating: /content/kaggle/train_images_jpeg/3977320696.jpg  
  inflating: /content/kaggle/train_images_jpeg/3977561724.jpg  
  inflating: /content/kaggle/train_images_jpeg/3977718689.jpg  
  inflating: /content/kaggle/train_images_jpeg/3977934674.jpg  
  inflating: /content/kaggle/train_images_jpeg/3977938536.jpg  
  inflating: /content/kaggle/train_images_jpeg/3978175497.jpg  
  inflating: /content/kaggle/train_images_jpeg/3978296365.jpg  
  inflating: /content/kaggle/train_images_jpeg/3978345491.jpg  
  inflating: /content/kaggle/train_images_jpeg/3978498326.jpg  
  inflating: /content/kaggle/train_images_jpeg/3978633568.jpg  
  inflating: /content/kaggle/train_images_jpeg/397896685.jpg  
  inflating: /content/kaggle/train_images_jpeg/3979130498.jpg  
  inflating: /content/kaggle/train_images_jpeg/3979670694.jpg  
  inflating: /content/kaggle/train_images_jpeg/3979826725.jpg  
  inflating: /content/kaggle/train_images_jpeg/3980236832.jpg  
  inflating: /content/kaggle/train_images_jpeg/3980286599.jpg  
  inflating: /content/kaggle/train_images_jpeg/3980578262.jpg  
  inflating: /content/kaggle/train_images_jpeg/3980819954.jpg  
  inflating: /content/kaggle/train_images_jpeg/398109991.jpg  
  inflating: /content/kaggle/train_images_jpeg/3981217700.jpg  
  inflating: /content/kaggle/train_images_jpeg/3981449307.jpg  
  inflating: /content/kaggle/train_images_jpeg/3981645736.jpg  
  inflating: /content/kaggle/train_images_jpeg/3982368414.jpg  
  inflating: /content/kaggle/train_images_jpeg/3982901070.jpg  
  inflating: /content/kaggle/train_images_jpeg/3982972908.jpg  
  inflating: /content/kaggle/train_images_jpeg/3983156415.jpg  
  inflating: /content/kaggle/train_images_jpeg/3983257977.jpg  
  inflating: /content/kaggle/train_images_jpeg/3983529541.jpg  
  inflating: /content/kaggle/train_images_jpeg/3983622976.jpg  
  inflating: /content/kaggle/train_images_jpeg/3984046455.jpg  
  inflating: /content/kaggle/train_images_jpeg/3984082727.jpg  
  inflating: /content/kaggle/train_images_jpeg/3984375685.jpg  
  inflating: /content/kaggle/train_images_jpeg/3984703972.jpg  
  inflating: /content/kaggle/train_images_jpeg/398530204.jpg  
  inflating: /content/kaggle/train_images_jpeg/3985367860.jpg  
  inflating: /content/kaggle/train_images_jpeg/3985416531.jpg  
  inflating: /content/kaggle/train_images_jpeg/3985539982.jpg  
  inflating: /content/kaggle/train_images_jpeg/3985545704.jpg  
  inflating: /content/kaggle/train_images_jpeg/3985864340.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986073933.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986159422.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986218390.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986415473.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986526512.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986617581.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986748411.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986774650.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986797492.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986821371.jpg  
  inflating: /content/kaggle/train_images_jpeg/3986994681.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987026948.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987029837.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987145170.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987160874.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987321075.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987329576.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987330899.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987528887.jpg  
  inflating: /content/kaggle/train_images_jpeg/3987800643.jpg  
  inflating: /content/kaggle/train_images_jpeg/3988179260.jpg  
  inflating: /content/kaggle/train_images_jpeg/3988520173.jpg  
  inflating: /content/kaggle/train_images_jpeg/3988625744.jpg  
  inflating: /content/kaggle/train_images_jpeg/3988748153.jpg  
  inflating: /content/kaggle/train_images_jpeg/3988816967.jpg  
  inflating: /content/kaggle/train_images_jpeg/3988908835.jpg  
  inflating: /content/kaggle/train_images_jpeg/3989425098.jpg  
  inflating: /content/kaggle/train_images_jpeg/3989450757.jpg  
  inflating: /content/kaggle/train_images_jpeg/3989567826.jpg  
  inflating: /content/kaggle/train_images_jpeg/3989761123.jpg  
  inflating: /content/kaggle/train_images_jpeg/399009476.jpg  
  inflating: /content/kaggle/train_images_jpeg/399128521.jpg  
  inflating: /content/kaggle/train_images_jpeg/3991445025.jpg  
  inflating: /content/kaggle/train_images_jpeg/3991703391.jpg  
  inflating: /content/kaggle/train_images_jpeg/3991899434.jpg  
  inflating: /content/kaggle/train_images_jpeg/3992156989.jpg  
  inflating: /content/kaggle/train_images_jpeg/3992168079.jpg  
  inflating: /content/kaggle/train_images_jpeg/3992333811.jpg  
  inflating: /content/kaggle/train_images_jpeg/3992509961.jpg  
  inflating: /content/kaggle/train_images_jpeg/3992628804.jpg  
  inflating: /content/kaggle/train_images_jpeg/3993385288.jpg  
  inflating: /content/kaggle/train_images_jpeg/3993406091.jpg  
  inflating: /content/kaggle/train_images_jpeg/3993445930.jpg  
  inflating: /content/kaggle/train_images_jpeg/3993544013.jpg  
  inflating: /content/kaggle/train_images_jpeg/3993617081.jpg  
  inflating: /content/kaggle/train_images_jpeg/3994140306.jpg  
  inflating: /content/kaggle/train_images_jpeg/3994489797.jpg  
  inflating: /content/kaggle/train_images_jpeg/3994624875.jpg  
  inflating: /content/kaggle/train_images_jpeg/3994849052.jpg  
  inflating: /content/kaggle/train_images_jpeg/3994869632.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995159118.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995459350.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995498206.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995539083.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995611090.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995611401.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995652879.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995855836.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995859683.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995871788.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995905691.jpg  
  inflating: /content/kaggle/train_images_jpeg/3995991109.jpg  
  inflating: /content/kaggle/train_images_jpeg/3996218398.jpg  
  inflating: /content/kaggle/train_images_jpeg/3996410280.jpg  
  inflating: /content/kaggle/train_images_jpeg/3996497470.jpg  
  inflating: /content/kaggle/train_images_jpeg/3996512301.jpg  
  inflating: /content/kaggle/train_images_jpeg/399652571.jpg  
  inflating: /content/kaggle/train_images_jpeg/3997023855.jpg  
  inflating: /content/kaggle/train_images_jpeg/3997092474.jpg  
  inflating: /content/kaggle/train_images_jpeg/3997582442.jpg  
  inflating: /content/kaggle/train_images_jpeg/399780928.jpg  
  inflating: /content/kaggle/train_images_jpeg/3997854029.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998061368.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998293147.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998419018.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998452657.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998460342.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998485682.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998876448.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998978709.jpg  
  inflating: /content/kaggle/train_images_jpeg/3998982675.jpg  
  inflating: /content/kaggle/train_images_jpeg/3999057498.jpg  
  inflating: /content/kaggle/train_images_jpeg/3999223206.jpg  
  inflating: /content/kaggle/train_images_jpeg/3999758372.jpg  
  inflating: /content/kaggle/train_images_jpeg/3999919472.jpg  
  inflating: /content/kaggle/train_images_jpeg/4000041992.jpg  
  inflating: /content/kaggle/train_images_jpeg/4000198689.jpg  
  inflating: /content/kaggle/train_images_jpeg/4000520733.jpg  
  inflating: /content/kaggle/train_images_jpeg/4000584857.jpg  
  inflating: /content/kaggle/train_images_jpeg/400079356.jpg  
  inflating: /content/kaggle/train_images_jpeg/4001352115.jpg  
  inflating: /content/kaggle/train_images_jpeg/4001662386.jpg  
  inflating: /content/kaggle/train_images_jpeg/4002244325.jpg  
  inflating: /content/kaggle/train_images_jpeg/4002359446.jpg  
  inflating: /content/kaggle/train_images_jpeg/4002980483.jpg  
  inflating: /content/kaggle/train_images_jpeg/4003064199.jpg  
  inflating: /content/kaggle/train_images_jpeg/4003333385.jpg  
  inflating: /content/kaggle/train_images_jpeg/4003454599.jpg  
  inflating: /content/kaggle/train_images_jpeg/4003743131.jpg  
  inflating: /content/kaggle/train_images_jpeg/4003954623.jpg  
  inflating: /content/kaggle/train_images_jpeg/4004133979.jpg  
  inflating: /content/kaggle/train_images_jpeg/4004256594.jpg  
  inflating: /content/kaggle/train_images_jpeg/4004395307.jpg  
  inflating: /content/kaggle/train_images_jpeg/4004655752.jpg  
  inflating: /content/kaggle/train_images_jpeg/4004943921.jpg  
  inflating: /content/kaggle/train_images_jpeg/4005310479.jpg  
  inflating: /content/kaggle/train_images_jpeg/4005501772.jpg  
  inflating: /content/kaggle/train_images_jpeg/4005530868.jpg  
  inflating: /content/kaggle/train_images_jpeg/4005695464.jpg  
  inflating: /content/kaggle/train_images_jpeg/400576594.jpg  
  inflating: /content/kaggle/train_images_jpeg/4005806149.jpg  
  inflating: /content/kaggle/train_images_jpeg/4006299018.jpg  
  inflating: /content/kaggle/train_images_jpeg/4006518224.jpg  
  inflating: /content/kaggle/train_images_jpeg/4006579451.jpg  
  inflating: /content/kaggle/train_images_jpeg/400659016.jpg  
  inflating: /content/kaggle/train_images_jpeg/4006771974.jpg  
  inflating: /content/kaggle/train_images_jpeg/400686072.jpg  
  inflating: /content/kaggle/train_images_jpeg/4007062391.jpg  
  inflating: /content/kaggle/train_images_jpeg/4007185339.jpg  
  inflating: /content/kaggle/train_images_jpeg/4007199956.jpg  
  inflating: /content/kaggle/train_images_jpeg/4007234267.jpg  
  inflating: /content/kaggle/train_images_jpeg/4007496530.jpg  
  inflating: /content/kaggle/train_images_jpeg/4007863717.jpg  
  inflating: /content/kaggle/train_images_jpeg/400794559.jpg  
  inflating: /content/kaggle/train_images_jpeg/4008326221.jpg  
  inflating: /content/kaggle/train_images_jpeg/4008495271.jpg  
  inflating: /content/kaggle/train_images_jpeg/4009113191.jpg  
  inflating: /content/kaggle/train_images_jpeg/4009310147.jpg  
  inflating: /content/kaggle/train_images_jpeg/4009415549.jpg  
  inflating: /content/kaggle/train_images_jpeg/4009427061.jpg  
  inflating: /content/kaggle/train_images_jpeg/4009888434.jpg  
  inflating: /content/kaggle/train_images_jpeg/4010033110.jpg  
  inflating: /content/kaggle/train_images_jpeg/4010091989.jpg  
  inflating: /content/kaggle/train_images_jpeg/4010133596.jpg  
  inflating: /content/kaggle/train_images_jpeg/401014506.jpg  
  inflating: /content/kaggle/train_images_jpeg/401103417.jpg  
  inflating: /content/kaggle/train_images_jpeg/4011347600.jpg  
  inflating: /content/kaggle/train_images_jpeg/4011584654.jpg  
  inflating: /content/kaggle/train_images_jpeg/4011808410.jpg  
  inflating: /content/kaggle/train_images_jpeg/4011855023.jpg  
  inflating: /content/kaggle/train_images_jpeg/4012035359.jpg  
  inflating: /content/kaggle/train_images_jpeg/4012105605.jpg  
  inflating: /content/kaggle/train_images_jpeg/4012298941.jpg  
  inflating: /content/kaggle/train_images_jpeg/4012991652.jpg  
  inflating: /content/kaggle/train_images_jpeg/4013151880.jpg  
  inflating: /content/kaggle/train_images_jpeg/4013206965.jpg  
  inflating: /content/kaggle/train_images_jpeg/4013482004.jpg  
  inflating: /content/kaggle/train_images_jpeg/4013610919.jpg  
  inflating: /content/kaggle/train_images_jpeg/4013834415.jpg  
  inflating: /content/kaggle/train_images_jpeg/4013991367.jpg  
  inflating: /content/kaggle/train_images_jpeg/4014439076.jpg  
  inflating: /content/kaggle/train_images_jpeg/4014877464.jpg  
  inflating: /content/kaggle/train_images_jpeg/4014881433.jpg  
  inflating: /content/kaggle/train_images_jpeg/4014913503.jpg  
  inflating: /content/kaggle/train_images_jpeg/4015277516.jpg  
  inflating: /content/kaggle/train_images_jpeg/401560785.jpg  
  inflating: /content/kaggle/train_images_jpeg/4016073096.jpg  
  inflating: /content/kaggle/train_images_jpeg/4016154109.jpg  
  inflating: /content/kaggle/train_images_jpeg/4016279583.jpg  
  inflating: /content/kaggle/train_images_jpeg/4016400274.jpg  
  inflating: /content/kaggle/train_images_jpeg/4016407107.jpg  
  inflating: /content/kaggle/train_images_jpeg/4016547157.jpg  
  inflating: /content/kaggle/train_images_jpeg/4016802646.jpg  
  inflating: /content/kaggle/train_images_jpeg/4017187341.jpg  
  inflating: /content/kaggle/train_images_jpeg/4017354587.jpg  
  inflating: /content/kaggle/train_images_jpeg/4017387228.jpg  
  inflating: /content/kaggle/train_images_jpeg/4017647533.jpg  
  inflating: /content/kaggle/train_images_jpeg/4017689394.jpg  
  inflating: /content/kaggle/train_images_jpeg/4017822607.jpg  
  inflating: /content/kaggle/train_images_jpeg/4017896312.jpg  
  inflating: /content/kaggle/train_images_jpeg/401790013.jpg  
  inflating: /content/kaggle/train_images_jpeg/4017977717.jpg  
  inflating: /content/kaggle/train_images_jpeg/4018169789.jpg  
  inflating: /content/kaggle/train_images_jpeg/401824702.jpg  
  inflating: /content/kaggle/train_images_jpeg/401825012.jpg  
  inflating: /content/kaggle/train_images_jpeg/4018250398.jpg  
  inflating: /content/kaggle/train_images_jpeg/4018307313.jpg  
  inflating: /content/kaggle/train_images_jpeg/4018364725.jpg  
  inflating: /content/kaggle/train_images_jpeg/4018367133.jpg  
  inflating: /content/kaggle/train_images_jpeg/4018898833.jpg  
  inflating: /content/kaggle/train_images_jpeg/4018949072.jpg  
  inflating: /content/kaggle/train_images_jpeg/4019060671.jpg  
  inflating: /content/kaggle/train_images_jpeg/4019065947.jpg  
  inflating: /content/kaggle/train_images_jpeg/4019067935.jpg  
  inflating: /content/kaggle/train_images_jpeg/4019214613.jpg  
  inflating: /content/kaggle/train_images_jpeg/4019472268.jpg  
  inflating: /content/kaggle/train_images_jpeg/4019771530.jpg  
  inflating: /content/kaggle/train_images_jpeg/4020055407.jpg  
  inflating: /content/kaggle/train_images_jpeg/4020073258.jpg  
  inflating: /content/kaggle/train_images_jpeg/4020138210.jpg  
  inflating: /content/kaggle/train_images_jpeg/4020462779.jpg  
  inflating: /content/kaggle/train_images_jpeg/4020967686.jpg  
  inflating: /content/kaggle/train_images_jpeg/4021015970.jpg  
  inflating: /content/kaggle/train_images_jpeg/4021120982.jpg  
  inflating: /content/kaggle/train_images_jpeg/4021769307.jpg  
  inflating: /content/kaggle/train_images_jpeg/4022000067.jpg  
  inflating: /content/kaggle/train_images_jpeg/402211676.jpg  
  inflating: /content/kaggle/train_images_jpeg/4022128079.jpg  
  inflating: /content/kaggle/train_images_jpeg/4022798796.jpg  
  inflating: /content/kaggle/train_images_jpeg/402280669.jpg  
  inflating: /content/kaggle/train_images_jpeg/4022871563.jpg  
  inflating: /content/kaggle/train_images_jpeg/4022972553.jpg  
  inflating: /content/kaggle/train_images_jpeg/4022980210.jpg  
  inflating: /content/kaggle/train_images_jpeg/4024341056.jpg  
  inflating: /content/kaggle/train_images_jpeg/4024391744.jpg  
  inflating: /content/kaggle/train_images_jpeg/4024425381.jpg  
  inflating: /content/kaggle/train_images_jpeg/4024428406.jpg  
  inflating: /content/kaggle/train_images_jpeg/4024436293.jpg  
  inflating: /content/kaggle/train_images_jpeg/4024636592.jpg  
  inflating: /content/kaggle/train_images_jpeg/4025247063.jpg  
  inflating: /content/kaggle/train_images_jpeg/4025505972.jpg  
  inflating: /content/kaggle/train_images_jpeg/4025590571.jpg  
  inflating: /content/kaggle/train_images_jpeg/4025854027.jpg  
  inflating: /content/kaggle/train_images_jpeg/4025993930.jpg  
  inflating: /content/kaggle/train_images_jpeg/4026064019.jpg  
  inflating: /content/kaggle/train_images_jpeg/402606580.jpg  
  inflating: /content/kaggle/train_images_jpeg/4026684435.jpg  
  inflating: /content/kaggle/train_images_jpeg/4026736343.jpg  
  inflating: /content/kaggle/train_images_jpeg/4026910494.jpg  
  inflating: /content/kaggle/train_images_jpeg/4027254563.jpg  
  inflating: /content/kaggle/train_images_jpeg/4027944552.jpg  
  inflating: /content/kaggle/train_images_jpeg/402862496.jpg  
  inflating: /content/kaggle/train_images_jpeg/402874662.jpg  
  inflating: /content/kaggle/train_images_jpeg/402875912.jpg  
  inflating: /content/kaggle/train_images_jpeg/4028806922.jpg  
  inflating: /content/kaggle/train_images_jpeg/4028883745.jpg  
  inflating: /content/kaggle/train_images_jpeg/4028966918.jpg  
  inflating: /content/kaggle/train_images_jpeg/4029027750.jpg  
  inflating: /content/kaggle/train_images_jpeg/402961309.jpg  
  inflating: /content/kaggle/train_images_jpeg/402962978.jpg  
  inflating: /content/kaggle/train_images_jpeg/4029728754.jpg  
  inflating: /content/kaggle/train_images_jpeg/4029880572.jpg  
  inflating: /content/kaggle/train_images_jpeg/4029905096.jpg  
  inflating: /content/kaggle/train_images_jpeg/4030129065.jpg  
  inflating: /content/kaggle/train_images_jpeg/4030345152.jpg  
  inflating: /content/kaggle/train_images_jpeg/4030356791.jpg  
  inflating: /content/kaggle/train_images_jpeg/4030410880.jpg  
  inflating: /content/kaggle/train_images_jpeg/403051866.jpg  
  inflating: /content/kaggle/train_images_jpeg/4030982383.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031122706.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031188863.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031297900.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031321038.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031374252.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031511007.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031523832.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031627524.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031789905.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031880127.jpg  
  inflating: /content/kaggle/train_images_jpeg/4031957327.jpg  
  inflating: /content/kaggle/train_images_jpeg/4032292698.jpg  
  inflating: /content/kaggle/train_images_jpeg/4032326580.jpg  
  inflating: /content/kaggle/train_images_jpeg/403241496.jpg  
  inflating: /content/kaggle/train_images_jpeg/4032774501.jpg  
  inflating: /content/kaggle/train_images_jpeg/4032903735.jpg  
  inflating: /content/kaggle/train_images_jpeg/403293009.jpg  
  inflating: /content/kaggle/train_images_jpeg/4032940326.jpg  
  inflating: /content/kaggle/train_images_jpeg/4033298149.jpg  
  inflating: /content/kaggle/train_images_jpeg/403345253.jpg  
  inflating: /content/kaggle/train_images_jpeg/4033546541.jpg  
  inflating: /content/kaggle/train_images_jpeg/403372857.jpg  
  inflating: /content/kaggle/train_images_jpeg/4033870667.jpg  
  inflating: /content/kaggle/train_images_jpeg/4034095153.jpg  
  inflating: /content/kaggle/train_images_jpeg/403422220.jpg  
  inflating: /content/kaggle/train_images_jpeg/4034332345.jpg  
  inflating: /content/kaggle/train_images_jpeg/403440184.jpg  
  inflating: /content/kaggle/train_images_jpeg/4034495674.jpg  
  inflating: /content/kaggle/train_images_jpeg/4034498053.jpg  
  inflating: /content/kaggle/train_images_jpeg/4034547314.jpg  
  inflating: /content/kaggle/train_images_jpeg/4034553253.jpg  
  inflating: /content/kaggle/train_images_jpeg/403458333.jpg  
  inflating: /content/kaggle/train_images_jpeg/4034653549.jpg  
  inflating: /content/kaggle/train_images_jpeg/4034666533.jpg  
  inflating: /content/kaggle/train_images_jpeg/403476410.jpg  
  inflating: /content/kaggle/train_images_jpeg/4035576240.jpg  
  inflating: /content/kaggle/train_images_jpeg/4035811730.jpg  
  inflating: /content/kaggle/train_images_jpeg/4035835394.jpg  
  inflating: /content/kaggle/train_images_jpeg/4036100881.jpg  
  inflating: /content/kaggle/train_images_jpeg/4036105950.jpg  
  inflating: /content/kaggle/train_images_jpeg/4036237704.jpg  
  inflating: /content/kaggle/train_images_jpeg/4036527823.jpg  
  inflating: /content/kaggle/train_images_jpeg/4036777489.jpg  
  inflating: /content/kaggle/train_images_jpeg/403680473.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037044151.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037316351.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037341116.jpg  
  inflating: /content/kaggle/train_images_jpeg/403735844.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037393509.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037509269.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037648479.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037735151.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037829966.jpg  
  inflating: /content/kaggle/train_images_jpeg/4037870925.jpg  
  inflating: /content/kaggle/train_images_jpeg/4038168935.jpg  
  inflating: /content/kaggle/train_images_jpeg/4038284250.jpg  
  inflating: /content/kaggle/train_images_jpeg/4038344014.jpg  
  inflating: /content/kaggle/train_images_jpeg/4038568741.jpg  
  inflating: /content/kaggle/train_images_jpeg/4038643368.jpg  
  inflating: /content/kaggle/train_images_jpeg/403910552.jpg  
  inflating: /content/kaggle/train_images_jpeg/4039408618.jpg  
  inflating: /content/kaggle/train_images_jpeg/4039538172.jpg  
  inflating: /content/kaggle/train_images_jpeg/403963359.jpg  
  inflating: /content/kaggle/train_images_jpeg/4039669211.jpg  
  inflating: /content/kaggle/train_images_jpeg/4040102956.jpg  
  inflating: /content/kaggle/train_images_jpeg/4040156841.jpg  
  inflating: /content/kaggle/train_images_jpeg/4040452479.jpg  
  inflating: /content/kaggle/train_images_jpeg/404066691.jpg  
  inflating: /content/kaggle/train_images_jpeg/4040861068.jpg  
  inflating: /content/kaggle/train_images_jpeg/404115232.jpg  
  inflating: /content/kaggle/train_images_jpeg/4041427827.jpg  
  inflating: /content/kaggle/train_images_jpeg/4042037111.jpg  
  inflating: /content/kaggle/train_images_jpeg/4042084056.jpg  
  inflating: /content/kaggle/train_images_jpeg/4042496889.jpg  
  inflating: /content/kaggle/train_images_jpeg/4042964772.jpg  
  inflating: /content/kaggle/train_images_jpeg/4043076131.jpg  
  inflating: /content/kaggle/train_images_jpeg/4043153792.jpg  
  inflating: /content/kaggle/train_images_jpeg/4043211245.jpg  
  inflating: /content/kaggle/train_images_jpeg/4043869250.jpg  
  inflating: /content/kaggle/train_images_jpeg/4044063310.jpg  
  inflating: /content/kaggle/train_images_jpeg/4044222946.jpg  
  inflating: /content/kaggle/train_images_jpeg/4044329664.jpg  
  inflating: /content/kaggle/train_images_jpeg/4044444164.jpg  
  inflating: /content/kaggle/train_images_jpeg/4044550421.jpg  
  inflating: /content/kaggle/train_images_jpeg/4044829046.jpg  
  inflating: /content/kaggle/train_images_jpeg/4044997961.jpg  
  inflating: /content/kaggle/train_images_jpeg/4045015795.jpg  
  inflating: /content/kaggle/train_images_jpeg/4045136417.jpg  
  inflating: /content/kaggle/train_images_jpeg/4045142021.jpg  
  inflating: /content/kaggle/train_images_jpeg/4045262215.jpg  
  inflating: /content/kaggle/train_images_jpeg/4045566880.jpg  
  inflating: /content/kaggle/train_images_jpeg/4046068592.jpg  
  inflating: /content/kaggle/train_images_jpeg/4046154865.jpg  
  inflating: /content/kaggle/train_images_jpeg/4046217352.jpg  
  inflating: /content/kaggle/train_images_jpeg/4046239145.jpg  
  inflating: /content/kaggle/train_images_jpeg/4046290790.jpg  
  inflating: /content/kaggle/train_images_jpeg/4046649903.jpg  
  inflating: /content/kaggle/train_images_jpeg/4046661202.jpg  
  inflating: /content/kaggle/train_images_jpeg/4046910331.jpg  
  inflating: /content/kaggle/train_images_jpeg/4047167362.jpg  
  inflating: /content/kaggle/train_images_jpeg/4047585545.jpg  
  inflating: /content/kaggle/train_images_jpeg/4047998740.jpg  
  inflating: /content/kaggle/train_images_jpeg/4048156987.jpg  
  inflating: /content/kaggle/train_images_jpeg/4048354655.jpg  
  inflating: /content/kaggle/train_images_jpeg/404837485.jpg  
  inflating: /content/kaggle/train_images_jpeg/4048377608.jpg  
  inflating: /content/kaggle/train_images_jpeg/4048486399.jpg  
  inflating: /content/kaggle/train_images_jpeg/4048519217.jpg  
  inflating: /content/kaggle/train_images_jpeg/404853146.jpg  
  inflating: /content/kaggle/train_images_jpeg/4048650706.jpg  
  inflating: /content/kaggle/train_images_jpeg/4048732920.jpg  
  inflating: /content/kaggle/train_images_jpeg/404883957.jpg  
  inflating: /content/kaggle/train_images_jpeg/4049425598.jpg  
  inflating: /content/kaggle/train_images_jpeg/4049438636.jpg  
  inflating: /content/kaggle/train_images_jpeg/4049710650.jpg  
  inflating: /content/kaggle/train_images_jpeg/4049743612.jpg  
  inflating: /content/kaggle/train_images_jpeg/4049843068.jpg  
  inflating: /content/kaggle/train_images_jpeg/4050218395.jpg  
  inflating: /content/kaggle/train_images_jpeg/4050620489.jpg  
  inflating: /content/kaggle/train_images_jpeg/4050718274.jpg  
  inflating: /content/kaggle/train_images_jpeg/4050750401.jpg  
  inflating: /content/kaggle/train_images_jpeg/4050904412.jpg  
  inflating: /content/kaggle/train_images_jpeg/4051003869.jpg  
  inflating: /content/kaggle/train_images_jpeg/4051205328.jpg  
  inflating: /content/kaggle/train_images_jpeg/4051216052.jpg  
  inflating: /content/kaggle/train_images_jpeg/4051367500.jpg  
  inflating: /content/kaggle/train_images_jpeg/4052176327.jpg  
  inflating: /content/kaggle/train_images_jpeg/4052185416.jpg  
  inflating: /content/kaggle/train_images_jpeg/4052298208.jpg  
  inflating: /content/kaggle/train_images_jpeg/4052486714.jpg  
  inflating: /content/kaggle/train_images_jpeg/4052560823.jpg  
  inflating: /content/kaggle/train_images_jpeg/4052896742.jpg  
  inflating: /content/kaggle/train_images_jpeg/4052938438.jpg  
  inflating: /content/kaggle/train_images_jpeg/4053192372.jpg  
  inflating: /content/kaggle/train_images_jpeg/405323789.jpg  
  inflating: /content/kaggle/train_images_jpeg/4053510295.jpg  
  inflating: /content/kaggle/train_images_jpeg/4053511214.jpg  
  inflating: /content/kaggle/train_images_jpeg/4053727516.jpg  
  inflating: /content/kaggle/train_images_jpeg/405406521.jpg  
  inflating: /content/kaggle/train_images_jpeg/4054194563.jpg  
  inflating: /content/kaggle/train_images_jpeg/4054246073.jpg  
  inflating: /content/kaggle/train_images_jpeg/4054632356.jpg  
  inflating: /content/kaggle/train_images_jpeg/4054666662.jpg  
  inflating: /content/kaggle/train_images_jpeg/4054950426.jpg  
  inflating: /content/kaggle/train_images_jpeg/405521670.jpg  
  inflating: /content/kaggle/train_images_jpeg/4056070889.jpg  
  inflating: /content/kaggle/train_images_jpeg/4056167943.jpg  
  inflating: /content/kaggle/train_images_jpeg/4056643222.jpg  
  inflating: /content/kaggle/train_images_jpeg/4056695916.jpg  
  inflating: /content/kaggle/train_images_jpeg/4056735912.jpg  
  inflating: /content/kaggle/train_images_jpeg/405683848.jpg  
  inflating: /content/kaggle/train_images_jpeg/4056868775.jpg  
  inflating: /content/kaggle/train_images_jpeg/405707941.jpg  
  inflating: /content/kaggle/train_images_jpeg/4057082743.jpg  
  inflating: /content/kaggle/train_images_jpeg/405720625.jpg  
  inflating: /content/kaggle/train_images_jpeg/4057315544.jpg  
  inflating: /content/kaggle/train_images_jpeg/4057359447.jpg  
  inflating: /content/kaggle/train_images_jpeg/4057637286.jpg  
  inflating: /content/kaggle/train_images_jpeg/4057824685.jpg  
  inflating: /content/kaggle/train_images_jpeg/4057831785.jpg  
  inflating: /content/kaggle/train_images_jpeg/405787230.jpg  
  inflating: /content/kaggle/train_images_jpeg/4057892749.jpg  
  inflating: /content/kaggle/train_images_jpeg/4058131705.jpg  
  inflating: /content/kaggle/train_images_jpeg/4058472696.jpg  
  inflating: /content/kaggle/train_images_jpeg/4058647833.jpg  
  inflating: /content/kaggle/train_images_jpeg/4058785345.jpg  
  inflating: /content/kaggle/train_images_jpeg/4059009090.jpg  
  inflating: /content/kaggle/train_images_jpeg/4059169921.jpg  
  inflating: /content/kaggle/train_images_jpeg/4059451569.jpg  
  inflating: /content/kaggle/train_images_jpeg/4059603470.jpg  
  inflating: /content/kaggle/train_images_jpeg/4059786587.jpg  
  inflating: /content/kaggle/train_images_jpeg/40598577.jpg  
  inflating: /content/kaggle/train_images_jpeg/4059993044.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060179434.jpg  
  inflating: /content/kaggle/train_images_jpeg/406021295.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060265637.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060304349.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060346540.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060346776.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060450564.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060707407.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060802139.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060945579.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060977828.jpg  
  inflating: /content/kaggle/train_images_jpeg/4060987360.jpg  
  inflating: /content/kaggle/train_images_jpeg/4061563490.jpg  
  inflating: /content/kaggle/train_images_jpeg/4061646597.jpg  
  inflating: /content/kaggle/train_images_jpeg/4061670540.jpg  
  inflating: /content/kaggle/train_images_jpeg/4061773647.jpg  
  inflating: /content/kaggle/train_images_jpeg/4062190855.jpg  
  inflating: /content/kaggle/train_images_jpeg/4062287710.jpg  
  inflating: /content/kaggle/train_images_jpeg/4062558073.jpg  
  inflating: /content/kaggle/train_images_jpeg/4062580069.jpg  
  inflating: /content/kaggle/train_images_jpeg/4062600395.jpg  
  inflating: /content/kaggle/train_images_jpeg/4062679165.jpg  
  inflating: /content/kaggle/train_images_jpeg/4063056293.jpg  
  inflating: /content/kaggle/train_images_jpeg/4063216337.jpg  
  inflating: /content/kaggle/train_images_jpeg/4063439592.jpg  
  inflating: /content/kaggle/train_images_jpeg/4063529695.jpg  
  inflating: /content/kaggle/train_images_jpeg/4063867745.jpg  
  inflating: /content/kaggle/train_images_jpeg/4063897288.jpg  
  inflating: /content/kaggle/train_images_jpeg/4064049916.jpg  
  inflating: /content/kaggle/train_images_jpeg/4064148193.jpg  
  inflating: /content/kaggle/train_images_jpeg/4064395542.jpg  
  inflating: /content/kaggle/train_images_jpeg/4064456640.jpg  
  inflating: /content/kaggle/train_images_jpeg/4064710747.jpg  
  inflating: /content/kaggle/train_images_jpeg/4064862687.jpg  
  inflating: /content/kaggle/train_images_jpeg/4065072100.jpg  
  inflating: /content/kaggle/train_images_jpeg/4065661474.jpg  
  inflating: /content/kaggle/train_images_jpeg/4065788460.jpg  
  inflating: /content/kaggle/train_images_jpeg/406648571.jpg  
  inflating: /content/kaggle/train_images_jpeg/4066829254.jpg  
  inflating: /content/kaggle/train_images_jpeg/4067721259.jpg  
  inflating: /content/kaggle/train_images_jpeg/4067764811.jpg  
  inflating: /content/kaggle/train_images_jpeg/4067939346.jpg  
  inflating: /content/kaggle/train_images_jpeg/4068103331.jpg  
  inflating: /content/kaggle/train_images_jpeg/4068398781.jpg  
  inflating: /content/kaggle/train_images_jpeg/4068404919.jpg  
  inflating: /content/kaggle/train_images_jpeg/4068888153.jpg  
  inflating: /content/kaggle/train_images_jpeg/406899084.jpg  
  inflating: /content/kaggle/train_images_jpeg/4069208912.jpg  
  inflating: /content/kaggle/train_images_jpeg/40696329.jpg  
  inflating: /content/kaggle/train_images_jpeg/4069710475.jpg  
  inflating: /content/kaggle/train_images_jpeg/4069795713.jpg  
  inflating: /content/kaggle/train_images_jpeg/4070109402.jpg  
  inflating: /content/kaggle/train_images_jpeg/4070357374.jpg  
  inflating: /content/kaggle/train_images_jpeg/407043133.jpg  
  inflating: /content/kaggle/train_images_jpeg/4070631340.jpg  
  inflating: /content/kaggle/train_images_jpeg/4071283452.jpg  
  inflating: /content/kaggle/train_images_jpeg/4071582691.jpg  
  inflating: /content/kaggle/train_images_jpeg/4071612105.jpg  
  inflating: /content/kaggle/train_images_jpeg/4071618930.jpg  
  inflating: /content/kaggle/train_images_jpeg/4071806046.jpg  
  inflating: /content/kaggle/train_images_jpeg/4071831340.jpg  
  inflating: /content/kaggle/train_images_jpeg/4072033035.jpg  
  inflating: /content/kaggle/train_images_jpeg/4072193966.jpg  
  inflating: /content/kaggle/train_images_jpeg/4072724949.jpg  
  inflating: /content/kaggle/train_images_jpeg/4072800453.jpg  
  inflating: /content/kaggle/train_images_jpeg/4072965036.jpg  
  inflating: /content/kaggle/train_images_jpeg/4073303739.jpg  
  inflating: /content/kaggle/train_images_jpeg/4073445610.jpg  
  inflating: /content/kaggle/train_images_jpeg/4073523035.jpg  
  inflating: /content/kaggle/train_images_jpeg/4073637668.jpg  
  inflating: /content/kaggle/train_images_jpeg/4073688156.jpg  
  inflating: /content/kaggle/train_images_jpeg/407426699.jpg  
  inflating: /content/kaggle/train_images_jpeg/4074421218.jpg  
  inflating: /content/kaggle/train_images_jpeg/4074718278.jpg  
  inflating: /content/kaggle/train_images_jpeg/4074847622.jpg  
  inflating: /content/kaggle/train_images_jpeg/4075237855.jpg  
  inflating: /content/kaggle/train_images_jpeg/4075320498.jpg  
  inflating: /content/kaggle/train_images_jpeg/4075412353.jpg  
  inflating: /content/kaggle/train_images_jpeg/4075436598.jpg  
  inflating: /content/kaggle/train_images_jpeg/4075854821.jpg  
  inflating: /content/kaggle/train_images_jpeg/4076400056.jpg  
  inflating: /content/kaggle/train_images_jpeg/4076735370.jpg  
  inflating: /content/kaggle/train_images_jpeg/4076823454.jpg  
  inflating: /content/kaggle/train_images_jpeg/4077138673.jpg  
  inflating: /content/kaggle/train_images_jpeg/4077296935.jpg  
  inflating: /content/kaggle/train_images_jpeg/4077418003.jpg  
  inflating: /content/kaggle/train_images_jpeg/4077473431.jpg  
  inflating: /content/kaggle/train_images_jpeg/4077715021.jpg  
  inflating: /content/kaggle/train_images_jpeg/407801447.jpg  
  inflating: /content/kaggle/train_images_jpeg/4078601864.jpg  
  inflating: /content/kaggle/train_images_jpeg/4079242692.jpg  
  inflating: /content/kaggle/train_images_jpeg/4079437688.jpg  
  inflating: /content/kaggle/train_images_jpeg/40795473.jpg  
  inflating: /content/kaggle/train_images_jpeg/4079941284.jpg  
  inflating: /content/kaggle/train_images_jpeg/4080358205.jpg  
  inflating: /content/kaggle/train_images_jpeg/4080368773.jpg  
  inflating: /content/kaggle/train_images_jpeg/4080443505.jpg  
  inflating: /content/kaggle/train_images_jpeg/408051106.jpg  
  inflating: /content/kaggle/train_images_jpeg/4080548789.jpg  
  inflating: /content/kaggle/train_images_jpeg/4080639262.jpg  
  inflating: /content/kaggle/train_images_jpeg/4080805940.jpg  
  inflating: /content/kaggle/train_images_jpeg/408081310.jpg  
  inflating: /content/kaggle/train_images_jpeg/4080945037.jpg  
  inflating: /content/kaggle/train_images_jpeg/4080972605.jpg  
  inflating: /content/kaggle/train_images_jpeg/4081070840.jpg  
  inflating: /content/kaggle/train_images_jpeg/4081152393.jpg  
  inflating: /content/kaggle/train_images_jpeg/4081341161.jpg  
  inflating: /content/kaggle/train_images_jpeg/408144068.jpg  
  inflating: /content/kaggle/train_images_jpeg/4081836555.jpg  
  inflating: /content/kaggle/train_images_jpeg/4082024517.jpg  
  inflating: /content/kaggle/train_images_jpeg/4082420465.jpg  
  inflating: /content/kaggle/train_images_jpeg/4082694328.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083175669.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083517071.jpg  
  inflating: /content/kaggle/train_images_jpeg/408355226.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083589127.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083644073.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083711449.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083726805.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083737751.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083768019.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083830732.jpg  
  inflating: /content/kaggle/train_images_jpeg/4083849263.jpg  
  inflating: /content/kaggle/train_images_jpeg/4084071481.jpg  
  inflating: /content/kaggle/train_images_jpeg/408414905.jpg  
  inflating: /content/kaggle/train_images_jpeg/4084209845.jpg  
  inflating: /content/kaggle/train_images_jpeg/4084470563.jpg  
  inflating: /content/kaggle/train_images_jpeg/4084600785.jpg  
  inflating: /content/kaggle/train_images_jpeg/4084618799.jpg  
  inflating: /content/kaggle/train_images_jpeg/4084681419.jpg  
  inflating: /content/kaggle/train_images_jpeg/4084684483.jpg  
  inflating: /content/kaggle/train_images_jpeg/4085008913.jpg  
  inflating: /content/kaggle/train_images_jpeg/4085837229.jpg  
  inflating: /content/kaggle/train_images_jpeg/4086398319.jpg  
  inflating: /content/kaggle/train_images_jpeg/4086759203.jpg  
  inflating: /content/kaggle/train_images_jpeg/4086892324.jpg  
  inflating: /content/kaggle/train_images_jpeg/408698793.jpg  
  inflating: /content/kaggle/train_images_jpeg/4087247373.jpg  
  inflating: /content/kaggle/train_images_jpeg/4087448407.jpg  
  inflating: /content/kaggle/train_images_jpeg/4087523720.jpg  
  inflating: /content/kaggle/train_images_jpeg/4087569473.jpg  
  inflating: /content/kaggle/train_images_jpeg/4088071692.jpg  
  inflating: /content/kaggle/train_images_jpeg/4088233611.jpg  
  inflating: /content/kaggle/train_images_jpeg/4088249542.jpg  
  inflating: /content/kaggle/train_images_jpeg/4088464085.jpg  
  inflating: /content/kaggle/train_images_jpeg/4088770277.jpg  
  inflating: /content/kaggle/train_images_jpeg/4089218356.jpg  
  inflating: /content/kaggle/train_images_jpeg/4089587580.jpg  
  inflating: /content/kaggle/train_images_jpeg/4089645917.jpg  
  inflating: /content/kaggle/train_images_jpeg/4089661162.jpg  
  inflating: /content/kaggle/train_images_jpeg/4089766352.jpg  
  inflating: /content/kaggle/train_images_jpeg/4089978663.jpg  
  inflating: /content/kaggle/train_images_jpeg/4090024132.jpg  
  inflating: /content/kaggle/train_images_jpeg/4090496115.jpg  
  inflating: /content/kaggle/train_images_jpeg/4090594888.jpg  
  inflating: /content/kaggle/train_images_jpeg/4090740611.jpg  
  inflating: /content/kaggle/train_images_jpeg/409126983.jpg  
  inflating: /content/kaggle/train_images_jpeg/4091333216.jpg  
  inflating: /content/kaggle/train_images_jpeg/4091446019.jpg  
  inflating: /content/kaggle/train_images_jpeg/4091571824.jpg  
  inflating: /content/kaggle/train_images_jpeg/4091618832.jpg  
  inflating: /content/kaggle/train_images_jpeg/4091663475.jpg  
  inflating: /content/kaggle/train_images_jpeg/4091748271.jpg  
  inflating: /content/kaggle/train_images_jpeg/4092163942.jpg  
  inflating: /content/kaggle/train_images_jpeg/4092211517.jpg  
  inflating: /content/kaggle/train_images_jpeg/4092403597.jpg  
  inflating: /content/kaggle/train_images_jpeg/4092496590.jpg  
  inflating: /content/kaggle/train_images_jpeg/4092575256.jpg  
  inflating: /content/kaggle/train_images_jpeg/4092623035.jpg  
  inflating: /content/kaggle/train_images_jpeg/4092816326.jpg  
  inflating: /content/kaggle/train_images_jpeg/409358481.jpg  
  inflating: /content/kaggle/train_images_jpeg/4093904731.jpg  
  inflating: /content/kaggle/train_images_jpeg/409443978.jpg  
  inflating: /content/kaggle/train_images_jpeg/4094696582.jpg  
  inflating: /content/kaggle/train_images_jpeg/409474529.jpg  
  inflating: /content/kaggle/train_images_jpeg/4094778981.jpg  
  inflating: /content/kaggle/train_images_jpeg/4095625090.jpg  
  inflating: /content/kaggle/train_images_jpeg/4095719634.jpg  
  inflating: /content/kaggle/train_images_jpeg/4095924422.jpg  
  inflating: /content/kaggle/train_images_jpeg/40960944.jpg  
  inflating: /content/kaggle/train_images_jpeg/4096334049.jpg  
  inflating: /content/kaggle/train_images_jpeg/4096337072.jpg  
  inflating: /content/kaggle/train_images_jpeg/4096675395.jpg  
  inflating: /content/kaggle/train_images_jpeg/4096774182.jpg  
  inflating: /content/kaggle/train_images_jpeg/4096966485.jpg  
  inflating: /content/kaggle/train_images_jpeg/409723324.jpg  
  inflating: /content/kaggle/train_images_jpeg/4097262272.jpg  
  inflating: /content/kaggle/train_images_jpeg/4098206524.jpg  
  inflating: /content/kaggle/train_images_jpeg/4098341362.jpg  
  inflating: /content/kaggle/train_images_jpeg/4098383673.jpg  
  inflating: /content/kaggle/train_images_jpeg/4098458638.jpg  
  inflating: /content/kaggle/train_images_jpeg/4098473118.jpg  
  inflating: /content/kaggle/train_images_jpeg/4098892948.jpg  
  inflating: /content/kaggle/train_images_jpeg/4098951453.jpg  
  inflating: /content/kaggle/train_images_jpeg/4099004871.jpg  
  inflating: /content/kaggle/train_images_jpeg/409901220.jpg  
  inflating: /content/kaggle/train_images_jpeg/4099957665.jpg  
  inflating: /content/kaggle/train_images_jpeg/4100265698.jpg  
  inflating: /content/kaggle/train_images_jpeg/4100436529.jpg  
  inflating: /content/kaggle/train_images_jpeg/4100445719.jpg  
  inflating: /content/kaggle/train_images_jpeg/4100598870.jpg  
  inflating: /content/kaggle/train_images_jpeg/4100817891.jpg  
  inflating: /content/kaggle/train_images_jpeg/4101194273.jpg  
  inflating: /content/kaggle/train_images_jpeg/4101440622.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102169055.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102201143.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102423093.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102442898.jpg  
  inflating: /content/kaggle/train_images_jpeg/410264599.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102729978.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102750438.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102833148.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102856795.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102864004.jpg  
  inflating: /content/kaggle/train_images_jpeg/410291053.jpg  
  inflating: /content/kaggle/train_images_jpeg/4102968836.jpg  
  inflating: /content/kaggle/train_images_jpeg/4103177818.jpg  
  inflating: /content/kaggle/train_images_jpeg/4103274356.jpg  
  inflating: /content/kaggle/train_images_jpeg/4103428960.jpg  
  inflating: /content/kaggle/train_images_jpeg/4103433070.jpg  
  inflating: /content/kaggle/train_images_jpeg/410355412.jpg  
  inflating: /content/kaggle/train_images_jpeg/4103654228.jpg  
  inflating: /content/kaggle/train_images_jpeg/4103773008.jpg  
  inflating: /content/kaggle/train_images_jpeg/4103867773.jpg  
  inflating: /content/kaggle/train_images_jpeg/410414425.jpg  
  inflating: /content/kaggle/train_images_jpeg/4104305706.jpg  
  inflating: /content/kaggle/train_images_jpeg/4104529237.jpg  
  inflating: /content/kaggle/train_images_jpeg/410476072.jpg  
  inflating: /content/kaggle/train_images_jpeg/4105402505.jpg  
  inflating: /content/kaggle/train_images_jpeg/410556634.jpg  
  inflating: /content/kaggle/train_images_jpeg/4105662619.jpg  
  inflating: /content/kaggle/train_images_jpeg/4106389238.jpg  
  inflating: /content/kaggle/train_images_jpeg/4106517442.jpg  
  inflating: /content/kaggle/train_images_jpeg/4106720331.jpg  
  inflating: /content/kaggle/train_images_jpeg/4106981326.jpg  
  inflating: /content/kaggle/train_images_jpeg/4107144871.jpg  
  inflating: /content/kaggle/train_images_jpeg/4107344800.jpg  
  inflating: /content/kaggle/train_images_jpeg/4107485206.jpg  
  inflating: /content/kaggle/train_images_jpeg/4107585642.jpg  
  inflating: /content/kaggle/train_images_jpeg/4107677180.jpg  
  inflating: /content/kaggle/train_images_jpeg/410771727.jpg  
  inflating: /content/kaggle/train_images_jpeg/4107720653.jpg  
  inflating: /content/kaggle/train_images_jpeg/4108340746.jpg  
  inflating: /content/kaggle/train_images_jpeg/4108393166.jpg  
  inflating: /content/kaggle/train_images_jpeg/410863155.jpg  
  inflating: /content/kaggle/train_images_jpeg/4108766138.jpg  
  inflating: /content/kaggle/train_images_jpeg/410880003.jpg  
  inflating: /content/kaggle/train_images_jpeg/4108844904.jpg  
  inflating: /content/kaggle/train_images_jpeg/410890316.jpg  
  inflating: /content/kaggle/train_images_jpeg/4109154808.jpg  
  inflating: /content/kaggle/train_images_jpeg/4109287296.jpg  
  inflating: /content/kaggle/train_images_jpeg/4109440762.jpg  
  inflating: /content/kaggle/train_images_jpeg/4109731442.jpg  
  inflating: /content/kaggle/train_images_jpeg/4109907649.jpg  
  inflating: /content/kaggle/train_images_jpeg/4109950736.jpg  
  inflating: /content/kaggle/train_images_jpeg/411062197.jpg  
  inflating: /content/kaggle/train_images_jpeg/4110644267.jpg  
  inflating: /content/kaggle/train_images_jpeg/4110692796.jpg  
  inflating: /content/kaggle/train_images_jpeg/4110987286.jpg  
  inflating: /content/kaggle/train_images_jpeg/4111161962.jpg  
  inflating: /content/kaggle/train_images_jpeg/4111265654.jpg  
  inflating: /content/kaggle/train_images_jpeg/4111579304.jpg  
  inflating: /content/kaggle/train_images_jpeg/4111582298.jpg  
  inflating: /content/kaggle/train_images_jpeg/4112011876.jpg  
  inflating: /content/kaggle/train_images_jpeg/4112721304.jpg  
  inflating: /content/kaggle/train_images_jpeg/4113552103.jpg  
  inflating: /content/kaggle/train_images_jpeg/4113678968.jpg  
  inflating: /content/kaggle/train_images_jpeg/4113877744.jpg  
  inflating: /content/kaggle/train_images_jpeg/4113975266.jpg  
  inflating: /content/kaggle/train_images_jpeg/4114035268.jpg  
  inflating: /content/kaggle/train_images_jpeg/4114133209.jpg  
  inflating: /content/kaggle/train_images_jpeg/4114136102.jpg  
  inflating: /content/kaggle/train_images_jpeg/4114142974.jpg  
  inflating: /content/kaggle/train_images_jpeg/4114788959.jpg  
  inflating: /content/kaggle/train_images_jpeg/4115111691.jpg  
  inflating: /content/kaggle/train_images_jpeg/4115342208.jpg  
  inflating: /content/kaggle/train_images_jpeg/4115513115.jpg  
  inflating: /content/kaggle/train_images_jpeg/4116136963.jpg  
  inflating: /content/kaggle/train_images_jpeg/4116414929.jpg  
  inflating: /content/kaggle/train_images_jpeg/4116600053.jpg  
  inflating: /content/kaggle/train_images_jpeg/4116832468.jpg  
  inflating: /content/kaggle/train_images_jpeg/4117129692.jpg  
  inflating: /content/kaggle/train_images_jpeg/4117169270.jpg  
  inflating: /content/kaggle/train_images_jpeg/4117178950.jpg  
  inflating: /content/kaggle/train_images_jpeg/4117276057.jpg  
  inflating: /content/kaggle/train_images_jpeg/4117539669.jpg  
  inflating: /content/kaggle/train_images_jpeg/4117744697.jpg  
  inflating: /content/kaggle/train_images_jpeg/4118106145.jpg  
  inflating: /content/kaggle/train_images_jpeg/4118609397.jpg  
  inflating: /content/kaggle/train_images_jpeg/4118708857.jpg  
  inflating: /content/kaggle/train_images_jpeg/4118954331.jpg  
  inflating: /content/kaggle/train_images_jpeg/4119019208.jpg  
  inflating: /content/kaggle/train_images_jpeg/4119076771.jpg  
  inflating: /content/kaggle/train_images_jpeg/4119270485.jpg  
  inflating: /content/kaggle/train_images_jpeg/4119371139.jpg  
  inflating: /content/kaggle/train_images_jpeg/4119520540.jpg  
  inflating: /content/kaggle/train_images_jpeg/411955232.jpg  
  inflating: /content/kaggle/train_images_jpeg/4120101206.jpg  
  inflating: /content/kaggle/train_images_jpeg/4120352368.jpg  
  inflating: /content/kaggle/train_images_jpeg/4120621808.jpg  
  inflating: /content/kaggle/train_images_jpeg/4120735558.jpg  
  inflating: /content/kaggle/train_images_jpeg/4120741228.jpg  
  inflating: /content/kaggle/train_images_jpeg/4120845845.jpg  
  inflating: /content/kaggle/train_images_jpeg/4120960004.jpg  
  inflating: /content/kaggle/train_images_jpeg/4120963447.jpg  
  inflating: /content/kaggle/train_images_jpeg/4121034467.jpg  
  inflating: /content/kaggle/train_images_jpeg/4121046251.jpg  
  inflating: /content/kaggle/train_images_jpeg/4121231239.jpg  
  inflating: /content/kaggle/train_images_jpeg/4121252698.jpg  
  inflating: /content/kaggle/train_images_jpeg/4121566836.jpg  
  inflating: /content/kaggle/train_images_jpeg/4121873151.jpg  
  inflating: /content/kaggle/train_images_jpeg/4122060123.jpg  
  inflating: /content/kaggle/train_images_jpeg/4122391127.jpg  
  inflating: /content/kaggle/train_images_jpeg/4122820167.jpg  
  inflating: /content/kaggle/train_images_jpeg/4122834254.jpg  
  inflating: /content/kaggle/train_images_jpeg/4122883459.jpg  
  inflating: /content/kaggle/train_images_jpeg/4123166218.jpg  
  inflating: /content/kaggle/train_images_jpeg/412355658.jpg  
  inflating: /content/kaggle/train_images_jpeg/4123594620.jpg  
  inflating: /content/kaggle/train_images_jpeg/4123656006.jpg  
  inflating: /content/kaggle/train_images_jpeg/412390858.jpg  
  inflating: /content/kaggle/train_images_jpeg/4123940124.jpg  
  inflating: /content/kaggle/train_images_jpeg/4124205703.jpg  
  inflating: /content/kaggle/train_images_jpeg/4124483418.jpg  
  inflating: /content/kaggle/train_images_jpeg/4124651871.jpg  
  inflating: /content/kaggle/train_images_jpeg/4125025056.jpg  
  inflating: /content/kaggle/train_images_jpeg/4125173435.jpg  
  inflating: /content/kaggle/train_images_jpeg/4125318611.jpg  
  inflating: /content/kaggle/train_images_jpeg/4126019985.jpg  
  inflating: /content/kaggle/train_images_jpeg/4126193524.jpg  
  inflating: /content/kaggle/train_images_jpeg/4126692105.jpg  
  inflating: /content/kaggle/train_images_jpeg/4126694609.jpg  
  inflating: /content/kaggle/train_images_jpeg/4126983355.jpg  
  inflating: /content/kaggle/train_images_jpeg/4127132722.jpg  
  inflating: /content/kaggle/train_images_jpeg/4127310091.jpg  
  inflating: /content/kaggle/train_images_jpeg/4127363037.jpg  
  inflating: /content/kaggle/train_images_jpeg/4127820008.jpg  
  inflating: /content/kaggle/train_images_jpeg/4128295692.jpg  
  inflating: /content/kaggle/train_images_jpeg/4128588977.jpg  
  inflating: /content/kaggle/train_images_jpeg/4128599330.jpg  
  inflating: /content/kaggle/train_images_jpeg/4128762392.jpg  
  inflating: /content/kaggle/train_images_jpeg/4129031753.jpg  
  inflating: /content/kaggle/train_images_jpeg/4129857747.jpg  
  inflating: /content/kaggle/train_images_jpeg/4130015523.jpg  
  inflating: /content/kaggle/train_images_jpeg/4130177618.jpg  
  inflating: /content/kaggle/train_images_jpeg/4130203885.jpg  
  inflating: /content/kaggle/train_images_jpeg/4130341996.jpg  
  inflating: /content/kaggle/train_images_jpeg/413051976.jpg  
  inflating: /content/kaggle/train_images_jpeg/4130557422.jpg  
  inflating: /content/kaggle/train_images_jpeg/4130607163.jpg  
  inflating: /content/kaggle/train_images_jpeg/4130960215.jpg  
  inflating: /content/kaggle/train_images_jpeg/4131012471.jpg  
  inflating: /content/kaggle/train_images_jpeg/4131123441.jpg  
  inflating: /content/kaggle/train_images_jpeg/413123167.jpg  
  inflating: /content/kaggle/train_images_jpeg/4131260506.jpg  
  inflating: /content/kaggle/train_images_jpeg/4131457294.jpg  
  inflating: /content/kaggle/train_images_jpeg/4132347499.jpg  
  inflating: /content/kaggle/train_images_jpeg/4132381633.jpg  
  inflating: /content/kaggle/train_images_jpeg/4132540951.jpg  
  inflating: /content/kaggle/train_images_jpeg/41327518.jpg  
  inflating: /content/kaggle/train_images_jpeg/4133329748.jpg  
  inflating: /content/kaggle/train_images_jpeg/4133546667.jpg  
  inflating: /content/kaggle/train_images_jpeg/4133624649.jpg  
  inflating: /content/kaggle/train_images_jpeg/4133641764.jpg  
  inflating: /content/kaggle/train_images_jpeg/4133934896.jpg  
  inflating: /content/kaggle/train_images_jpeg/4134468341.jpg  
  inflating: /content/kaggle/train_images_jpeg/4134583704.jpg  
  inflating: /content/kaggle/train_images_jpeg/4134617519.jpg  
  inflating: /content/kaggle/train_images_jpeg/4134659314.jpg  
  inflating: /content/kaggle/train_images_jpeg/4135070493.jpg  
  inflating: /content/kaggle/train_images_jpeg/4135122260.jpg  
  inflating: /content/kaggle/train_images_jpeg/4135213760.jpg  
  inflating: /content/kaggle/train_images_jpeg/41357060.jpg  
  inflating: /content/kaggle/train_images_jpeg/4135889078.jpg  
  inflating: /content/kaggle/train_images_jpeg/4135953143.jpg  
  inflating: /content/kaggle/train_images_jpeg/4136065352.jpg  
  inflating: /content/kaggle/train_images_jpeg/4136137862.jpg  
  inflating: /content/kaggle/train_images_jpeg/4136626919.jpg  
  inflating: /content/kaggle/train_images_jpeg/4136833908.jpg  
  inflating: /content/kaggle/train_images_jpeg/4136929395.jpg  
  inflating: /content/kaggle/train_images_jpeg/4136963668.jpg  
  inflating: /content/kaggle/train_images_jpeg/4137525990.jpg  
  inflating: /content/kaggle/train_images_jpeg/4137700702.jpg  
  inflating: /content/kaggle/train_images_jpeg/4137735351.jpg  
  inflating: /content/kaggle/train_images_jpeg/4137790344.jpg  
  inflating: /content/kaggle/train_images_jpeg/41378433.jpg  
  inflating: /content/kaggle/train_images_jpeg/4137861888.jpg  
  inflating: /content/kaggle/train_images_jpeg/4138481373.jpg  
  inflating: /content/kaggle/train_images_jpeg/4138769021.jpg  
  inflating: /content/kaggle/train_images_jpeg/4138957556.jpg  
  inflating: /content/kaggle/train_images_jpeg/413906882.jpg  
  inflating: /content/kaggle/train_images_jpeg/413912363.jpg  
  inflating: /content/kaggle/train_images_jpeg/413920422.jpg  
  inflating: /content/kaggle/train_images_jpeg/4139268407.jpg  
  inflating: /content/kaggle/train_images_jpeg/4140015912.jpg  
  inflating: /content/kaggle/train_images_jpeg/4140207015.jpg  
  inflating: /content/kaggle/train_images_jpeg/4140381716.jpg  
  inflating: /content/kaggle/train_images_jpeg/41404383.jpg  
  inflating: /content/kaggle/train_images_jpeg/4140557884.jpg  
  inflating: /content/kaggle/train_images_jpeg/4140868783.jpg  
  inflating: /content/kaggle/train_images_jpeg/4141439714.jpg  
  inflating: /content/kaggle/train_images_jpeg/4141594059.jpg  
  inflating: /content/kaggle/train_images_jpeg/4141630996.jpg  
  inflating: /content/kaggle/train_images_jpeg/414171398.jpg  
  inflating: /content/kaggle/train_images_jpeg/4141721005.jpg  
  inflating: /content/kaggle/train_images_jpeg/4141801603.jpg  
  inflating: /content/kaggle/train_images_jpeg/4141898495.jpg  
  inflating: /content/kaggle/train_images_jpeg/4142137699.jpg  
  inflating: /content/kaggle/train_images_jpeg/4142266385.jpg  
  inflating: /content/kaggle/train_images_jpeg/414229694.jpg  
  inflating: /content/kaggle/train_images_jpeg/4142424247.jpg  
  inflating: /content/kaggle/train_images_jpeg/4142462733.jpg  
  inflating: /content/kaggle/train_images_jpeg/4142500062.jpg  
  inflating: /content/kaggle/train_images_jpeg/4142699923.jpg  
  inflating: /content/kaggle/train_images_jpeg/4142864830.jpg  
  inflating: /content/kaggle/train_images_jpeg/4142973523.jpg  
  inflating: /content/kaggle/train_images_jpeg/414320641.jpg  
  inflating: /content/kaggle/train_images_jpeg/4143264926.jpg  
  inflating: /content/kaggle/train_images_jpeg/4143432365.jpg  
  inflating: /content/kaggle/train_images_jpeg/414363375.jpg  
  inflating: /content/kaggle/train_images_jpeg/4143889304.jpg  
  inflating: /content/kaggle/train_images_jpeg/4144053251.jpg  
  inflating: /content/kaggle/train_images_jpeg/4144134428.jpg  
  inflating: /content/kaggle/train_images_jpeg/4144248686.jpg  
  inflating: /content/kaggle/train_images_jpeg/4144297967.jpg  
  inflating: /content/kaggle/train_images_jpeg/4144515023.jpg  
  inflating: /content/kaggle/train_images_jpeg/4144868742.jpg  
  inflating: /content/kaggle/train_images_jpeg/4145051602.jpg  
  inflating: /content/kaggle/train_images_jpeg/4145160333.jpg  
  inflating: /content/kaggle/train_images_jpeg/4145471533.jpg  
  inflating: /content/kaggle/train_images_jpeg/4145595052.jpg  
  inflating: /content/kaggle/train_images_jpeg/4145634320.jpg  
  inflating: /content/kaggle/train_images_jpeg/4145708140.jpg  
  inflating: /content/kaggle/train_images_jpeg/4145817013.jpg  
  inflating: /content/kaggle/train_images_jpeg/4145869943.jpg  
  inflating: /content/kaggle/train_images_jpeg/414587008.jpg  
  inflating: /content/kaggle/train_images_jpeg/4146003606.jpg  
  inflating: /content/kaggle/train_images_jpeg/4146091086.jpg  
  inflating: /content/kaggle/train_images_jpeg/4146139706.jpg  
  inflating: /content/kaggle/train_images_jpeg/4146567066.jpg  
  inflating: /content/kaggle/train_images_jpeg/4146743223.jpg  
  inflating: /content/kaggle/train_images_jpeg/4146786218.jpg  
  inflating: /content/kaggle/train_images_jpeg/4146910494.jpg  
  inflating: /content/kaggle/train_images_jpeg/4147019519.jpg  
  inflating: /content/kaggle/train_images_jpeg/4147446952.jpg  
  inflating: /content/kaggle/train_images_jpeg/4147456412.jpg  
  inflating: /content/kaggle/train_images_jpeg/4147565807.jpg  
  inflating: /content/kaggle/train_images_jpeg/4147670856.jpg  
  inflating: /content/kaggle/train_images_jpeg/4147695010.jpg  
  inflating: /content/kaggle/train_images_jpeg/4147986236.jpg  
  inflating: /content/kaggle/train_images_jpeg/4147991798.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148250496.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148306870.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148349078.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148374755.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148746293.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148790087.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148883240.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148970869.jpg  
  inflating: /content/kaggle/train_images_jpeg/4148972063.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149005618.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149019611.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149032443.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149062810.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149113936.jpg  
  inflating: /content/kaggle/train_images_jpeg/414926193.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149439273.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149442480.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149713311.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149713617.jpg  
  inflating: /content/kaggle/train_images_jpeg/4149719008.jpg  
  inflating: /content/kaggle/train_images_jpeg/4150333729.jpg  
  inflating: /content/kaggle/train_images_jpeg/415073532.jpg  
  inflating: /content/kaggle/train_images_jpeg/4150882054.jpg  
  inflating: /content/kaggle/train_images_jpeg/415127331.jpg  
  inflating: /content/kaggle/train_images_jpeg/4151340541.jpg  
  inflating: /content/kaggle/train_images_jpeg/4151371064.jpg  
  inflating: /content/kaggle/train_images_jpeg/4151450216.jpg  
  inflating: /content/kaggle/train_images_jpeg/4151543321.jpg  
  inflating: /content/kaggle/train_images_jpeg/4152070738.jpg  
  inflating: /content/kaggle/train_images_jpeg/4152202956.jpg  
  inflating: /content/kaggle/train_images_jpeg/4152354751.jpg  
  inflating: /content/kaggle/train_images_jpeg/4152813711.jpg  
  inflating: /content/kaggle/train_images_jpeg/4152969433.jpg  
  inflating: /content/kaggle/train_images_jpeg/4153020952.jpg  
  inflating: /content/kaggle/train_images_jpeg/4153074724.jpg  
  inflating: /content/kaggle/train_images_jpeg/4153204450.jpg  
  inflating: /content/kaggle/train_images_jpeg/4153230948.jpg  
  inflating: /content/kaggle/train_images_jpeg/4153465850.jpg  
  inflating: /content/kaggle/train_images_jpeg/4153590251.jpg  
  inflating: /content/kaggle/train_images_jpeg/4153904483.jpg  
  inflating: /content/kaggle/train_images_jpeg/4153984677.jpg  
  inflating: /content/kaggle/train_images_jpeg/4154410133.jpg  
  inflating: /content/kaggle/train_images_jpeg/4154571034.jpg  
  inflating: /content/kaggle/train_images_jpeg/4154577723.jpg  
  inflating: /content/kaggle/train_images_jpeg/415504810.jpg  
  inflating: /content/kaggle/train_images_jpeg/4155077237.jpg  
  inflating: /content/kaggle/train_images_jpeg/4155175371.jpg  
  inflating: /content/kaggle/train_images_jpeg/4155925395.jpg  
  inflating: /content/kaggle/train_images_jpeg/415601411.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156066738.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156138691.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156232104.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156293959.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156350478.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156518225.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156520758.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156615923.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156754691.jpg  
  inflating: /content/kaggle/train_images_jpeg/4156956690.jpg  
  inflating: /content/kaggle/train_images_jpeg/4157431857.jpg  
  inflating: /content/kaggle/train_images_jpeg/4157582812.jpg  
  inflating: /content/kaggle/train_images_jpeg/4157808497.jpg  
  inflating: /content/kaggle/train_images_jpeg/4157923017.jpg  
  inflating: /content/kaggle/train_images_jpeg/415809799.jpg  
  inflating: /content/kaggle/train_images_jpeg/4158544304.jpg  
  inflating: /content/kaggle/train_images_jpeg/4158622141.jpg  
  inflating: /content/kaggle/train_images_jpeg/415901273.jpg  
  inflating: /content/kaggle/train_images_jpeg/4159206286.jpg  
  inflating: /content/kaggle/train_images_jpeg/4159264325.jpg  
  inflating: /content/kaggle/train_images_jpeg/4159550001.jpg  
  inflating: /content/kaggle/train_images_jpeg/4159698994.jpg  
  inflating: /content/kaggle/train_images_jpeg/4159778976.jpg  
  inflating: /content/kaggle/train_images_jpeg/4159967753.jpg  
  inflating: /content/kaggle/train_images_jpeg/4160459669.jpg  
  inflating: /content/kaggle/train_images_jpeg/416062259.jpg  
  inflating: /content/kaggle/train_images_jpeg/41606397.jpg  
  inflating: /content/kaggle/train_images_jpeg/4160794520.jpg  
  inflating: /content/kaggle/train_images_jpeg/4161456491.jpg  
  inflating: /content/kaggle/train_images_jpeg/4161605185.jpg  
  inflating: /content/kaggle/train_images_jpeg/4161798280.jpg  
  inflating: /content/kaggle/train_images_jpeg/4162062319.jpg  
  inflating: /content/kaggle/train_images_jpeg/4162289609.jpg  
  inflating: /content/kaggle/train_images_jpeg/4162370694.jpg  
  inflating: /content/kaggle/train_images_jpeg/416260433.jpg  
  inflating: /content/kaggle/train_images_jpeg/416297686.jpg  
  inflating: /content/kaggle/train_images_jpeg/4163008109.jpg  
  inflating: /content/kaggle/train_images_jpeg/416350020.jpg  
  inflating: /content/kaggle/train_images_jpeg/4163993800.jpg  
  inflating: /content/kaggle/train_images_jpeg/4164175215.jpg  
  inflating: /content/kaggle/train_images_jpeg/4165205071.jpg  
  inflating: /content/kaggle/train_images_jpeg/4165290692.jpg  
  inflating: /content/kaggle/train_images_jpeg/4165383936.jpg  
  inflating: /content/kaggle/train_images_jpeg/4165541319.jpg  
  inflating: /content/kaggle/train_images_jpeg/4165714007.jpg  
  inflating: /content/kaggle/train_images_jpeg/4165918071.jpg  
  inflating: /content/kaggle/train_images_jpeg/4165966394.jpg  
  inflating: /content/kaggle/train_images_jpeg/4166172905.jpg  
  inflating: /content/kaggle/train_images_jpeg/4166257739.jpg  
  inflating: /content/kaggle/train_images_jpeg/4166481906.jpg  
  inflating: /content/kaggle/train_images_jpeg/4166602274.jpg  
  inflating: /content/kaggle/train_images_jpeg/4166762.jpg  
  inflating: /content/kaggle/train_images_jpeg/4166830303.jpg  
  inflating: /content/kaggle/train_images_jpeg/4167054860.jpg  
  inflating: /content/kaggle/train_images_jpeg/4167185859.jpg  
  inflating: /content/kaggle/train_images_jpeg/4167436274.jpg  
  inflating: /content/kaggle/train_images_jpeg/4167938990.jpg  
  inflating: /content/kaggle/train_images_jpeg/4168229813.jpg  
  inflating: /content/kaggle/train_images_jpeg/4168406521.jpg  
  inflating: /content/kaggle/train_images_jpeg/4168463468.jpg  
  inflating: /content/kaggle/train_images_jpeg/4168645136.jpg  
  inflating: /content/kaggle/train_images_jpeg/416874515.jpg  
  inflating: /content/kaggle/train_images_jpeg/4168975711.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169005982.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169071977.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169121477.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169133281.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169428267.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169508703.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169558391.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169577123.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169595131.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169606060.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169747301.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169857735.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169866451.jpg  
  inflating: /content/kaggle/train_images_jpeg/4169894391.jpg  
  inflating: /content/kaggle/train_images_jpeg/4170279280.jpg  
  inflating: /content/kaggle/train_images_jpeg/417059979.jpg  
  inflating: /content/kaggle/train_images_jpeg/4170665280.jpg  
  inflating: /content/kaggle/train_images_jpeg/417083161.jpg  
  inflating: /content/kaggle/train_images_jpeg/4170892667.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171069852.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171083166.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171117342.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171305326.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171327555.jpg  
  inflating: /content/kaggle/train_images_jpeg/417135798.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171363767.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171404904.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171429454.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171468415.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171475132.jpg  
  inflating: /content/kaggle/train_images_jpeg/4171842238.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172116548.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172181287.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172211620.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172221636.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172276292.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172444687.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172480899.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172651490.jpg  
  inflating: /content/kaggle/train_images_jpeg/4172721678.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173133461.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173419470.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173430293.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173509764.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173521076.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173578063.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173585663.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173729579.jpg  
  inflating: /content/kaggle/train_images_jpeg/4173960352.jpg  
  inflating: /content/kaggle/train_images_jpeg/4174034867.jpg  
  inflating: /content/kaggle/train_images_jpeg/4174350664.jpg  
  inflating: /content/kaggle/train_images_jpeg/4174883420.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175172679.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175214629.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175366577.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175374809.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175405033.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175483651.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175723076.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175864678.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175885310.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175951103.jpg  
  inflating: /content/kaggle/train_images_jpeg/4175967929.jpg  
  inflating: /content/kaggle/train_images_jpeg/4176018336.jpg  
  inflating: /content/kaggle/train_images_jpeg/4176445921.jpg  
  inflating: /content/kaggle/train_images_jpeg/4176553783.jpg  
  inflating: /content/kaggle/train_images_jpeg/4176585618.jpg  
  inflating: /content/kaggle/train_images_jpeg/4176726961.jpg  
  inflating: /content/kaggle/train_images_jpeg/4177084912.jpg  
  inflating: /content/kaggle/train_images_jpeg/4177148396.jpg  
  inflating: /content/kaggle/train_images_jpeg/4177200098.jpg  
  inflating: /content/kaggle/train_images_jpeg/417726822.jpg  
  inflating: /content/kaggle/train_images_jpeg/4177391802.jpg  
  inflating: /content/kaggle/train_images_jpeg/4177392079.jpg  
  inflating: /content/kaggle/train_images_jpeg/4177483982.jpg  
  inflating: /content/kaggle/train_images_jpeg/4177519290.jpg  
  inflating: /content/kaggle/train_images_jpeg/4177958446.jpg  
  inflating: /content/kaggle/train_images_jpeg/4178125933.jpg  
  inflating: /content/kaggle/train_images_jpeg/4178245302.jpg  
  inflating: /content/kaggle/train_images_jpeg/417840962.jpg  
  inflating: /content/kaggle/train_images_jpeg/4178594597.jpg  
  inflating: /content/kaggle/train_images_jpeg/4179147529.jpg  
  inflating: /content/kaggle/train_images_jpeg/4179303014.jpg  
  inflating: /content/kaggle/train_images_jpeg/4179442683.jpg  
  inflating: /content/kaggle/train_images_jpeg/4179444530.jpg  
  inflating: /content/kaggle/train_images_jpeg/4179630738.jpg  
  inflating: /content/kaggle/train_images_jpeg/4179735226.jpg  
  inflating: /content/kaggle/train_images_jpeg/4180192243.jpg  
  inflating: /content/kaggle/train_images_jpeg/4180586995.jpg  
  inflating: /content/kaggle/train_images_jpeg/4180626813.jpg  
  inflating: /content/kaggle/train_images_jpeg/4181129288.jpg  
  inflating: /content/kaggle/train_images_jpeg/4181351157.jpg  
  inflating: /content/kaggle/train_images_jpeg/4181746841.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182063113.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182229432.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182496583.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182510325.jpg  
  inflating: /content/kaggle/train_images_jpeg/418261395.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182626844.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182634633.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182646483.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182745953.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182889279.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182898688.jpg  
  inflating: /content/kaggle/train_images_jpeg/4182987199.jpg  
  inflating: /content/kaggle/train_images_jpeg/4183077936.jpg  
  inflating: /content/kaggle/train_images_jpeg/4183078751.jpg  
  inflating: /content/kaggle/train_images_jpeg/4183084622.jpg  
  inflating: /content/kaggle/train_images_jpeg/4183253873.jpg  
  inflating: /content/kaggle/train_images_jpeg/4183312671.jpg  
  inflating: /content/kaggle/train_images_jpeg/418334255.jpg  
  inflating: /content/kaggle/train_images_jpeg/4183847559.jpg  
  inflating: /content/kaggle/train_images_jpeg/4183866544.jpg  
  inflating: /content/kaggle/train_images_jpeg/4183926297.jpg  
  inflating: /content/kaggle/train_images_jpeg/4184062100.jpg  
  inflating: /content/kaggle/train_images_jpeg/4184461961.jpg  
  inflating: /content/kaggle/train_images_jpeg/4184485788.jpg  
  inflating: /content/kaggle/train_images_jpeg/4184902338.jpg  
  inflating: /content/kaggle/train_images_jpeg/4185096944.jpg  
  inflating: /content/kaggle/train_images_jpeg/4185505558.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186416539.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186436193.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186528669.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186603766.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186633206.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186640212.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186680625.jpg  
  inflating: /content/kaggle/train_images_jpeg/418673724.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186901068.jpg  
  inflating: /content/kaggle/train_images_jpeg/4186913818.jpg  
  inflating: /content/kaggle/train_images_jpeg/4187343844.jpg  
  inflating: /content/kaggle/train_images_jpeg/4188111262.jpg  
  inflating: /content/kaggle/train_images_jpeg/4188170872.jpg  
  inflating: /content/kaggle/train_images_jpeg/4188219605.jpg  
  inflating: /content/kaggle/train_images_jpeg/4188255023.jpg  
  inflating: /content/kaggle/train_images_jpeg/4188579631.jpg  
  inflating: /content/kaggle/train_images_jpeg/418911240.jpg  
  inflating: /content/kaggle/train_images_jpeg/4189307730.jpg  
  inflating: /content/kaggle/train_images_jpeg/4189434450.jpg  
  inflating: /content/kaggle/train_images_jpeg/4189463484.jpg  
  inflating: /content/kaggle/train_images_jpeg/4189636250.jpg  
  inflating: /content/kaggle/train_images_jpeg/4189821383.jpg  
  inflating: /content/kaggle/train_images_jpeg/4190467935.jpg  
  inflating: /content/kaggle/train_images_jpeg/4191284579.jpg  
  inflating: /content/kaggle/train_images_jpeg/4191409437.jpg  
  inflating: /content/kaggle/train_images_jpeg/4191778272.jpg  
  inflating: /content/kaggle/train_images_jpeg/4191979346.jpg  
  inflating: /content/kaggle/train_images_jpeg/4192173547.jpg  
  inflating: /content/kaggle/train_images_jpeg/4192202317.jpg  
  inflating: /content/kaggle/train_images_jpeg/4192503187.jpg  
  inflating: /content/kaggle/train_images_jpeg/4192665082.jpg  
  inflating: /content/kaggle/train_images_jpeg/4192717491.jpg  
  inflating: /content/kaggle/train_images_jpeg/4192792225.jpg  
  inflating: /content/kaggle/train_images_jpeg/4192933342.jpg  
  inflating: /content/kaggle/train_images_jpeg/4193039618.jpg  
  inflating: /content/kaggle/train_images_jpeg/4193527713.jpg  
  inflating: /content/kaggle/train_images_jpeg/4193627922.jpg  
  inflating: /content/kaggle/train_images_jpeg/4193821272.jpg  
  inflating: /content/kaggle/train_images_jpeg/4193954616.jpg  
  inflating: /content/kaggle/train_images_jpeg/4194395982.jpg  
  inflating: /content/kaggle/train_images_jpeg/4194767619.jpg  
  inflating: /content/kaggle/train_images_jpeg/4194771487.jpg  
  inflating: /content/kaggle/train_images_jpeg/4194820497.jpg  
  inflating: /content/kaggle/train_images_jpeg/4195040582.jpg  
  inflating: /content/kaggle/train_images_jpeg/4195112641.jpg  
  inflating: /content/kaggle/train_images_jpeg/4195244088.jpg  
  inflating: /content/kaggle/train_images_jpeg/4195466993.jpg  
  inflating: /content/kaggle/train_images_jpeg/4195586692.jpg  
  inflating: /content/kaggle/train_images_jpeg/4195598174.jpg  
  inflating: /content/kaggle/train_images_jpeg/4196010375.jpg  
  inflating: /content/kaggle/train_images_jpeg/4196311493.jpg  
  inflating: /content/kaggle/train_images_jpeg/4196557563.jpg  
  inflating: /content/kaggle/train_images_jpeg/4196856438.jpg  
  inflating: /content/kaggle/train_images_jpeg/4196928486.jpg  
  inflating: /content/kaggle/train_images_jpeg/4196953609.jpg  
  inflating: /content/kaggle/train_images_jpeg/419708385.jpg  
  inflating: /content/kaggle/train_images_jpeg/4197342074.jpg  
  inflating: /content/kaggle/train_images_jpeg/4197537350.jpg  
  inflating: /content/kaggle/train_images_jpeg/4197541916.jpg  
  inflating: /content/kaggle/train_images_jpeg/4197748508.jpg  
  inflating: /content/kaggle/train_images_jpeg/4197924159.jpg  
  inflating: /content/kaggle/train_images_jpeg/4198242632.jpg  
  inflating: /content/kaggle/train_images_jpeg/4198510978.jpg  
  inflating: /content/kaggle/train_images_jpeg/4198716327.jpg  
  inflating: /content/kaggle/train_images_jpeg/4199179186.jpg  
  inflating: /content/kaggle/train_images_jpeg/4199257644.jpg  
  inflating: /content/kaggle/train_images_jpeg/4199323027.jpg  
  inflating: /content/kaggle/train_images_jpeg/4199546662.jpg  
  inflating: /content/kaggle/train_images_jpeg/4199549961.jpg  
  inflating: /content/kaggle/train_images_jpeg/419974195.jpg  
  inflating: /content/kaggle/train_images_jpeg/4200117481.jpg  
  inflating: /content/kaggle/train_images_jpeg/4200249723.jpg  
  inflating: /content/kaggle/train_images_jpeg/4200538063.jpg  
  inflating: /content/kaggle/train_images_jpeg/4200872179.jpg  
  inflating: /content/kaggle/train_images_jpeg/4200880538.jpg  
  inflating: /content/kaggle/train_images_jpeg/4200969502.jpg  
  inflating: /content/kaggle/train_images_jpeg/4201017527.jpg  
  inflating: /content/kaggle/train_images_jpeg/4201154907.jpg  
  inflating: /content/kaggle/train_images_jpeg/4201636225.jpg  
  inflating: /content/kaggle/train_images_jpeg/4201637914.jpg  
  inflating: /content/kaggle/train_images_jpeg/4201965605.jpg  
  inflating: /content/kaggle/train_images_jpeg/4202098451.jpg  
  inflating: /content/kaggle/train_images_jpeg/4202232655.jpg  
  inflating: /content/kaggle/train_images_jpeg/4202339262.jpg  
  inflating: /content/kaggle/train_images_jpeg/4202436858.jpg  
  inflating: /content/kaggle/train_images_jpeg/4202441426.jpg  
  inflating: /content/kaggle/train_images_jpeg/42026505.jpg  
  inflating: /content/kaggle/train_images_jpeg/4203360884.jpg  
  inflating: /content/kaggle/train_images_jpeg/4203623611.jpg  
  inflating: /content/kaggle/train_images_jpeg/4203754534.jpg  
  inflating: /content/kaggle/train_images_jpeg/4203886176.jpg  
  inflating: /content/kaggle/train_images_jpeg/4203927586.jpg  
  inflating: /content/kaggle/train_images_jpeg/4204029505.jpg  
  inflating: /content/kaggle/train_images_jpeg/4204052226.jpg  
  inflating: /content/kaggle/train_images_jpeg/4204435196.jpg  
  inflating: /content/kaggle/train_images_jpeg/4204628073.jpg  
  inflating: /content/kaggle/train_images_jpeg/4204930835.jpg  
  inflating: /content/kaggle/train_images_jpeg/420499628.jpg  
  inflating: /content/kaggle/train_images_jpeg/4205231348.jpg  
  inflating: /content/kaggle/train_images_jpeg/4205256960.jpg  
  inflating: /content/kaggle/train_images_jpeg/4205544766.jpg  
  inflating: /content/kaggle/train_images_jpeg/4205804371.jpg  
  inflating: /content/kaggle/train_images_jpeg/4205935925.jpg  
  inflating: /content/kaggle/train_images_jpeg/4206104015.jpg  
  inflating: /content/kaggle/train_images_jpeg/4206128911.jpg  
  inflating: /content/kaggle/train_images_jpeg/4206288054.jpg  
  inflating: /content/kaggle/train_images_jpeg/420653130.jpg  
  inflating: /content/kaggle/train_images_jpeg/4206587190.jpg  
  inflating: /content/kaggle/train_images_jpeg/4206778919.jpg  
  inflating: /content/kaggle/train_images_jpeg/4206947168.jpg  
  inflating: /content/kaggle/train_images_jpeg/4206993197.jpg  
  inflating: /content/kaggle/train_images_jpeg/4207293267.jpg  
  inflating: /content/kaggle/train_images_jpeg/420749600.jpg  
  inflating: /content/kaggle/train_images_jpeg/4207507257.jpg  
  inflating: /content/kaggle/train_images_jpeg/4207531803.jpg  
  inflating: /content/kaggle/train_images_jpeg/4207597104.jpg  
  inflating: /content/kaggle/train_images_jpeg/4207597254.jpg  
  inflating: /content/kaggle/train_images_jpeg/4207857980.jpg  
  inflating: /content/kaggle/train_images_jpeg/4208333966.jpg  
  inflating: /content/kaggle/train_images_jpeg/4208451715.jpg  
  inflating: /content/kaggle/train_images_jpeg/4208508755.jpg  
  inflating: /content/kaggle/train_images_jpeg/4208715814.jpg  
  inflating: /content/kaggle/train_images_jpeg/4208734427.jpg  
  inflating: /content/kaggle/train_images_jpeg/4209027570.jpg  
  inflating: /content/kaggle/train_images_jpeg/42091153.jpg  
  inflating: /content/kaggle/train_images_jpeg/4209232605.jpg  
  inflating: /content/kaggle/train_images_jpeg/4209575445.jpg  
  inflating: /content/kaggle/train_images_jpeg/4209628430.jpg  
  inflating: /content/kaggle/train_images_jpeg/4209668687.jpg  
  inflating: /content/kaggle/train_images_jpeg/4209715863.jpg  
  inflating: /content/kaggle/train_images_jpeg/4209772803.jpg  
  inflating: /content/kaggle/train_images_jpeg/420979598.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210199349.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210262767.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210272961.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210295166.jpg  
  inflating: /content/kaggle/train_images_jpeg/421035788.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210428578.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210616939.jpg  
  inflating: /content/kaggle/train_images_jpeg/421071700.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210825389.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210831538.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210844423.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210867586.jpg  
  inflating: /content/kaggle/train_images_jpeg/4210957612.jpg  
  inflating: /content/kaggle/train_images_jpeg/4211138249.jpg  
  inflating: /content/kaggle/train_images_jpeg/4211450087.jpg  
  inflating: /content/kaggle/train_images_jpeg/4211652237.jpg  
  inflating: /content/kaggle/train_images_jpeg/4211828884.jpg  
  inflating: /content/kaggle/train_images_jpeg/4211960085.jpg  
  inflating: /content/kaggle/train_images_jpeg/4212247949.jpg  
  inflating: /content/kaggle/train_images_jpeg/4212381540.jpg  
  inflating: /content/kaggle/train_images_jpeg/4212642108.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213060082.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213221330.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213312070.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213411330.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213471018.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213479544.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213496821.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213525466.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213617078.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213734588.jpg  
  inflating: /content/kaggle/train_images_jpeg/4213863678.jpg  
  inflating: /content/kaggle/train_images_jpeg/4214126617.jpg  
  inflating: /content/kaggle/train_images_jpeg/4214231918.jpg  
  inflating: /content/kaggle/train_images_jpeg/4214625845.jpg  
  inflating: /content/kaggle/train_images_jpeg/4214804223.jpg  
  inflating: /content/kaggle/train_images_jpeg/42150813.jpg  
  inflating: /content/kaggle/train_images_jpeg/4215244581.jpg  
  inflating: /content/kaggle/train_images_jpeg/4215295571.jpg  
  inflating: /content/kaggle/train_images_jpeg/4215365960.jpg  
  inflating: /content/kaggle/train_images_jpeg/4215422065.jpg  
  inflating: /content/kaggle/train_images_jpeg/4215590346.jpg  
  inflating: /content/kaggle/train_images_jpeg/4215606048.jpg  
  inflating: /content/kaggle/train_images_jpeg/4215655540.jpg  
  inflating: /content/kaggle/train_images_jpeg/4215887355.jpg  
  inflating: /content/kaggle/train_images_jpeg/4216163881.jpg  
  inflating: /content/kaggle/train_images_jpeg/4216173282.jpg  
  inflating: /content/kaggle/train_images_jpeg/421638370.jpg  
  inflating: /content/kaggle/train_images_jpeg/4217597340.jpg  
  inflating: /content/kaggle/train_images_jpeg/4217871378.jpg  
  inflating: /content/kaggle/train_images_jpeg/4218379987.jpg  
  inflating: /content/kaggle/train_images_jpeg/4218669271.jpg  
  inflating: /content/kaggle/train_images_jpeg/4219325672.jpg  
  inflating: /content/kaggle/train_images_jpeg/4219389723.jpg  
  inflating: /content/kaggle/train_images_jpeg/4219528096.jpg  
  inflating: /content/kaggle/train_images_jpeg/4219779875.jpg  
  inflating: /content/kaggle/train_images_jpeg/4220427697.jpg  
  inflating: /content/kaggle/train_images_jpeg/4220488715.jpg  
  inflating: /content/kaggle/train_images_jpeg/4220602838.jpg  
  inflating: /content/kaggle/train_images_jpeg/4220858043.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221079095.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221104214.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221172112.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221245537.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221337280.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221848010.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221898488.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221918564.jpg  
  inflating: /content/kaggle/train_images_jpeg/4221969635.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222040143.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222242.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222358832.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222447484.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222515459.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222869193.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222895181.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222936048.jpg  
  inflating: /content/kaggle/train_images_jpeg/4222984856.jpg  
  inflating: /content/kaggle/train_images_jpeg/4223217189.jpg  
  inflating: /content/kaggle/train_images_jpeg/4223297410.jpg  
  inflating: /content/kaggle/train_images_jpeg/4223515593.jpg  
  inflating: /content/kaggle/train_images_jpeg/4223598705.jpg  
  inflating: /content/kaggle/train_images_jpeg/4223665750.jpg  
  inflating: /content/kaggle/train_images_jpeg/4223800974.jpg  
  inflating: /content/kaggle/train_images_jpeg/4224082964.jpg  
  inflating: /content/kaggle/train_images_jpeg/4224255718.jpg  
  inflating: /content/kaggle/train_images_jpeg/4224427146.jpg  
  inflating: /content/kaggle/train_images_jpeg/4224453437.jpg  
  inflating: /content/kaggle/train_images_jpeg/4224616597.jpg  
  inflating: /content/kaggle/train_images_jpeg/4224712607.jpg  
  inflating: /content/kaggle/train_images_jpeg/4224873954.jpg  
  inflating: /content/kaggle/train_images_jpeg/4225063396.jpg  
  inflating: /content/kaggle/train_images_jpeg/4225133358.jpg  
  inflating: /content/kaggle/train_images_jpeg/4225259568.jpg  
  inflating: /content/kaggle/train_images_jpeg/4225506393.jpg  
  inflating: /content/kaggle/train_images_jpeg/4225572023.jpg  
  inflating: /content/kaggle/train_images_jpeg/422596234.jpg  
  inflating: /content/kaggle/train_images_jpeg/4226051437.jpg  
  inflating: /content/kaggle/train_images_jpeg/4226241214.jpg  
  inflating: /content/kaggle/train_images_jpeg/422632532.jpg  
  inflating: /content/kaggle/train_images_jpeg/4226417214.jpg  
  inflating: /content/kaggle/train_images_jpeg/422690051.jpg  
  inflating: /content/kaggle/train_images_jpeg/4227424714.jpg  
  inflating: /content/kaggle/train_images_jpeg/422752547.jpg  
  inflating: /content/kaggle/train_images_jpeg/4227613635.jpg  
  inflating: /content/kaggle/train_images_jpeg/4227756572.jpg  
  inflating: /content/kaggle/train_images_jpeg/4228006175.jpg  
  inflating: /content/kaggle/train_images_jpeg/4228467711.jpg  
  inflating: /content/kaggle/train_images_jpeg/4228501282.jpg  
  inflating: /content/kaggle/train_images_jpeg/4228517372.jpg  
  inflating: /content/kaggle/train_images_jpeg/4228621377.jpg  
  inflating: /content/kaggle/train_images_jpeg/4228732666.jpg  
  inflating: /content/kaggle/train_images_jpeg/4228743901.jpg  
  inflating: /content/kaggle/train_images_jpeg/4228769241.jpg  
  inflating: /content/kaggle/train_images_jpeg/42290082.jpg  
  inflating: /content/kaggle/train_images_jpeg/4229009634.jpg  
  inflating: /content/kaggle/train_images_jpeg/4230253873.jpg  
  inflating: /content/kaggle/train_images_jpeg/4230502495.jpg  
  inflating: /content/kaggle/train_images_jpeg/4230605387.jpg  
  inflating: /content/kaggle/train_images_jpeg/4230970262.jpg  
  inflating: /content/kaggle/train_images_jpeg/423114651.jpg  
  inflating: /content/kaggle/train_images_jpeg/4231168569.jpg  
  inflating: /content/kaggle/train_images_jpeg/4231979613.jpg  
  inflating: /content/kaggle/train_images_jpeg/4232363601.jpg  
  inflating: /content/kaggle/train_images_jpeg/423248664.jpg  
  inflating: /content/kaggle/train_images_jpeg/4232654944.jpg  
  inflating: /content/kaggle/train_images_jpeg/423272178.jpg  
  inflating: /content/kaggle/train_images_jpeg/423288187.jpg  
  inflating: /content/kaggle/train_images_jpeg/4232966905.jpg  
  inflating: /content/kaggle/train_images_jpeg/4233314988.jpg  
  inflating: /content/kaggle/train_images_jpeg/4233592574.jpg  
  inflating: /content/kaggle/train_images_jpeg/4233694735.jpg  
  inflating: /content/kaggle/train_images_jpeg/423373963.jpg  
  inflating: /content/kaggle/train_images_jpeg/4233818337.jpg  
  inflating: /content/kaggle/train_images_jpeg/4233882902.jpg  
  inflating: /content/kaggle/train_images_jpeg/4234424797.jpg  
  inflating: /content/kaggle/train_images_jpeg/4234497061.jpg  
  inflating: /content/kaggle/train_images_jpeg/4234605337.jpg  
  inflating: /content/kaggle/train_images_jpeg/4234858756.jpg  
  inflating: /content/kaggle/train_images_jpeg/4235208276.jpg  
  inflating: /content/kaggle/train_images_jpeg/4235664377.jpg  
  inflating: /content/kaggle/train_images_jpeg/4235958385.jpg  
  inflating: /content/kaggle/train_images_jpeg/4236479992.jpg  
  inflating: /content/kaggle/train_images_jpeg/4237027288.jpg  
  inflating: /content/kaggle/train_images_jpeg/4237100244.jpg  
  inflating: /content/kaggle/train_images_jpeg/4237476054.jpg  
  inflating: /content/kaggle/train_images_jpeg/4237501920.jpg  
  inflating: /content/kaggle/train_images_jpeg/423771558.jpg  
  inflating: /content/kaggle/train_images_jpeg/4237851473.jpg  
  inflating: /content/kaggle/train_images_jpeg/4239036041.jpg  
  inflating: /content/kaggle/train_images_jpeg/4239047736.jpg  
  inflating: /content/kaggle/train_images_jpeg/4239074071.jpg  
  inflating: /content/kaggle/train_images_jpeg/423907510.jpg  
  inflating: /content/kaggle/train_images_jpeg/4239164688.jpg  
  inflating: /content/kaggle/train_images_jpeg/4239180232.jpg  
  inflating: /content/kaggle/train_images_jpeg/4239262882.jpg  
  inflating: /content/kaggle/train_images_jpeg/4240036351.jpg  
  inflating: /content/kaggle/train_images_jpeg/4240281500.jpg  
  inflating: /content/kaggle/train_images_jpeg/4240296796.jpg  
  inflating: /content/kaggle/train_images_jpeg/424041602.jpg  
  inflating: /content/kaggle/train_images_jpeg/4240447884.jpg  
  inflating: /content/kaggle/train_images_jpeg/4241010942.jpg  
  inflating: /content/kaggle/train_images_jpeg/4241128101.jpg  
  inflating: /content/kaggle/train_images_jpeg/424168659.jpg  
  inflating: /content/kaggle/train_images_jpeg/4241697639.jpg  
  inflating: /content/kaggle/train_images_jpeg/4241803356.jpg  
  inflating: /content/kaggle/train_images_jpeg/4242194730.jpg  
  inflating: /content/kaggle/train_images_jpeg/4242296013.jpg  
  inflating: /content/kaggle/train_images_jpeg/4242325516.jpg  
  inflating: /content/kaggle/train_images_jpeg/4242340626.jpg  
  inflating: /content/kaggle/train_images_jpeg/424246187.jpg  
  inflating: /content/kaggle/train_images_jpeg/424257956.jpg  
  inflating: /content/kaggle/train_images_jpeg/4242793741.jpg  
  inflating: /content/kaggle/train_images_jpeg/4242899751.jpg  
  inflating: /content/kaggle/train_images_jpeg/4243068188.jpg  
  inflating: /content/kaggle/train_images_jpeg/4243138480.jpg  
  inflating: /content/kaggle/train_images_jpeg/4243169950.jpg  
  inflating: /content/kaggle/train_images_jpeg/4244470722.jpg  
  inflating: /content/kaggle/train_images_jpeg/4244950360.jpg  
  inflating: /content/kaggle/train_images_jpeg/4245177289.jpg  
  inflating: /content/kaggle/train_images_jpeg/424538562.jpg  
  inflating: /content/kaggle/train_images_jpeg/424543130.jpg  
  inflating: /content/kaggle/train_images_jpeg/4245498205.jpg  
  inflating: /content/kaggle/train_images_jpeg/4245562546.jpg  
  inflating: /content/kaggle/train_images_jpeg/4245683638.jpg  
  inflating: /content/kaggle/train_images_jpeg/4245699755.jpg  
  inflating: /content/kaggle/train_images_jpeg/4246064356.jpg  
  inflating: /content/kaggle/train_images_jpeg/4246281634.jpg  
  inflating: /content/kaggle/train_images_jpeg/424650710.jpg  
  inflating: /content/kaggle/train_images_jpeg/424686742.jpg  
  inflating: /content/kaggle/train_images_jpeg/424691365.jpg  
  inflating: /content/kaggle/train_images_jpeg/4246986532.jpg  
  inflating: /content/kaggle/train_images_jpeg/4247295410.jpg  
  inflating: /content/kaggle/train_images_jpeg/4247400003.jpg  
  inflating: /content/kaggle/train_images_jpeg/4247589581.jpg  
  inflating: /content/kaggle/train_images_jpeg/4247710206.jpg  
  inflating: /content/kaggle/train_images_jpeg/4247839780.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248003612.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248062879.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248105895.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248150807.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248249660.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248329912.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248343921.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248695502.jpg  
  inflating: /content/kaggle/train_images_jpeg/4248770671.jpg  
  inflating: /content/kaggle/train_images_jpeg/4249429876.jpg  
  inflating: /content/kaggle/train_images_jpeg/4249694195.jpg  
  inflating: /content/kaggle/train_images_jpeg/4249699505.jpg  
  inflating: /content/kaggle/train_images_jpeg/4249930536.jpg  
  inflating: /content/kaggle/train_images_jpeg/424999624.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250119562.jpg  
  inflating: /content/kaggle/train_images_jpeg/425020385.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250210058.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250231606.jpg  
  inflating: /content/kaggle/train_images_jpeg/425031851.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250418714.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250520416.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250538490.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250554784.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250623520.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250668297.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250729106.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250754910.jpg  
  inflating: /content/kaggle/train_images_jpeg/425082747.jpg  
  inflating: /content/kaggle/train_images_jpeg/4250885951.jpg  
  inflating: /content/kaggle/train_images_jpeg/4251001492.jpg  
  inflating: /content/kaggle/train_images_jpeg/4251271803.jpg  
  inflating: /content/kaggle/train_images_jpeg/4251608120.jpg  
  inflating: /content/kaggle/train_images_jpeg/4251678390.jpg  
  inflating: /content/kaggle/train_images_jpeg/4251933055.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252015282.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252058382.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252095621.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252192689.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252235677.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252236416.jpg  
  inflating: /content/kaggle/train_images_jpeg/425235104.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252410554.jpg  
  inflating: /content/kaggle/train_images_jpeg/425244758.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252535713.jpg  
  inflating: /content/kaggle/train_images_jpeg/4252539994.jpg  
  inflating: /content/kaggle/train_images_jpeg/4253189039.jpg  
  inflating: /content/kaggle/train_images_jpeg/4253520478.jpg  
  inflating: /content/kaggle/train_images_jpeg/4253753819.jpg  
  inflating: /content/kaggle/train_images_jpeg/4253761974.jpg  
  inflating: /content/kaggle/train_images_jpeg/4253799258.jpg  
  inflating: /content/kaggle/train_images_jpeg/425389648.jpg  
  inflating: /content/kaggle/train_images_jpeg/4254213032.jpg  
  inflating: /content/kaggle/train_images_jpeg/4254533142.jpg  
  inflating: /content/kaggle/train_images_jpeg/4254813390.jpg  
  inflating: /content/kaggle/train_images_jpeg/4254971723.jpg  
  inflating: /content/kaggle/train_images_jpeg/4254996610.jpg  
  inflating: /content/kaggle/train_images_jpeg/4255100884.jpg  
  inflating: /content/kaggle/train_images_jpeg/4255196582.jpg  
  inflating: /content/kaggle/train_images_jpeg/4255258797.jpg  
  inflating: /content/kaggle/train_images_jpeg/4255275522.jpg  
  inflating: /content/kaggle/train_images_jpeg/4255452857.jpg  
  inflating: /content/kaggle/train_images_jpeg/4255490685.jpg  
  inflating: /content/kaggle/train_images_jpeg/4255738008.jpg  
  inflating: /content/kaggle/train_images_jpeg/4255843801.jpg  
  inflating: /content/kaggle/train_images_jpeg/4256202412.jpg  
  inflating: /content/kaggle/train_images_jpeg/4256268171.jpg  
  inflating: /content/kaggle/train_images_jpeg/4256542670.jpg  
  inflating: /content/kaggle/train_images_jpeg/4256620425.jpg  
  inflating: /content/kaggle/train_images_jpeg/4256663928.jpg  
  inflating: /content/kaggle/train_images_jpeg/425678500.jpg  
  inflating: /content/kaggle/train_images_jpeg/4256882986.jpg  
  inflating: /content/kaggle/train_images_jpeg/4256968855.jpg  
  inflating: /content/kaggle/train_images_jpeg/4257203192.jpg  
  inflating: /content/kaggle/train_images_jpeg/4257261494.jpg  
  inflating: /content/kaggle/train_images_jpeg/4257577206.jpg  
  inflating: /content/kaggle/train_images_jpeg/4257897572.jpg  
  inflating: /content/kaggle/train_images_jpeg/42586742.jpg  
  inflating: /content/kaggle/train_images_jpeg/4258860412.jpg  
  inflating: /content/kaggle/train_images_jpeg/4258928980.jpg  
  inflating: /content/kaggle/train_images_jpeg/4259637871.jpg  
  inflating: /content/kaggle/train_images_jpeg/425994591.jpg  
  inflating: /content/kaggle/train_images_jpeg/426011031.jpg  
  inflating: /content/kaggle/train_images_jpeg/4260449976.jpg  
  inflating: /content/kaggle/train_images_jpeg/4260526608.jpg  
  inflating: /content/kaggle/train_images_jpeg/4260532551.jpg  
  inflating: /content/kaggle/train_images_jpeg/42609166.jpg  
  inflating: /content/kaggle/train_images_jpeg/4261141445.jpg  
  inflating: /content/kaggle/train_images_jpeg/4261150820.jpg  
  inflating: /content/kaggle/train_images_jpeg/4261199097.jpg  
  inflating: /content/kaggle/train_images_jpeg/426129077.jpg  
  inflating: /content/kaggle/train_images_jpeg/4261378787.jpg  
  inflating: /content/kaggle/train_images_jpeg/4261671268.jpg  
  inflating: /content/kaggle/train_images_jpeg/426170022.jpg  
  inflating: /content/kaggle/train_images_jpeg/4262071206.jpg  
  inflating: /content/kaggle/train_images_jpeg/4262086916.jpg  
  inflating: /content/kaggle/train_images_jpeg/4262259136.jpg  
  inflating: /content/kaggle/train_images_jpeg/4262410116.jpg  
  inflating: /content/kaggle/train_images_jpeg/4262559239.jpg  
  inflating: /content/kaggle/train_images_jpeg/4262567845.jpg  
  inflating: /content/kaggle/train_images_jpeg/4262629224.jpg  
  inflating: /content/kaggle/train_images_jpeg/4262860938.jpg  
  inflating: /content/kaggle/train_images_jpeg/4263534897.jpg  
  inflating: /content/kaggle/train_images_jpeg/4263725317.jpg  
  inflating: /content/kaggle/train_images_jpeg/4263858320.jpg  
  inflating: /content/kaggle/train_images_jpeg/4264274445.jpg  
  inflating: /content/kaggle/train_images_jpeg/426501539.jpg  
  inflating: /content/kaggle/train_images_jpeg/426528709.jpg  
  inflating: /content/kaggle/train_images_jpeg/426530715.jpg  
  inflating: /content/kaggle/train_images_jpeg/4265695955.jpg  
  inflating: /content/kaggle/train_images_jpeg/4265793200.jpg  
  inflating: /content/kaggle/train_images_jpeg/4265846658.jpg  
  inflating: /content/kaggle/train_images_jpeg/4265873256.jpg  
  inflating: /content/kaggle/train_images_jpeg/4266410348.jpg  
  inflating: /content/kaggle/train_images_jpeg/4266856745.jpg  
  inflating: /content/kaggle/train_images_jpeg/4266883021.jpg  
  inflating: /content/kaggle/train_images_jpeg/4266959009.jpg  
  inflating: /content/kaggle/train_images_jpeg/4267085223.jpg  
  inflating: /content/kaggle/train_images_jpeg/4267160725.jpg  
  inflating: /content/kaggle/train_images_jpeg/4267171540.jpg  
  inflating: /content/kaggle/train_images_jpeg/4267414655.jpg  
  inflating: /content/kaggle/train_images_jpeg/4267819868.jpg  
  inflating: /content/kaggle/train_images_jpeg/4267879183.jpg  
  inflating: /content/kaggle/train_images_jpeg/4268211199.jpg  
  inflating: /content/kaggle/train_images_jpeg/4268256477.jpg  
  inflating: /content/kaggle/train_images_jpeg/4268397225.jpg  
  inflating: /content/kaggle/train_images_jpeg/4268549566.jpg  
  inflating: /content/kaggle/train_images_jpeg/42688414.jpg  
  inflating: /content/kaggle/train_images_jpeg/4269113447.jpg  
  inflating: /content/kaggle/train_images_jpeg/4269208386.jpg  
  inflating: /content/kaggle/train_images_jpeg/4269789999.jpg  
  inflating: /content/kaggle/train_images_jpeg/4269823150.jpg  
  inflating: /content/kaggle/train_images_jpeg/4269828095.jpg  
  inflating: /content/kaggle/train_images_jpeg/4269977129.jpg  
  inflating: /content/kaggle/train_images_jpeg/4270123145.jpg  
  inflating: /content/kaggle/train_images_jpeg/4270603433.jpg  
  inflating: /content/kaggle/train_images_jpeg/4270811965.jpg  
  inflating: /content/kaggle/train_images_jpeg/4270972443.jpg  
  inflating: /content/kaggle/train_images_jpeg/4270993331.jpg  
  inflating: /content/kaggle/train_images_jpeg/4271000778.jpg  
  inflating: /content/kaggle/train_images_jpeg/4271208803.jpg  
  inflating: /content/kaggle/train_images_jpeg/4271963761.jpg  
  inflating: /content/kaggle/train_images_jpeg/427201982.jpg  
  inflating: /content/kaggle/train_images_jpeg/427226135.jpg  
  inflating: /content/kaggle/train_images_jpeg/4272507898.jpg  
  inflating: /content/kaggle/train_images_jpeg/4272684860.jpg  
  inflating: /content/kaggle/train_images_jpeg/4272738876.jpg  
  inflating: /content/kaggle/train_images_jpeg/427286737.jpg  
  inflating: /content/kaggle/train_images_jpeg/4272950907.jpg  
  inflating: /content/kaggle/train_images_jpeg/427331923.jpg  
  inflating: /content/kaggle/train_images_jpeg/4273381406.jpg  
  inflating: /content/kaggle/train_images_jpeg/4273424873.jpg  
  inflating: /content/kaggle/train_images_jpeg/4273616869.jpg  
  inflating: /content/kaggle/train_images_jpeg/4273727278.jpg  
  inflating: /content/kaggle/train_images_jpeg/4273998923.jpg  
  inflating: /content/kaggle/train_images_jpeg/4274006379.jpg  
  inflating: /content/kaggle/train_images_jpeg/4274049119.jpg  
  inflating: /content/kaggle/train_images_jpeg/4274564396.jpg  
  inflating: /content/kaggle/train_images_jpeg/4274689672.jpg  
  inflating: /content/kaggle/train_images_jpeg/4274749483.jpg  
  inflating: /content/kaggle/train_images_jpeg/427487173.jpg  
  inflating: /content/kaggle/train_images_jpeg/4275116781.jpg  
  inflating: /content/kaggle/train_images_jpeg/427517931.jpg  
  inflating: /content/kaggle/train_images_jpeg/4275236690.jpg  
  inflating: /content/kaggle/train_images_jpeg/4275245124.jpg  
  inflating: /content/kaggle/train_images_jpeg/4275284230.jpg  
  inflating: /content/kaggle/train_images_jpeg/427529521.jpg  
  inflating: /content/kaggle/train_images_jpeg/4275296346.jpg  
  inflating: /content/kaggle/train_images_jpeg/4275452291.jpg  
  inflating: /content/kaggle/train_images_jpeg/4275645735.jpg  
  inflating: /content/kaggle/train_images_jpeg/4275773216.jpg  
  inflating: /content/kaggle/train_images_jpeg/4276075687.jpg  
  inflating: /content/kaggle/train_images_jpeg/4276437960.jpg  
  inflating: /content/kaggle/train_images_jpeg/4276465485.jpg  
  inflating: /content/kaggle/train_images_jpeg/4276501403.jpg  
  inflating: /content/kaggle/train_images_jpeg/427669101.jpg  
  inflating: /content/kaggle/train_images_jpeg/4276702530.jpg  
  inflating: /content/kaggle/train_images_jpeg/4276709796.jpg  
  inflating: /content/kaggle/train_images_jpeg/4276754883.jpg  
  inflating: /content/kaggle/train_images_jpeg/4276789803.jpg  
  inflating: /content/kaggle/train_images_jpeg/4277021360.jpg  
  inflating: /content/kaggle/train_images_jpeg/4277157912.jpg  
  inflating: /content/kaggle/train_images_jpeg/4277201548.jpg  
  inflating: /content/kaggle/train_images_jpeg/4277213356.jpg  
  inflating: /content/kaggle/train_images_jpeg/4277729347.jpg  
  inflating: /content/kaggle/train_images_jpeg/427782419.jpg  
  inflating: /content/kaggle/train_images_jpeg/4278159410.jpg  
  inflating: /content/kaggle/train_images_jpeg/4278290945.jpg  
  inflating: /content/kaggle/train_images_jpeg/4278349650.jpg  
  inflating: /content/kaggle/train_images_jpeg/4278355555.jpg  
  inflating: /content/kaggle/train_images_jpeg/4278469660.jpg  
  inflating: /content/kaggle/train_images_jpeg/4278686402.jpg  
  inflating: /content/kaggle/train_images_jpeg/4278878757.jpg  
  inflating: /content/kaggle/train_images_jpeg/4279143511.jpg  
  inflating: /content/kaggle/train_images_jpeg/4279177464.jpg  
  inflating: /content/kaggle/train_images_jpeg/4279248558.jpg  
  inflating: /content/kaggle/train_images_jpeg/4279337211.jpg  
  inflating: /content/kaggle/train_images_jpeg/4279357084.jpg  
  inflating: /content/kaggle/train_images_jpeg/4279465930.jpg  
  inflating: /content/kaggle/train_images_jpeg/4279471194.jpg  
  inflating: /content/kaggle/train_images_jpeg/4279868467.jpg  
  inflating: /content/kaggle/train_images_jpeg/4280091186.jpg  
  inflating: /content/kaggle/train_images_jpeg/4280523848.jpg  
  inflating: /content/kaggle/train_images_jpeg/4280698838.jpg  
  inflating: /content/kaggle/train_images_jpeg/4280760906.jpg  
  inflating: /content/kaggle/train_images_jpeg/4280947903.jpg  
  inflating: /content/kaggle/train_images_jpeg/4281502207.jpg  
  inflating: /content/kaggle/train_images_jpeg/4281504647.jpg  
  inflating: /content/kaggle/train_images_jpeg/4281654118.jpg  
  inflating: /content/kaggle/train_images_jpeg/428166614.jpg  
  inflating: /content/kaggle/train_images_jpeg/4282010677.jpg  
  inflating: /content/kaggle/train_images_jpeg/4282408832.jpg  
  inflating: /content/kaggle/train_images_jpeg/4282442229.jpg  
  inflating: /content/kaggle/train_images_jpeg/4282530176.jpg  
  inflating: /content/kaggle/train_images_jpeg/4282727554.jpg  
  inflating: /content/kaggle/train_images_jpeg/4282894767.jpg  
  inflating: /content/kaggle/train_images_jpeg/4282908664.jpg  
  inflating: /content/kaggle/train_images_jpeg/4283054120.jpg  
  inflating: /content/kaggle/train_images_jpeg/4283076582.jpg  
  inflating: /content/kaggle/train_images_jpeg/4283270414.jpg  
  inflating: /content/kaggle/train_images_jpeg/4283277874.jpg  
  inflating: /content/kaggle/train_images_jpeg/4283521063.jpg  
  inflating: /content/kaggle/train_images_jpeg/4284057693.jpg  
  inflating: /content/kaggle/train_images_jpeg/4284191566.jpg  
  inflating: /content/kaggle/train_images_jpeg/4284260544.jpg  
  inflating: /content/kaggle/train_images_jpeg/4284398134.jpg  
  inflating: /content/kaggle/train_images_jpeg/4284426558.jpg  
  inflating: /content/kaggle/train_images_jpeg/4284428305.jpg  
  inflating: /content/kaggle/train_images_jpeg/4284674042.jpg  
  inflating: /content/kaggle/train_images_jpeg/4284813323.jpg  
  inflating: /content/kaggle/train_images_jpeg/4285226176.jpg  
  inflating: /content/kaggle/train_images_jpeg/4285379899.jpg  
  inflating: /content/kaggle/train_images_jpeg/4285401686.jpg  
  inflating: /content/kaggle/train_images_jpeg/4285755413.jpg  
  inflating: /content/kaggle/train_images_jpeg/4286158151.jpg  
  inflating: /content/kaggle/train_images_jpeg/4286169099.jpg  
  inflating: /content/kaggle/train_images_jpeg/4286174060.jpg  
  inflating: /content/kaggle/train_images_jpeg/4286239894.jpg  
  inflating: /content/kaggle/train_images_jpeg/4286284700.jpg  
  inflating: /content/kaggle/train_images_jpeg/428641617.jpg  
  inflating: /content/kaggle/train_images_jpeg/4286577227.jpg  
  inflating: /content/kaggle/train_images_jpeg/4286700834.jpg  
  inflating: /content/kaggle/train_images_jpeg/428692692.jpg  
  inflating: /content/kaggle/train_images_jpeg/4287033165.jpg  
  inflating: /content/kaggle/train_images_jpeg/4287071486.jpg  
  inflating: /content/kaggle/train_images_jpeg/428725949.jpg  
  inflating: /content/kaggle/train_images_jpeg/4287278405.jpg  
  inflating: /content/kaggle/train_images_jpeg/4287286739.jpg  
  inflating: /content/kaggle/train_images_jpeg/4287369745.jpg  
  inflating: /content/kaggle/train_images_jpeg/4287423419.jpg  
  inflating: /content/kaggle/train_images_jpeg/4287448555.jpg  
  inflating: /content/kaggle/train_images_jpeg/4287820275.jpg  
  inflating: /content/kaggle/train_images_jpeg/4288246700.jpg  
  inflating: /content/kaggle/train_images_jpeg/4288249349.jpg  
  inflating: /content/kaggle/train_images_jpeg/4288369732.jpg  
  inflating: /content/kaggle/train_images_jpeg/4288418406.jpg  
  inflating: /content/kaggle/train_images_jpeg/4288554103.jpg  
  inflating: /content/kaggle/train_images_jpeg/4289523242.jpg  
  inflating: /content/kaggle/train_images_jpeg/4289669666.jpg  
  inflating: /content/kaggle/train_images_jpeg/4290607578.jpg  
  inflating: /content/kaggle/train_images_jpeg/429071612.jpg  
  inflating: /content/kaggle/train_images_jpeg/4290786696.jpg  
  inflating: /content/kaggle/train_images_jpeg/4290827656.jpg  
  inflating: /content/kaggle/train_images_jpeg/4290868604.jpg  
  inflating: /content/kaggle/train_images_jpeg/4290883718.jpg  
  inflating: /content/kaggle/train_images_jpeg/4291020124.jpg  
  inflating: /content/kaggle/train_images_jpeg/4291517626.jpg  
  inflating: /content/kaggle/train_images_jpeg/4291622548.jpg  
  inflating: /content/kaggle/train_images_jpeg/4291798124.jpg  
  inflating: /content/kaggle/train_images_jpeg/4291850520.jpg  
  inflating: /content/kaggle/train_images_jpeg/4291924776.jpg  
  inflating: /content/kaggle/train_images_jpeg/429193832.jpg  
  inflating: /content/kaggle/train_images_jpeg/4291943687.jpg  
  inflating: /content/kaggle/train_images_jpeg/4292043437.jpg  
  inflating: /content/kaggle/train_images_jpeg/4292224219.jpg  
  inflating: /content/kaggle/train_images_jpeg/4292271303.jpg  
  inflating: /content/kaggle/train_images_jpeg/429230321.jpg  
  inflating: /content/kaggle/train_images_jpeg/4292333499.jpg  
  inflating: /content/kaggle/train_images_jpeg/4292377658.jpg  
  inflating: /content/kaggle/train_images_jpeg/4292386497.jpg  
  inflating: /content/kaggle/train_images_jpeg/4292850114.jpg  
  inflating: /content/kaggle/train_images_jpeg/4292988075.jpg  
  inflating: /content/kaggle/train_images_jpeg/4293129441.jpg  
  inflating: /content/kaggle/train_images_jpeg/4293589004.jpg  
  inflating: /content/kaggle/train_images_jpeg/4293661491.jpg  
  inflating: /content/kaggle/train_images_jpeg/4293817306.jpg  
  inflating: /content/kaggle/train_images_jpeg/4293860103.jpg  
  inflating: /content/kaggle/train_images_jpeg/429424915.jpg  
  inflating: /content/kaggle/train_images_jpeg/4294756187.jpg  
  inflating: /content/kaggle/train_images_jpeg/42968835.jpg  
  inflating: /content/kaggle/train_images_jpeg/429832892.jpg  
  inflating: /content/kaggle/train_images_jpeg/429982747.jpg  
  inflating: /content/kaggle/train_images_jpeg/430094135.jpg  
  inflating: /content/kaggle/train_images_jpeg/430916626.jpg  
  inflating: /content/kaggle/train_images_jpeg/431233168.jpg  
  inflating: /content/kaggle/train_images_jpeg/431411749.jpg  
  inflating: /content/kaggle/train_images_jpeg/431419127.jpg  
  inflating: /content/kaggle/train_images_jpeg/431535307.jpg  
  inflating: /content/kaggle/train_images_jpeg/431731696.jpg  
  inflating: /content/kaggle/train_images_jpeg/431851340.jpg  
  inflating: /content/kaggle/train_images_jpeg/431956415.jpg  
  inflating: /content/kaggle/train_images_jpeg/432302938.jpg  
  inflating: /content/kaggle/train_images_jpeg/432371484.jpg  
  inflating: /content/kaggle/train_images_jpeg/432428117.jpg  
  inflating: /content/kaggle/train_images_jpeg/432656934.jpg  
  inflating: /content/kaggle/train_images_jpeg/43315915.jpg  
  inflating: /content/kaggle/train_images_jpeg/433273878.jpg  
  inflating: /content/kaggle/train_images_jpeg/433569439.jpg  
  inflating: /content/kaggle/train_images_jpeg/433676551.jpg  
  inflating: /content/kaggle/train_images_jpeg/43400769.jpg  
  inflating: /content/kaggle/train_images_jpeg/434025087.jpg  
  inflating: /content/kaggle/train_images_jpeg/434128804.jpg  
  inflating: /content/kaggle/train_images_jpeg/434367485.jpg  
  inflating: /content/kaggle/train_images_jpeg/434900248.jpg  
  inflating: /content/kaggle/train_images_jpeg/435059376.jpg  
  inflating: /content/kaggle/train_images_jpeg/435094576.jpg  
  inflating: /content/kaggle/train_images_jpeg/43523745.jpg  
  inflating: /content/kaggle/train_images_jpeg/435303871.jpg  
  inflating: /content/kaggle/train_images_jpeg/435404397.jpg  
  inflating: /content/kaggle/train_images_jpeg/435467528.jpg  
  inflating: /content/kaggle/train_images_jpeg/435476831.jpg  
  inflating: /content/kaggle/train_images_jpeg/4359365.jpg  
  inflating: /content/kaggle/train_images_jpeg/435951726.jpg  
  inflating: /content/kaggle/train_images_jpeg/435952255.jpg  
  inflating: /content/kaggle/train_images_jpeg/436004250.jpg  
  inflating: /content/kaggle/train_images_jpeg/436011038.jpg  
  inflating: /content/kaggle/train_images_jpeg/436031847.jpg  
  inflating: /content/kaggle/train_images_jpeg/436314229.jpg  
  inflating: /content/kaggle/train_images_jpeg/4365857.jpg  
  inflating: /content/kaggle/train_images_jpeg/436868168.jpg  
  inflating: /content/kaggle/train_images_jpeg/437121347.jpg  
  inflating: /content/kaggle/train_images_jpeg/43727066.jpg  
  inflating: /content/kaggle/train_images_jpeg/437398008.jpg  
  inflating: /content/kaggle/train_images_jpeg/437629432.jpg  
  inflating: /content/kaggle/train_images_jpeg/437673562.jpg  
  inflating: /content/kaggle/train_images_jpeg/437931902.jpg  
  inflating: /content/kaggle/train_images_jpeg/437958298.jpg  
  inflating: /content/kaggle/train_images_jpeg/438095815.jpg  
  inflating: /content/kaggle/train_images_jpeg/438286664.jpg  
  inflating: /content/kaggle/train_images_jpeg/438352262.jpg  
  inflating: /content/kaggle/train_images_jpeg/438557972.jpg  
  inflating: /content/kaggle/train_images_jpeg/439049574.jpg  
  inflating: /content/kaggle/train_images_jpeg/439346642.jpg  
  inflating: /content/kaggle/train_images_jpeg/43958226.jpg  
  inflating: /content/kaggle/train_images_jpeg/439915243.jpg  
  inflating: /content/kaggle/train_images_jpeg/440064041.jpg  
  inflating: /content/kaggle/train_images_jpeg/440065824.jpg  
  inflating: /content/kaggle/train_images_jpeg/440608001.jpg  
  inflating: /content/kaggle/train_images_jpeg/440896922.jpg  
  inflating: /content/kaggle/train_images_jpeg/441313044.jpg  
  inflating: /content/kaggle/train_images_jpeg/441408374.jpg  
  inflating: /content/kaggle/train_images_jpeg/441501298.jpg  
  inflating: /content/kaggle/train_images_jpeg/441540366.jpg  
  inflating: /content/kaggle/train_images_jpeg/441579945.jpg  
  inflating: /content/kaggle/train_images_jpeg/441630949.jpg  
  inflating: /content/kaggle/train_images_jpeg/442164564.jpg  
  inflating: /content/kaggle/train_images_jpeg/442172384.jpg  
  inflating: /content/kaggle/train_images_jpeg/442179764.jpg  
  inflating: /content/kaggle/train_images_jpeg/442207015.jpg  
  inflating: /content/kaggle/train_images_jpeg/442386946.jpg  
  inflating: /content/kaggle/train_images_jpeg/442397332.jpg  
  inflating: /content/kaggle/train_images_jpeg/442454672.jpg  
  inflating: /content/kaggle/train_images_jpeg/442646143.jpg  
  inflating: /content/kaggle/train_images_jpeg/442743040.jpg  
  inflating: /content/kaggle/train_images_jpeg/442743258.jpg  
  inflating: /content/kaggle/train_images_jpeg/442849128.jpg  
  inflating: /content/kaggle/train_images_jpeg/442906284.jpg  
  inflating: /content/kaggle/train_images_jpeg/442989383.jpg  
  inflating: /content/kaggle/train_images_jpeg/443211656.jpg  
  inflating: /content/kaggle/train_images_jpeg/443215881.jpg  
  inflating: /content/kaggle/train_images_jpeg/443656391.jpg  
  inflating: /content/kaggle/train_images_jpeg/443817384.jpg  
  inflating: /content/kaggle/train_images_jpeg/444154867.jpg  
  inflating: /content/kaggle/train_images_jpeg/444416814.jpg  
  inflating: /content/kaggle/train_images_jpeg/444631842.jpg  
  inflating: /content/kaggle/train_images_jpeg/444715052.jpg  
  inflating: /content/kaggle/train_images_jpeg/445058593.jpg  
  inflating: /content/kaggle/train_images_jpeg/445321069.jpg  
  inflating: /content/kaggle/train_images_jpeg/445341591.jpg  
  inflating: /content/kaggle/train_images_jpeg/445689900.jpg  
  inflating: /content/kaggle/train_images_jpeg/445879019.jpg  
  inflating: /content/kaggle/train_images_jpeg/446451403.jpg  
  inflating: /content/kaggle/train_images_jpeg/446511089.jpg  
  inflating: /content/kaggle/train_images_jpeg/446546740.jpg  
  inflating: /content/kaggle/train_images_jpeg/446547261.jpg  
  inflating: /content/kaggle/train_images_jpeg/446585225.jpg  
  inflating: /content/kaggle/train_images_jpeg/446913360.jpg  
  inflating: /content/kaggle/train_images_jpeg/446986430.jpg  
  inflating: /content/kaggle/train_images_jpeg/447048984.jpg  
  inflating: /content/kaggle/train_images_jpeg/447053671.jpg  
  inflating: /content/kaggle/train_images_jpeg/447327937.jpg  
  inflating: /content/kaggle/train_images_jpeg/447702060.jpg  
  inflating: /content/kaggle/train_images_jpeg/44779769.jpg  
  inflating: /content/kaggle/train_images_jpeg/447826793.jpg  
  inflating: /content/kaggle/train_images_jpeg/447847284.jpg  
  inflating: /content/kaggle/train_images_jpeg/44786547.jpg  
  inflating: /content/kaggle/train_images_jpeg/448026259.jpg  
  inflating: /content/kaggle/train_images_jpeg/448572806.jpg  
  inflating: /content/kaggle/train_images_jpeg/448840430.jpg  
  inflating: /content/kaggle/train_images_jpeg/448853755.jpg  
  inflating: /content/kaggle/train_images_jpeg/449389274.jpg  
  inflating: /content/kaggle/train_images_jpeg/449531366.jpg  
  inflating: /content/kaggle/train_images_jpeg/450167036.jpg  
  inflating: /content/kaggle/train_images_jpeg/450217405.jpg  
  inflating: /content/kaggle/train_images_jpeg/450239051.jpg  
  inflating: /content/kaggle/train_images_jpeg/450609144.jpg  
  inflating: /content/kaggle/train_images_jpeg/451058398.jpg  
  inflating: /content/kaggle/train_images_jpeg/451261982.jpg  
  inflating: /content/kaggle/train_images_jpeg/451285147.jpg  
  inflating: /content/kaggle/train_images_jpeg/451431780.jpg  
  inflating: /content/kaggle/train_images_jpeg/451433123.jpg  
  inflating: /content/kaggle/train_images_jpeg/45143723.jpg  
  inflating: /content/kaggle/train_images_jpeg/451482977.jpg  
  inflating: /content/kaggle/train_images_jpeg/451500275.jpg  
  inflating: /content/kaggle/train_images_jpeg/451532153.jpg  
  inflating: /content/kaggle/train_images_jpeg/451612458.jpg  
  inflating: /content/kaggle/train_images_jpeg/451825559.jpg  
  inflating: /content/kaggle/train_images_jpeg/451922996.jpg  
  inflating: /content/kaggle/train_images_jpeg/4522938.jpg  
  inflating: /content/kaggle/train_images_jpeg/452327589.jpg  
  inflating: /content/kaggle/train_images_jpeg/452338583.jpg  
  inflating: /content/kaggle/train_images_jpeg/452351258.jpg  
  inflating: /content/kaggle/train_images_jpeg/452420525.jpg  
  inflating: /content/kaggle/train_images_jpeg/452781312.jpg  
  inflating: /content/kaggle/train_images_jpeg/454183787.jpg  
  inflating: /content/kaggle/train_images_jpeg/454246300.jpg  
  inflating: /content/kaggle/train_images_jpeg/454637792.jpg  
  inflating: /content/kaggle/train_images_jpeg/454710225.jpg  
  inflating: /content/kaggle/train_images_jpeg/454771505.jpg  
  inflating: /content/kaggle/train_images_jpeg/4551119.jpg  
  inflating: /content/kaggle/train_images_jpeg/455136283.jpg  
  inflating: /content/kaggle/train_images_jpeg/455188005.jpg  
  inflating: /content/kaggle/train_images_jpeg/455328033.jpg  
  inflating: /content/kaggle/train_images_jpeg/455503561.jpg  
  inflating: /content/kaggle/train_images_jpeg/455970803.jpg  
  inflating: /content/kaggle/train_images_jpeg/456001532.jpg  
  inflating: /content/kaggle/train_images_jpeg/456107080.jpg  
  inflating: /content/kaggle/train_images_jpeg/456224979.jpg  
  inflating: /content/kaggle/train_images_jpeg/456278844.jpg  
  inflating: /content/kaggle/train_images_jpeg/456464390.jpg  
  inflating: /content/kaggle/train_images_jpeg/456647345.jpg  
  inflating: /content/kaggle/train_images_jpeg/456963939.jpg  
  inflating: /content/kaggle/train_images_jpeg/457102375.jpg  
  inflating: /content/kaggle/train_images_jpeg/457376738.jpg  
  inflating: /content/kaggle/train_images_jpeg/457405364.jpg  
  inflating: /content/kaggle/train_images_jpeg/457446390.jpg  
  inflating: /content/kaggle/train_images_jpeg/45753456.jpg  
  inflating: /content/kaggle/train_images_jpeg/45787177.jpg  
  inflating: /content/kaggle/train_images_jpeg/457931044.jpg  
  inflating: /content/kaggle/train_images_jpeg/457946090.jpg  
  inflating: /content/kaggle/train_images_jpeg/457979538.jpg  
  inflating: /content/kaggle/train_images_jpeg/458078692.jpg  
  inflating: /content/kaggle/train_images_jpeg/458083471.jpg  
  inflating: /content/kaggle/train_images_jpeg/458086405.jpg  
  inflating: /content/kaggle/train_images_jpeg/458113547.jpg  
  inflating: /content/kaggle/train_images_jpeg/458279026.jpg  
  inflating: /content/kaggle/train_images_jpeg/458282782.jpg  
  inflating: /content/kaggle/train_images_jpeg/458696690.jpg  
  inflating: /content/kaggle/train_images_jpeg/458698920.jpg  
  inflating: /content/kaggle/train_images_jpeg/459018171.jpg  
  inflating: /content/kaggle/train_images_jpeg/459025811.jpg  
  inflating: /content/kaggle/train_images_jpeg/459069338.jpg  
  inflating: /content/kaggle/train_images_jpeg/459155800.jpg  
  inflating: /content/kaggle/train_images_jpeg/459183399.jpg  
  inflating: /content/kaggle/train_images_jpeg/459241736.jpg  
  inflating: /content/kaggle/train_images_jpeg/459331011.jpg  
  inflating: /content/kaggle/train_images_jpeg/459566103.jpg  
  inflating: /content/kaggle/train_images_jpeg/459566440.jpg  
  inflating: /content/kaggle/train_images_jpeg/459715600.jpg  
  inflating: /content/kaggle/train_images_jpeg/459727273.jpg  
  inflating: /content/kaggle/train_images_jpeg/459889345.jpg  
  inflating: /content/kaggle/train_images_jpeg/460359141.jpg  
  inflating: /content/kaggle/train_images_jpeg/460660800.jpg  
  inflating: /content/kaggle/train_images_jpeg/460695084.jpg  
  inflating: /content/kaggle/train_images_jpeg/46087551.jpg  
  inflating: /content/kaggle/train_images_jpeg/460888118.jpg  
  inflating: /content/kaggle/train_images_jpeg/461042131.jpg  
  inflating: /content/kaggle/train_images_jpeg/461442834.jpg  
  inflating: /content/kaggle/train_images_jpeg/461505973.jpg  
  inflating: /content/kaggle/train_images_jpeg/461517299.jpg  
  inflating: /content/kaggle/train_images_jpeg/461574055.jpg  
  inflating: /content/kaggle/train_images_jpeg/461654762.jpg  
  inflating: /content/kaggle/train_images_jpeg/462009251.jpg  
  inflating: /content/kaggle/train_images_jpeg/462053910.jpg  
  inflating: /content/kaggle/train_images_jpeg/462079305.jpg  
  inflating: /content/kaggle/train_images_jpeg/462192848.jpg  
  inflating: /content/kaggle/train_images_jpeg/462402577.jpg  
  inflating: /content/kaggle/train_images_jpeg/462491927.jpg  
  inflating: /content/kaggle/train_images_jpeg/462652564.jpg  
  inflating: /content/kaggle/train_images_jpeg/462768820.jpg  
  inflating: /content/kaggle/train_images_jpeg/462938008.jpg  
  inflating: /content/kaggle/train_images_jpeg/463033778.jpg  
  inflating: /content/kaggle/train_images_jpeg/463306990.jpg  
  inflating: /content/kaggle/train_images_jpeg/463752462.jpg  
  inflating: /content/kaggle/train_images_jpeg/463938223.jpg  
  inflating: /content/kaggle/train_images_jpeg/464089326.jpg  
  inflating: /content/kaggle/train_images_jpeg/464249040.jpg  
  inflating: /content/kaggle/train_images_jpeg/464299112.jpg  
  inflating: /content/kaggle/train_images_jpeg/464335035.jpg  
  inflating: /content/kaggle/train_images_jpeg/46435039.jpg  
  inflating: /content/kaggle/train_images_jpeg/464695635.jpg  
  inflating: /content/kaggle/train_images_jpeg/465394840.jpg  
  inflating: /content/kaggle/train_images_jpeg/465786805.jpg  
  inflating: /content/kaggle/train_images_jpeg/466394178.jpg  
  inflating: /content/kaggle/train_images_jpeg/466665230.jpg  
  inflating: /content/kaggle/train_images_jpeg/466809222.jpg  
  inflating: /content/kaggle/train_images_jpeg/467000681.jpg  
  inflating: /content/kaggle/train_images_jpeg/467037759.jpg  
  inflating: /content/kaggle/train_images_jpeg/467561327.jpg  
  inflating: /content/kaggle/train_images_jpeg/467965750.jpg  
  inflating: /content/kaggle/train_images_jpeg/468599121.jpg  
  inflating: /content/kaggle/train_images_jpeg/469109506.jpg  
  inflating: /content/kaggle/train_images_jpeg/469245584.jpg  
  inflating: /content/kaggle/train_images_jpeg/469487.jpg  
  inflating: /content/kaggle/train_images_jpeg/469514672.jpg  
  inflating: /content/kaggle/train_images_jpeg/469559658.jpg  
  inflating: /content/kaggle/train_images_jpeg/469627647.jpg  
  inflating: /content/kaggle/train_images_jpeg/469651575.jpg  
  inflating: /content/kaggle/train_images_jpeg/46965268.jpg  
  inflating: /content/kaggle/train_images_jpeg/469662229.jpg  
  inflating: /content/kaggle/train_images_jpeg/469729622.jpg  
  inflating: /content/kaggle/train_images_jpeg/469774939.jpg  
  inflating: /content/kaggle/train_images_jpeg/469798275.jpg  
  inflating: /content/kaggle/train_images_jpeg/470010237.jpg  
  inflating: /content/kaggle/train_images_jpeg/470266437.jpg  
  inflating: /content/kaggle/train_images_jpeg/470378049.jpg  
  inflating: /content/kaggle/train_images_jpeg/470635054.jpg  
  inflating: /content/kaggle/train_images_jpeg/471126071.jpg  
  inflating: /content/kaggle/train_images_jpeg/471570254.jpg  
  inflating: /content/kaggle/train_images_jpeg/471647021.jpg  
  inflating: /content/kaggle/train_images_jpeg/471719560.jpg  
  inflating: /content/kaggle/train_images_jpeg/471733925.jpg  
  inflating: /content/kaggle/train_images_jpeg/471759171.jpg  
  inflating: /content/kaggle/train_images_jpeg/471808107.jpg  
  inflating: /content/kaggle/train_images_jpeg/471996434.jpg  
  inflating: /content/kaggle/train_images_jpeg/472269630.jpg  
  inflating: /content/kaggle/train_images_jpeg/472300747.jpg  
  inflating: /content/kaggle/train_images_jpeg/472370398.jpg  
  inflating: /content/kaggle/train_images_jpeg/472465250.jpg  
  inflating: /content/kaggle/train_images_jpeg/472489554.jpg  
  inflating: /content/kaggle/train_images_jpeg/472536044.jpg  
  inflating: /content/kaggle/train_images_jpeg/472839300.jpg  
  inflating: /content/kaggle/train_images_jpeg/473238027.jpg  
  inflating: /content/kaggle/train_images_jpeg/473358865.jpg  
  inflating: /content/kaggle/train_images_jpeg/473737593.jpg  
  inflating: /content/kaggle/train_images_jpeg/473806024.jpg  
  inflating: /content/kaggle/train_images_jpeg/473823142.jpg  
  inflating: /content/kaggle/train_images_jpeg/473895860.jpg  
  inflating: /content/kaggle/train_images_jpeg/473941755.jpg  
  inflating: /content/kaggle/train_images_jpeg/474097045.jpg  
  inflating: /content/kaggle/train_images_jpeg/474493920.jpg  
  inflating: /content/kaggle/train_images_jpeg/475006659.jpg  
  inflating: /content/kaggle/train_images_jpeg/475084135.jpg  
  inflating: /content/kaggle/train_images_jpeg/475097203.jpg  
  inflating: /content/kaggle/train_images_jpeg/475228141.jpg  
  inflating: /content/kaggle/train_images_jpeg/475418863.jpg  
  inflating: /content/kaggle/train_images_jpeg/475593787.jpg  
  inflating: /content/kaggle/train_images_jpeg/475756576.jpg  
  inflating: /content/kaggle/train_images_jpeg/476012362.jpg  
  inflating: /content/kaggle/train_images_jpeg/476113846.jpg  
  inflating: /content/kaggle/train_images_jpeg/476295659.jpg  
  inflating: /content/kaggle/train_images_jpeg/476297006.jpg  
  inflating: /content/kaggle/train_images_jpeg/476487552.jpg  
  inflating: /content/kaggle/train_images_jpeg/476858432.jpg  
  inflating: /content/kaggle/train_images_jpeg/477466097.jpg  
  inflating: /content/kaggle/train_images_jpeg/477484606.jpg  
  inflating: /content/kaggle/train_images_jpeg/477523981.jpg  
  inflating: /content/kaggle/train_images_jpeg/477888939.jpg  
  inflating: /content/kaggle/train_images_jpeg/478036306.jpg  
  inflating: /content/kaggle/train_images_jpeg/478370518.jpg  
  inflating: /content/kaggle/train_images_jpeg/478400081.jpg  
  inflating: /content/kaggle/train_images_jpeg/478426425.jpg  
  inflating: /content/kaggle/train_images_jpeg/4785038.jpg  
  inflating: /content/kaggle/train_images_jpeg/478546048.jpg  
  inflating: /content/kaggle/train_images_jpeg/478554372.jpg  
  inflating: /content/kaggle/train_images_jpeg/478676678.jpg  
  inflating: /content/kaggle/train_images_jpeg/478688374.jpg  
  inflating: /content/kaggle/train_images_jpeg/478757157.jpg  
  inflating: /content/kaggle/train_images_jpeg/478838530.jpg  
  inflating: /content/kaggle/train_images_jpeg/479283253.jpg  
  inflating: /content/kaggle/train_images_jpeg/479472063.jpg  
  inflating: /content/kaggle/train_images_jpeg/479609263.jpg  
  inflating: /content/kaggle/train_images_jpeg/479659706.jpg  
  inflating: /content/kaggle/train_images_jpeg/479691451.jpg  
  inflating: /content/kaggle/train_images_jpeg/480419575.jpg  
  inflating: /content/kaggle/train_images_jpeg/480420375.jpg  
  inflating: /content/kaggle/train_images_jpeg/480492521.jpg  
  inflating: /content/kaggle/train_images_jpeg/480754210.jpg  
  inflating: /content/kaggle/train_images_jpeg/480764320.jpg  
  inflating: /content/kaggle/train_images_jpeg/480985864.jpg  
  inflating: /content/kaggle/train_images_jpeg/48105658.jpg  
  inflating: /content/kaggle/train_images_jpeg/481101110.jpg  
  inflating: /content/kaggle/train_images_jpeg/481152398.jpg  
  inflating: /content/kaggle/train_images_jpeg/481202063.jpg  
  inflating: /content/kaggle/train_images_jpeg/48153077.jpg  
  inflating: /content/kaggle/train_images_jpeg/481585072.jpg  
  inflating: /content/kaggle/train_images_jpeg/481972599.jpg  
  inflating: /content/kaggle/train_images_jpeg/482191440.jpg  
  inflating: /content/kaggle/train_images_jpeg/482335767.jpg  
  inflating: /content/kaggle/train_images_jpeg/482396705.jpg  
  inflating: /content/kaggle/train_images_jpeg/482843238.jpg  
  inflating: /content/kaggle/train_images_jpeg/483058921.jpg  
  inflating: /content/kaggle/train_images_jpeg/483070348.jpg  
  inflating: /content/kaggle/train_images_jpeg/483132634.jpg  
  inflating: /content/kaggle/train_images_jpeg/483199386.jpg  
  inflating: /content/kaggle/train_images_jpeg/483210216.jpg  
  inflating: /content/kaggle/train_images_jpeg/483372035.jpg  
  inflating: /content/kaggle/train_images_jpeg/483398598.jpg  
  inflating: /content/kaggle/train_images_jpeg/483417793.jpg  
  inflating: /content/kaggle/train_images_jpeg/483725147.jpg  
  inflating: /content/kaggle/train_images_jpeg/483774797.jpg  
  inflating: /content/kaggle/train_images_jpeg/483986538.jpg  
  inflating: /content/kaggle/train_images_jpeg/484161659.jpg  
  inflating: /content/kaggle/train_images_jpeg/484219848.jpg  
  inflating: /content/kaggle/train_images_jpeg/484286450.jpg  
  inflating: /content/kaggle/train_images_jpeg/484462927.jpg  
  inflating: /content/kaggle/train_images_jpeg/484625436.jpg  
  inflating: /content/kaggle/train_images_jpeg/484710612.jpg  
  inflating: /content/kaggle/train_images_jpeg/4851187.jpg  
  inflating: /content/kaggle/train_images_jpeg/485289472.jpg  
  inflating: /content/kaggle/train_images_jpeg/485328354.jpg  
  inflating: /content/kaggle/train_images_jpeg/485496455.jpg  
  inflating: /content/kaggle/train_images_jpeg/486088821.jpg  
  inflating: /content/kaggle/train_images_jpeg/486182898.jpg  
  inflating: /content/kaggle/train_images_jpeg/486370102.jpg  
  inflating: /content/kaggle/train_images_jpeg/486378688.jpg  
  inflating: /content/kaggle/train_images_jpeg/486827297.jpg  
  inflating: /content/kaggle/train_images_jpeg/487107070.jpg  
  inflating: /content/kaggle/train_images_jpeg/487175432.jpg  
  inflating: /content/kaggle/train_images_jpeg/48759144.jpg  
  inflating: /content/kaggle/train_images_jpeg/487710367.jpg  
  inflating: /content/kaggle/train_images_jpeg/487884059.jpg  
  inflating: /content/kaggle/train_images_jpeg/488165307.jpg  
  inflating: /content/kaggle/train_images_jpeg/488245279.jpg  
  inflating: /content/kaggle/train_images_jpeg/488438522.jpg  
  inflating: /content/kaggle/train_images_jpeg/488450580.jpg  
  inflating: /content/kaggle/train_images_jpeg/488530530.jpg  
  inflating: /content/kaggle/train_images_jpeg/488621358.jpg  
  inflating: /content/kaggle/train_images_jpeg/488710990.jpg  
  inflating: /content/kaggle/train_images_jpeg/488981840.jpg  
  inflating: /content/kaggle/train_images_jpeg/489343827.jpg  
  inflating: /content/kaggle/train_images_jpeg/489369440.jpg  
  inflating: /content/kaggle/train_images_jpeg/489562516.jpg  
  inflating: /content/kaggle/train_images_jpeg/489607845.jpg  
  inflating: /content/kaggle/train_images_jpeg/489859226.jpg  
  inflating: /content/kaggle/train_images_jpeg/489869560.jpg  
  inflating: /content/kaggle/train_images_jpeg/490262929.jpg  
  inflating: /content/kaggle/train_images_jpeg/490343607.jpg  
  inflating: /content/kaggle/train_images_jpeg/490603548.jpg  
  inflating: /content/kaggle/train_images_jpeg/490649765.jpg  
  inflating: /content/kaggle/train_images_jpeg/490760030.jpg  
  inflating: /content/kaggle/train_images_jpeg/490933333.jpg  
  inflating: /content/kaggle/train_images_jpeg/491244285.jpg  
  inflating: /content/kaggle/train_images_jpeg/491341032.jpg  
  inflating: /content/kaggle/train_images_jpeg/491402925.jpg  
  inflating: /content/kaggle/train_images_jpeg/491516744.jpg  
  inflating: /content/kaggle/train_images_jpeg/491673903.jpg  
  inflating: /content/kaggle/train_images_jpeg/491901266.jpg  
  inflating: /content/kaggle/train_images_jpeg/492140725.jpg  
  inflating: /content/kaggle/train_images_jpeg/492151497.jpg  
  inflating: /content/kaggle/train_images_jpeg/49247184.jpg  
  inflating: /content/kaggle/train_images_jpeg/492645288.jpg  
  inflating: /content/kaggle/train_images_jpeg/493667259.jpg  
  inflating: /content/kaggle/train_images_jpeg/493875479.jpg  
  inflating: /content/kaggle/train_images_jpeg/494174224.jpg  
  inflating: /content/kaggle/train_images_jpeg/494373942.jpg  
  inflating: /content/kaggle/train_images_jpeg/49440106.jpg  
  inflating: /content/kaggle/train_images_jpeg/494558399.jpg  
  inflating: /content/kaggle/train_images_jpeg/494596361.jpg  
  inflating: /content/kaggle/train_images_jpeg/495190803.jpg  
  inflating: /content/kaggle/train_images_jpeg/495290160.jpg  
  inflating: /content/kaggle/train_images_jpeg/49533395.jpg  
  inflating: /content/kaggle/train_images_jpeg/495499602.jpg  
  inflating: /content/kaggle/train_images_jpeg/495769274.jpg  
  inflating: /content/kaggle/train_images_jpeg/495897960.jpg  
  inflating: /content/kaggle/train_images_jpeg/495907528.jpg  
  inflating: /content/kaggle/train_images_jpeg/496190872.jpg  
  inflating: /content/kaggle/train_images_jpeg/496222891.jpg  
  inflating: /content/kaggle/train_images_jpeg/496284862.jpg  
  inflating: /content/kaggle/train_images_jpeg/496523270.jpg  
  inflating: /content/kaggle/train_images_jpeg/496631673.jpg  
  inflating: /content/kaggle/train_images_jpeg/496814023.jpg  
  inflating: /content/kaggle/train_images_jpeg/496924131.jpg  
  inflating: /content/kaggle/train_images_jpeg/496949674.jpg  
  inflating: /content/kaggle/train_images_jpeg/49697815.jpg  
  inflating: /content/kaggle/train_images_jpeg/497021480.jpg  
  inflating: /content/kaggle/train_images_jpeg/49703968.jpg  
  inflating: /content/kaggle/train_images_jpeg/497447638.jpg  
  inflating: /content/kaggle/train_images_jpeg/497483114.jpg  
  inflating: /content/kaggle/train_images_jpeg/497620321.jpg  
  inflating: /content/kaggle/train_images_jpeg/497624056.jpg  
  inflating: /content/kaggle/train_images_jpeg/497685909.jpg  
  inflating: /content/kaggle/train_images_jpeg/498197766.jpg  
  inflating: /content/kaggle/train_images_jpeg/498240070.jpg  
  inflating: /content/kaggle/train_images_jpeg/498242244.jpg  
  inflating: /content/kaggle/train_images_jpeg/498277992.jpg  
  inflating: /content/kaggle/train_images_jpeg/498454187.jpg  
  inflating: /content/kaggle/train_images_jpeg/498491072.jpg  
  inflating: /content/kaggle/train_images_jpeg/49856658.jpg  
  inflating: /content/kaggle/train_images_jpeg/498735095.jpg  
  inflating: /content/kaggle/train_images_jpeg/498850777.jpg  
  inflating: /content/kaggle/train_images_jpeg/498928968.jpg  
  inflating: /content/kaggle/train_images_jpeg/499130995.jpg  
  inflating: /content/kaggle/train_images_jpeg/499152575.jpg  
  inflating: /content/kaggle/train_images_jpeg/499195591.jpg  
  inflating: /content/kaggle/train_images_jpeg/49920337.jpg  
  inflating: /content/kaggle/train_images_jpeg/499499899.jpg  
  inflating: /content/kaggle/train_images_jpeg/499562675.jpg  
  inflating: /content/kaggle/train_images_jpeg/499671530.jpg  
  inflating: /content/kaggle/train_images_jpeg/499934842.jpg  
  inflating: /content/kaggle/train_images_jpeg/500165253.jpg  
  inflating: /content/kaggle/train_images_jpeg/500317925.jpg  
  inflating: /content/kaggle/train_images_jpeg/500440865.jpg  
  inflating: /content/kaggle/train_images_jpeg/500785791.jpg  
  inflating: /content/kaggle/train_images_jpeg/501052709.jpg  
  inflating: /content/kaggle/train_images_jpeg/501215014.jpg  
  inflating: /content/kaggle/train_images_jpeg/501394346.jpg  
  inflating: /content/kaggle/train_images_jpeg/501634061.jpg  
  inflating: /content/kaggle/train_images_jpeg/50223703.jpg  
  inflating: /content/kaggle/train_images_jpeg/502274488.jpg  
  inflating: /content/kaggle/train_images_jpeg/502320523.jpg  
  inflating: /content/kaggle/train_images_jpeg/502783701.jpg  
  inflating: /content/kaggle/train_images_jpeg/503037836.jpg  
  inflating: /content/kaggle/train_images_jpeg/503224990.jpg  
  inflating: /content/kaggle/train_images_jpeg/503366497.jpg  
  inflating: /content/kaggle/train_images_jpeg/503851333.jpg  
  inflating: /content/kaggle/train_images_jpeg/503867520.jpg  
  inflating: /content/kaggle/train_images_jpeg/503880370.jpg  
  inflating: /content/kaggle/train_images_jpeg/503916638.jpg  
  inflating: /content/kaggle/train_images_jpeg/504065374.jpg  
  inflating: /content/kaggle/train_images_jpeg/504400425.jpg  
  inflating: /content/kaggle/train_images_jpeg/50441514.jpg  
  inflating: /content/kaggle/train_images_jpeg/504689064.jpg  
  inflating: /content/kaggle/train_images_jpeg/504875275.jpg  
  inflating: /content/kaggle/train_images_jpeg/50496855.jpg  
  inflating: /content/kaggle/train_images_jpeg/505261633.jpg  
  inflating: /content/kaggle/train_images_jpeg/505355209.jpg  
  inflating: /content/kaggle/train_images_jpeg/505693686.jpg  
  inflating: /content/kaggle/train_images_jpeg/505820957.jpg  
  inflating: /content/kaggle/train_images_jpeg/50589657.jpg  
  inflating: /content/kaggle/train_images_jpeg/506080526.jpg  
  inflating: /content/kaggle/train_images_jpeg/506567755.jpg  
  inflating: /content/kaggle/train_images_jpeg/506664858.jpg  
  inflating: /content/kaggle/train_images_jpeg/506713297.jpg  
  inflating: /content/kaggle/train_images_jpeg/506774842.jpg  
  inflating: /content/kaggle/train_images_jpeg/507004978.jpg  
  inflating: /content/kaggle/train_images_jpeg/507089312.jpg  
  inflating: /content/kaggle/train_images_jpeg/507279911.jpg  
  inflating: /content/kaggle/train_images_jpeg/508104541.jpg  
  inflating: /content/kaggle/train_images_jpeg/508241911.jpg  
  inflating: /content/kaggle/train_images_jpeg/508250510.jpg  
  inflating: /content/kaggle/train_images_jpeg/508378289.jpg  
  inflating: /content/kaggle/train_images_jpeg/508653988.jpg  
  inflating: /content/kaggle/train_images_jpeg/508678905.jpg  
  inflating: /content/kaggle/train_images_jpeg/5088626.jpg  
  inflating: /content/kaggle/train_images_jpeg/509573595.jpg  
  inflating: /content/kaggle/train_images_jpeg/509720498.jpg  
  inflating: /content/kaggle/train_images_jpeg/509958138.jpg  
  inflating: /content/kaggle/train_images_jpeg/510134831.jpg  
  inflating: /content/kaggle/train_images_jpeg/510336475.jpg  
  inflating: /content/kaggle/train_images_jpeg/510338633.jpg  
  inflating: /content/kaggle/train_images_jpeg/51063556.jpg  
  inflating: /content/kaggle/train_images_jpeg/510655855.jpg  
  inflating: /content/kaggle/train_images_jpeg/510749381.jpg  
  inflating: /content/kaggle/train_images_jpeg/51075448.jpg  
  inflating: /content/kaggle/train_images_jpeg/510847291.jpg  
  inflating: /content/kaggle/train_images_jpeg/510873412.jpg  
  inflating: /content/kaggle/train_images_jpeg/510931414.jpg  
  inflating: /content/kaggle/train_images_jpeg/511089845.jpg  
  inflating: /content/kaggle/train_images_jpeg/511322441.jpg  
  inflating: /content/kaggle/train_images_jpeg/511472935.jpg  
  inflating: /content/kaggle/train_images_jpeg/511494516.jpg  
  inflating: /content/kaggle/train_images_jpeg/511654743.jpg  
  inflating: /content/kaggle/train_images_jpeg/511675910.jpg  
  inflating: /content/kaggle/train_images_jpeg/511932063.jpg  
  inflating: /content/kaggle/train_images_jpeg/511993936.jpg  
  inflating: /content/kaggle/train_images_jpeg/512152604.jpg  
  inflating: /content/kaggle/train_images_jpeg/512168162.jpg  
  inflating: /content/kaggle/train_images_jpeg/512575634.jpg  
  inflating: /content/kaggle/train_images_jpeg/512651880.jpg  
  inflating: /content/kaggle/train_images_jpeg/512811593.jpg  
  inflating: /content/kaggle/train_images_jpeg/51284514.jpg  
  inflating: /content/kaggle/train_images_jpeg/512994798.jpg  
  inflating: /content/kaggle/train_images_jpeg/513308138.jpg  
  inflating: /content/kaggle/train_images_jpeg/513364056.jpg  
  inflating: /content/kaggle/train_images_jpeg/513549647.jpg  
  inflating: /content/kaggle/train_images_jpeg/51370822.jpg  
  inflating: /content/kaggle/train_images_jpeg/513780423.jpg  
  inflating: /content/kaggle/train_images_jpeg/513916180.jpg  
  inflating: /content/kaggle/train_images_jpeg/513986084.jpg  
  inflating: /content/kaggle/train_images_jpeg/514040790.jpg  
  inflating: /content/kaggle/train_images_jpeg/514282454.jpg  
  inflating: /content/kaggle/train_images_jpeg/514376645.jpg  
  inflating: /content/kaggle/train_images_jpeg/51460409.jpg  
  inflating: /content/kaggle/train_images_jpeg/514638622.jpg  
  inflating: /content/kaggle/train_images_jpeg/514840131.jpg  
  inflating: /content/kaggle/train_images_jpeg/514995034.jpg  
  inflating: /content/kaggle/train_images_jpeg/515083070.jpg  
  inflating: /content/kaggle/train_images_jpeg/515191532.jpg  
  inflating: /content/kaggle/train_images_jpeg/515241983.jpg  
  inflating: /content/kaggle/train_images_jpeg/515316460.jpg  
  inflating: /content/kaggle/train_images_jpeg/515391369.jpg  
  inflating: /content/kaggle/train_images_jpeg/515448717.jpg  
  inflating: /content/kaggle/train_images_jpeg/515738750.jpg  
  inflating: /content/kaggle/train_images_jpeg/51624303.jpg  
  inflating: /content/kaggle/train_images_jpeg/516331845.jpg  
  inflating: /content/kaggle/train_images_jpeg/516333196.jpg  
  inflating: /content/kaggle/train_images_jpeg/516746229.jpg  
  inflating: /content/kaggle/train_images_jpeg/517018049.jpg  
  inflating: /content/kaggle/train_images_jpeg/517170612.jpg  
  inflating: /content/kaggle/train_images_jpeg/517295595.jpg  
  inflating: /content/kaggle/train_images_jpeg/51748275.jpg  
  inflating: /content/kaggle/train_images_jpeg/518232429.jpg  
  inflating: /content/kaggle/train_images_jpeg/518284284.jpg  
  inflating: /content/kaggle/train_images_jpeg/518398469.jpg  
  inflating: /content/kaggle/train_images_jpeg/518719429.jpg  
  inflating: /content/kaggle/train_images_jpeg/518891556.jpg  
  inflating: /content/kaggle/train_images_jpeg/519050764.jpg  
  inflating: /content/kaggle/train_images_jpeg/519080705.jpg  
  inflating: /content/kaggle/train_images_jpeg/519341092.jpg  
  inflating: /content/kaggle/train_images_jpeg/519363437.jpg  
  inflating: /content/kaggle/train_images_jpeg/519373224.jpg  
  inflating: /content/kaggle/train_images_jpeg/519516742.jpg  
  inflating: /content/kaggle/train_images_jpeg/519569660.jpg  
  inflating: /content/kaggle/train_images_jpeg/520111872.jpg  
  inflating: /content/kaggle/train_images_jpeg/520184661.jpg  
  inflating: /content/kaggle/train_images_jpeg/520310239.jpg  
  inflating: /content/kaggle/train_images_jpeg/520827506.jpg  
  inflating: /content/kaggle/train_images_jpeg/520992069.jpg  
  inflating: /content/kaggle/train_images_jpeg/521262022.jpg  
  inflating: /content/kaggle/train_images_jpeg/522043720.jpg  
  inflating: /content/kaggle/train_images_jpeg/522172661.jpg  
  inflating: /content/kaggle/train_images_jpeg/522209459.jpg  
  inflating: /content/kaggle/train_images_jpeg/522535695.jpg  
  inflating: /content/kaggle/train_images_jpeg/522793998.jpg  
  inflating: /content/kaggle/train_images_jpeg/522854384.jpg  
  inflating: /content/kaggle/train_images_jpeg/523005537.jpg  
  inflating: /content/kaggle/train_images_jpeg/523032468.jpg  
  inflating: /content/kaggle/train_images_jpeg/523149736.jpg  
  inflating: /content/kaggle/train_images_jpeg/523201478.jpg  
  inflating: /content/kaggle/train_images_jpeg/523467512.jpg  
  inflating: /content/kaggle/train_images_jpeg/524130379.jpg  
  inflating: /content/kaggle/train_images_jpeg/52417145.jpg  
  inflating: /content/kaggle/train_images_jpeg/524188630.jpg  
  inflating: /content/kaggle/train_images_jpeg/524234621.jpg  
  inflating: /content/kaggle/train_images_jpeg/524701920.jpg  
  inflating: /content/kaggle/train_images_jpeg/52480515.jpg  
  inflating: /content/kaggle/train_images_jpeg/525349447.jpg  
  inflating: /content/kaggle/train_images_jpeg/525691978.jpg  
  inflating: /content/kaggle/train_images_jpeg/525742373.jpg  
  inflating: /content/kaggle/train_images_jpeg/525960141.jpg  
  inflating: /content/kaggle/train_images_jpeg/526290781.jpg  
  inflating: /content/kaggle/train_images_jpeg/52672633.jpg  
  inflating: /content/kaggle/train_images_jpeg/526842311.jpg  
  inflating: /content/kaggle/train_images_jpeg/527207274.jpg  
  inflating: /content/kaggle/train_images_jpeg/527287896.jpg  
  inflating: /content/kaggle/train_images_jpeg/52729180.jpg  
  inflating: /content/kaggle/train_images_jpeg/527304483.jpg  
  inflating: /content/kaggle/train_images_jpeg/527458103.jpg  
  inflating: /content/kaggle/train_images_jpeg/527474755.jpg  
  inflating: /content/kaggle/train_images_jpeg/527619168.jpg  
  inflating: /content/kaggle/train_images_jpeg/527648295.jpg  
  inflating: /content/kaggle/train_images_jpeg/527923260.jpg  
  inflating: /content/kaggle/train_images_jpeg/528179991.jpg  
  inflating: /content/kaggle/train_images_jpeg/528487165.jpg  
  inflating: /content/kaggle/train_images_jpeg/528632958.jpg  
  inflating: /content/kaggle/train_images_jpeg/528691632.jpg  
  inflating: /content/kaggle/train_images_jpeg/52883488.jpg  
  inflating: /content/kaggle/train_images_jpeg/529324614.jpg  
  inflating: /content/kaggle/train_images_jpeg/529520501.jpg  
  inflating: /content/kaggle/train_images_jpeg/529572554.jpg  
  inflating: /content/kaggle/train_images_jpeg/529641068.jpg  
  inflating: /content/kaggle/train_images_jpeg/530166145.jpg  
  inflating: /content/kaggle/train_images_jpeg/530221019.jpg  
  inflating: /content/kaggle/train_images_jpeg/53025412.jpg  
  inflating: /content/kaggle/train_images_jpeg/530355388.jpg  
  inflating: /content/kaggle/train_images_jpeg/530632304.jpg  
  inflating: /content/kaggle/train_images_jpeg/53065520.jpg  
  inflating: /content/kaggle/train_images_jpeg/530867664.jpg  
  inflating: /content/kaggle/train_images_jpeg/531185235.jpg  
  inflating: /content/kaggle/train_images_jpeg/53126023.jpg  
  inflating: /content/kaggle/train_images_jpeg/531614810.jpg  
  inflating: /content/kaggle/train_images_jpeg/53164927.jpg  
  inflating: /content/kaggle/train_images_jpeg/531653208.jpg  
  inflating: /content/kaggle/train_images_jpeg/53200283.jpg  
  inflating: /content/kaggle/train_images_jpeg/532038171.jpg  
  inflating: /content/kaggle/train_images_jpeg/532081653.jpg  
  inflating: /content/kaggle/train_images_jpeg/532103360.jpg  
  inflating: /content/kaggle/train_images_jpeg/532201178.jpg  
  inflating: /content/kaggle/train_images_jpeg/532235062.jpg  
  inflating: /content/kaggle/train_images_jpeg/532255691.jpg  
  inflating: /content/kaggle/train_images_jpeg/532304081.jpg  
  inflating: /content/kaggle/train_images_jpeg/532464272.jpg  
  inflating: /content/kaggle/train_images_jpeg/532508558.jpg  
  inflating: /content/kaggle/train_images_jpeg/532692632.jpg  
  inflating: /content/kaggle/train_images_jpeg/533133014.jpg  
  inflating: /content/kaggle/train_images_jpeg/533486476.jpg  
  inflating: /content/kaggle/train_images_jpeg/533613162.jpg  
  inflating: /content/kaggle/train_images_jpeg/534270890.jpg  
  inflating: /content/kaggle/train_images_jpeg/534358787.jpg  
  inflating: /content/kaggle/train_images_jpeg/534364866.jpg  
  inflating: /content/kaggle/train_images_jpeg/534568222.jpg  
  inflating: /content/kaggle/train_images_jpeg/534784883.jpg  
  inflating: /content/kaggle/train_images_jpeg/534932324.jpg  
  inflating: /content/kaggle/train_images_jpeg/534969562.jpg  
  inflating: /content/kaggle/train_images_jpeg/53515353.jpg  
  inflating: /content/kaggle/train_images_jpeg/535314273.jpg  
  inflating: /content/kaggle/train_images_jpeg/535503922.jpg  
  inflating: /content/kaggle/train_images_jpeg/535534657.jpg  
  inflating: /content/kaggle/train_images_jpeg/535537385.jpg  
  inflating: /content/kaggle/train_images_jpeg/53615554.jpg  
  inflating: /content/kaggle/train_images_jpeg/536966524.jpg  
  inflating: /content/kaggle/train_images_jpeg/537247997.jpg  
  inflating: /content/kaggle/train_images_jpeg/537279050.jpg  
  inflating: /content/kaggle/train_images_jpeg/537462269.jpg  
  inflating: /content/kaggle/train_images_jpeg/537704740.jpg  
  inflating: /content/kaggle/train_images_jpeg/537771989.jpg  
  inflating: /content/kaggle/train_images_jpeg/538079327.jpg  
  inflating: /content/kaggle/train_images_jpeg/53822293.jpg  
  inflating: /content/kaggle/train_images_jpeg/53835845.jpg  
  inflating: /content/kaggle/train_images_jpeg/538938122.jpg  
  inflating: /content/kaggle/train_images_jpeg/539156114.jpg  
  inflating: /content/kaggle/train_images_jpeg/539212497.jpg  
  inflating: /content/kaggle/train_images_jpeg/539448425.jpg  
  inflating: /content/kaggle/train_images_jpeg/53955129.jpg  
  inflating: /content/kaggle/train_images_jpeg/539640759.jpg  
  inflating: /content/kaggle/train_images_jpeg/539706836.jpg  
  inflating: /content/kaggle/train_images_jpeg/540248010.jpg  
  inflating: /content/kaggle/train_images_jpeg/540729599.jpg  
  inflating: /content/kaggle/train_images_jpeg/540762921.jpg  
  inflating: /content/kaggle/train_images_jpeg/540817686.jpg  
  inflating: /content/kaggle/train_images_jpeg/540860171.jpg  
  inflating: /content/kaggle/train_images_jpeg/541016077.jpg  
  inflating: /content/kaggle/train_images_jpeg/541216971.jpg  
  inflating: /content/kaggle/train_images_jpeg/54133224.jpg  
  inflating: /content/kaggle/train_images_jpeg/541581535.jpg  
  inflating: /content/kaggle/train_images_jpeg/541684272.jpg  
  inflating: /content/kaggle/train_images_jpeg/541812079.jpg  
  inflating: /content/kaggle/train_images_jpeg/541997227.jpg  
  inflating: /content/kaggle/train_images_jpeg/542067115.jpg  
  inflating: /content/kaggle/train_images_jpeg/542129392.jpg  
  inflating: /content/kaggle/train_images_jpeg/542215511.jpg  
  inflating: /content/kaggle/train_images_jpeg/542432519.jpg  
  inflating: /content/kaggle/train_images_jpeg/542560691.jpg  
  inflating: /content/kaggle/train_images_jpeg/542786109.jpg  
  inflating: /content/kaggle/train_images_jpeg/542875481.jpg  
  inflating: /content/kaggle/train_images_jpeg/543032315.jpg  
  inflating: /content/kaggle/train_images_jpeg/5430583.jpg  
  inflating: /content/kaggle/train_images_jpeg/54321323.jpg  
  inflating: /content/kaggle/train_images_jpeg/543312121.jpg  
  inflating: /content/kaggle/train_images_jpeg/543499151.jpg  
  inflating: /content/kaggle/train_images_jpeg/543515988.jpg  
  inflating: /content/kaggle/train_images_jpeg/543588730.jpg  
  inflating: /content/kaggle/train_images_jpeg/543674498.jpg  
  inflating: /content/kaggle/train_images_jpeg/543908014.jpg  
  inflating: /content/kaggle/train_images_jpeg/543908861.jpg  
  inflating: /content/kaggle/train_images_jpeg/544308898.jpg  
  inflating: /content/kaggle/train_images_jpeg/544310124.jpg  
  inflating: /content/kaggle/train_images_jpeg/544346867.jpg  
  inflating: /content/kaggle/train_images_jpeg/544498440.jpg  
  inflating: /content/kaggle/train_images_jpeg/544530143.jpg  
  inflating: /content/kaggle/train_images_jpeg/544532198.jpg  
  inflating: /content/kaggle/train_images_jpeg/544545158.jpg  
  inflating: /content/kaggle/train_images_jpeg/544761733.jpg  
  inflating: /content/kaggle/train_images_jpeg/544785304.jpg  
  inflating: /content/kaggle/train_images_jpeg/544841387.jpg  
  inflating: /content/kaggle/train_images_jpeg/544885077.jpg  
  inflating: /content/kaggle/train_images_jpeg/545003862.jpg  
  inflating: /content/kaggle/train_images_jpeg/545074586.jpg  
  inflating: /content/kaggle/train_images_jpeg/545206870.jpg  
  inflating: /content/kaggle/train_images_jpeg/545499966.jpg  
  inflating: /content/kaggle/train_images_jpeg/545763549.jpg  
  inflating: /content/kaggle/train_images_jpeg/545818494.jpg  
  inflating: /content/kaggle/train_images_jpeg/545843686.jpg  
  inflating: /content/kaggle/train_images_jpeg/545897624.jpg  
  inflating: /content/kaggle/train_images_jpeg/54600142.jpg  
  inflating: /content/kaggle/train_images_jpeg/546003679.jpg  
  inflating: /content/kaggle/train_images_jpeg/546383916.jpg  
  inflating: /content/kaggle/train_images_jpeg/546421963.jpg  
  inflating: /content/kaggle/train_images_jpeg/546528869.jpg  
  inflating: /content/kaggle/train_images_jpeg/546602360.jpg  
  inflating: /content/kaggle/train_images_jpeg/546912616.jpg  
  inflating: /content/kaggle/train_images_jpeg/546931175.jpg  
  inflating: /content/kaggle/train_images_jpeg/546947132.jpg  
  inflating: /content/kaggle/train_images_jpeg/547059239.jpg  
  inflating: /content/kaggle/train_images_jpeg/547270823.jpg  
  inflating: /content/kaggle/train_images_jpeg/547271949.jpg  
  inflating: /content/kaggle/train_images_jpeg/547866885.jpg  
  inflating: /content/kaggle/train_images_jpeg/54787315.jpg  
  inflating: /content/kaggle/train_images_jpeg/548402353.jpg  
  inflating: /content/kaggle/train_images_jpeg/548412421.jpg  
  inflating: /content/kaggle/train_images_jpeg/548597854.jpg  
  inflating: /content/kaggle/train_images_jpeg/548717343.jpg  
  inflating: /content/kaggle/train_images_jpeg/548963583.jpg  
  inflating: /content/kaggle/train_images_jpeg/549334343.jpg  
  inflating: /content/kaggle/train_images_jpeg/549529055.jpg  
  inflating: /content/kaggle/train_images_jpeg/549591801.jpg  
  inflating: /content/kaggle/train_images_jpeg/549750394.jpg  
  inflating: /content/kaggle/train_images_jpeg/549830599.jpg  
  inflating: /content/kaggle/train_images_jpeg/549854027.jpg  
  inflating: /content/kaggle/train_images_jpeg/550133495.jpg  
  inflating: /content/kaggle/train_images_jpeg/550429661.jpg  
  inflating: /content/kaggle/train_images_jpeg/550691642.jpg  
  inflating: /content/kaggle/train_images_jpeg/550742055.jpg  
  inflating: /content/kaggle/train_images_jpeg/550916089.jpg  
  inflating: /content/kaggle/train_images_jpeg/550983047.jpg  
  inflating: /content/kaggle/train_images_jpeg/551051657.jpg  
  inflating: /content/kaggle/train_images_jpeg/5511383.jpg  
  inflating: /content/kaggle/train_images_jpeg/551310653.jpg  
  inflating: /content/kaggle/train_images_jpeg/551716959.jpg  
  inflating: /content/kaggle/train_images_jpeg/551875095.jpg  
  inflating: /content/kaggle/train_images_jpeg/552169332.jpg  
  inflating: /content/kaggle/train_images_jpeg/55220429.jpg  
  inflating: /content/kaggle/train_images_jpeg/552242420.jpg  
  inflating: /content/kaggle/train_images_jpeg/552389666.jpg  
  inflating: /content/kaggle/train_images_jpeg/553154853.jpg  
  inflating: /content/kaggle/train_images_jpeg/553195372.jpg  
  inflating: /content/kaggle/train_images_jpeg/55319830.jpg  
  inflating: /content/kaggle/train_images_jpeg/553204190.jpg  
  inflating: /content/kaggle/train_images_jpeg/553294224.jpg  
  inflating: /content/kaggle/train_images_jpeg/553826173.jpg  
  inflating: /content/kaggle/train_images_jpeg/554118057.jpg  
  inflating: /content/kaggle/train_images_jpeg/554189180.jpg  
  inflating: /content/kaggle/train_images_jpeg/554488826.jpg  
  inflating: /content/kaggle/train_images_jpeg/554618944.jpg  
  inflating: /content/kaggle/train_images_jpeg/5546511.jpg  
  inflating: /content/kaggle/train_images_jpeg/554934001.jpg  
  inflating: /content/kaggle/train_images_jpeg/555028236.jpg  
  inflating: /content/kaggle/train_images_jpeg/555296352.jpg  
  inflating: /content/kaggle/train_images_jpeg/555882055.jpg  
  inflating: /content/kaggle/train_images_jpeg/556066757.jpg  
  inflating: /content/kaggle/train_images_jpeg/556170087.jpg  
  inflating: /content/kaggle/train_images_jpeg/556223341.jpg  
  inflating: /content/kaggle/train_images_jpeg/556542792.jpg  
  inflating: /content/kaggle/train_images_jpeg/556624815.jpg  
  inflating: /content/kaggle/train_images_jpeg/556665949.jpg  
  inflating: /content/kaggle/train_images_jpeg/55670030.jpg  
  inflating: /content/kaggle/train_images_jpeg/557056564.jpg  
  inflating: /content/kaggle/train_images_jpeg/557774617.jpg  
  inflating: /content/kaggle/train_images_jpeg/55799003.jpg  
  inflating: /content/kaggle/train_images_jpeg/559509734.jpg  
  inflating: /content/kaggle/train_images_jpeg/559693099.jpg  
  inflating: /content/kaggle/train_images_jpeg/559984441.jpg  
  inflating: /content/kaggle/train_images_jpeg/560477016.jpg  
  inflating: /content/kaggle/train_images_jpeg/560592460.jpg  
  inflating: /content/kaggle/train_images_jpeg/560888503.jpg  
  inflating: /content/kaggle/train_images_jpeg/561131295.jpg  
  inflating: /content/kaggle/train_images_jpeg/561201584.jpg  
  inflating: /content/kaggle/train_images_jpeg/56135051.jpg  
  inflating: /content/kaggle/train_images_jpeg/561385001.jpg  
  inflating: /content/kaggle/train_images_jpeg/561444501.jpg  
  inflating: /content/kaggle/train_images_jpeg/561647799.jpg  
  inflating: /content/kaggle/train_images_jpeg/561864770.jpg  
  inflating: /content/kaggle/train_images_jpeg/562027159.jpg  
  inflating: /content/kaggle/train_images_jpeg/56205477.jpg  
  inflating: /content/kaggle/train_images_jpeg/562228915.jpg  
  inflating: /content/kaggle/train_images_jpeg/562337477.jpg  
  inflating: /content/kaggle/train_images_jpeg/562822735.jpg  
  inflating: /content/kaggle/train_images_jpeg/563348054.jpg  
  inflating: /content/kaggle/train_images_jpeg/563887175.jpg  
  inflating: /content/kaggle/train_images_jpeg/564364376.jpg  
  inflating: /content/kaggle/train_images_jpeg/564511381.jpg  
  inflating: /content/kaggle/train_images_jpeg/564643932.jpg  
  inflating: /content/kaggle/train_images_jpeg/564925067.jpg  
  inflating: /content/kaggle/train_images_jpeg/565347582.jpg  
  inflating: /content/kaggle/train_images_jpeg/565367936.jpg  
  inflating: /content/kaggle/train_images_jpeg/565965080.jpg  
  inflating: /content/kaggle/train_images_jpeg/566159695.jpg  
  inflating: /content/kaggle/train_images_jpeg/566231170.jpg  
  inflating: /content/kaggle/train_images_jpeg/566279368.jpg  
  inflating: /content/kaggle/train_images_jpeg/5664536.jpg  
  inflating: /content/kaggle/train_images_jpeg/566469674.jpg  
  inflating: /content/kaggle/train_images_jpeg/566542293.jpg  
  inflating: /content/kaggle/train_images_jpeg/566571284.jpg  
  inflating: /content/kaggle/train_images_jpeg/5666225.jpg  
  inflating: /content/kaggle/train_images_jpeg/566719664.jpg  
  inflating: /content/kaggle/train_images_jpeg/567206056.jpg  
  inflating: /content/kaggle/train_images_jpeg/567537807.jpg  
  inflating: /content/kaggle/train_images_jpeg/567779495.jpg  
  inflating: /content/kaggle/train_images_jpeg/56784677.jpg  
  inflating: /content/kaggle/train_images_jpeg/567892299.jpg  
  inflating: /content/kaggle/train_images_jpeg/56813625.jpg  
  inflating: /content/kaggle/train_images_jpeg/568226171.jpg  
  inflating: /content/kaggle/train_images_jpeg/568347975.jpg  
  inflating: /content/kaggle/train_images_jpeg/568411429.jpg  
  inflating: /content/kaggle/train_images_jpeg/568504809.jpg  
  inflating: /content/kaggle/train_images_jpeg/568585262.jpg  
  inflating: /content/kaggle/train_images_jpeg/568805661.jpg  
  inflating: /content/kaggle/train_images_jpeg/568949064.jpg  
  inflating: /content/kaggle/train_images_jpeg/569345273.jpg  
  inflating: /content/kaggle/train_images_jpeg/569545786.jpg  
  inflating: /content/kaggle/train_images_jpeg/569609163.jpg  
  inflating: /content/kaggle/train_images_jpeg/569842713.jpg  
  inflating: /content/kaggle/train_images_jpeg/570097057.jpg  
  inflating: /content/kaggle/train_images_jpeg/57023383.jpg  
  inflating: /content/kaggle/train_images_jpeg/570348622.jpg  
  inflating: /content/kaggle/train_images_jpeg/570526420.jpg  
  inflating: /content/kaggle/train_images_jpeg/570889595.jpg  
  inflating: /content/kaggle/train_images_jpeg/57099592.jpg  
  inflating: /content/kaggle/train_images_jpeg/571006343.jpg  
  inflating: /content/kaggle/train_images_jpeg/571189248.jpg  
  inflating: /content/kaggle/train_images_jpeg/571328280.jpg  
  inflating: /content/kaggle/train_images_jpeg/57149651.jpg  
  inflating: /content/kaggle/train_images_jpeg/571576955.jpg  
  inflating: /content/kaggle/train_images_jpeg/571732176.jpg  
  inflating: /content/kaggle/train_images_jpeg/572003019.jpg  
  inflating: /content/kaggle/train_images_jpeg/572073587.jpg  
  inflating: /content/kaggle/train_images_jpeg/572515769.jpg  
  inflating: /content/kaggle/train_images_jpeg/572739477.jpg  
  inflating: /content/kaggle/train_images_jpeg/573039129.jpg  
  inflating: /content/kaggle/train_images_jpeg/573324267.jpg  
  inflating: /content/kaggle/train_images_jpeg/573623784.jpg  
  inflating: /content/kaggle/train_images_jpeg/573832722.jpg  
  inflating: /content/kaggle/train_images_jpeg/573879422.jpg  
  inflating: /content/kaggle/train_images_jpeg/574000840.jpg  
  inflating: /content/kaggle/train_images_jpeg/574578186.jpg  
  inflating: /content/kaggle/train_images_jpeg/575082952.jpg  
  inflating: /content/kaggle/train_images_jpeg/575098680.jpg  
  inflating: /content/kaggle/train_images_jpeg/575135832.jpg  
  inflating: /content/kaggle/train_images_jpeg/575181306.jpg  
  inflating: /content/kaggle/train_images_jpeg/575338550.jpg  
  inflating: /content/kaggle/train_images_jpeg/575396227.jpg  
  inflating: /content/kaggle/train_images_jpeg/575428243.jpg  
  inflating: /content/kaggle/train_images_jpeg/576478448.jpg  
  inflating: /content/kaggle/train_images_jpeg/57665451.jpg  
  inflating: /content/kaggle/train_images_jpeg/577090506.jpg  
  inflating: /content/kaggle/train_images_jpeg/577274696.jpg  
  inflating: /content/kaggle/train_images_jpeg/577275229.jpg  
  inflating: /content/kaggle/train_images_jpeg/577684636.jpg  
  inflating: /content/kaggle/train_images_jpeg/577741069.jpg  
  inflating: /content/kaggle/train_images_jpeg/578080012.jpg  
  inflating: /content/kaggle/train_images_jpeg/578106393.jpg  
  inflating: /content/kaggle/train_images_jpeg/578279237.jpg  
  inflating: /content/kaggle/train_images_jpeg/57861623.jpg  
  inflating: /content/kaggle/train_images_jpeg/578646228.jpg  
  inflating: /content/kaggle/train_images_jpeg/57892387.jpg  
  inflating: /content/kaggle/train_images_jpeg/579280251.jpg  
  inflating: /content/kaggle/train_images_jpeg/579333790.jpg  
  inflating: /content/kaggle/train_images_jpeg/579336785.jpg  
  inflating: /content/kaggle/train_images_jpeg/579498969.jpg  
  inflating: /content/kaggle/train_images_jpeg/580100046.jpg  
  inflating: /content/kaggle/train_images_jpeg/580111608.jpg  
  inflating: /content/kaggle/train_images_jpeg/580293785.jpg  
  inflating: /content/kaggle/train_images_jpeg/580516102.jpg  
  inflating: /content/kaggle/train_images_jpeg/580550239.jpg  
  inflating: /content/kaggle/train_images_jpeg/580838214.jpg  
  inflating: /content/kaggle/train_images_jpeg/580859644.jpg  
  inflating: /content/kaggle/train_images_jpeg/581030887.jpg  
  inflating: /content/kaggle/train_images_jpeg/581164870.jpg  
  inflating: /content/kaggle/train_images_jpeg/581179733.jpg  
  inflating: /content/kaggle/train_images_jpeg/581235562.jpg  
  inflating: /content/kaggle/train_images_jpeg/581749808.jpg  
  inflating: /content/kaggle/train_images_jpeg/581902083.jpg  
  inflating: /content/kaggle/train_images_jpeg/582120514.jpg  
  inflating: /content/kaggle/train_images_jpeg/582179912.jpg  
  inflating: /content/kaggle/train_images_jpeg/582352615.jpg  
  inflating: /content/kaggle/train_images_jpeg/582499050.jpg  
  inflating: /content/kaggle/train_images_jpeg/582719754.jpg  
  inflating: /content/kaggle/train_images_jpeg/582948478.jpg  
  inflating: /content/kaggle/train_images_jpeg/58390189.jpg  
  inflating: /content/kaggle/train_images_jpeg/584367116.jpg  
  inflating: /content/kaggle/train_images_jpeg/58446146.jpg  
  inflating: /content/kaggle/train_images_jpeg/584513475.jpg  
  inflating: /content/kaggle/train_images_jpeg/584742887.jpg  
  inflating: /content/kaggle/train_images_jpeg/584853244.jpg  
  inflating: /content/kaggle/train_images_jpeg/584996062.jpg  
  inflating: /content/kaggle/train_images_jpeg/585067161.jpg  
  inflating: /content/kaggle/train_images_jpeg/585209164.jpg  
  inflating: /content/kaggle/train_images_jpeg/585228910.jpg  
  inflating: /content/kaggle/train_images_jpeg/58528063.jpg  
  inflating: /content/kaggle/train_images_jpeg/58559275.jpg  
  inflating: /content/kaggle/train_images_jpeg/585813976.jpg  
  inflating: /content/kaggle/train_images_jpeg/585953153.jpg  
  inflating: /content/kaggle/train_images_jpeg/586054705.jpg  
  inflating: /content/kaggle/train_images_jpeg/586116935.jpg  
  inflating: /content/kaggle/train_images_jpeg/586367885.jpg  
  inflating: /content/kaggle/train_images_jpeg/586470698.jpg  
  inflating: /content/kaggle/train_images_jpeg/586485536.jpg  
  inflating: /content/kaggle/train_images_jpeg/58667011.jpg  
  inflating: /content/kaggle/train_images_jpeg/586687554.jpg  
  inflating: /content/kaggle/train_images_jpeg/586808428.jpg  
  inflating: /content/kaggle/train_images_jpeg/587011215.jpg  
  inflating: /content/kaggle/train_images_jpeg/587043810.jpg  
  inflating: /content/kaggle/train_images_jpeg/58720038.jpg  
  inflating: /content/kaggle/train_images_jpeg/587329916.jpg  
  inflating: /content/kaggle/train_images_jpeg/587410113.jpg  
  inflating: /content/kaggle/train_images_jpeg/587420634.jpg  
  inflating: /content/kaggle/train_images_jpeg/587620501.jpg  
  inflating: /content/kaggle/train_images_jpeg/587692768.jpg  
  inflating: /content/kaggle/train_images_jpeg/58780369.jpg  
  inflating: /content/kaggle/train_images_jpeg/587829607.jpg  
  inflating: /content/kaggle/train_images_jpeg/588030213.jpg  
  inflating: /content/kaggle/train_images_jpeg/588169966.jpg  
  inflating: /content/kaggle/train_images_jpeg/588425651.jpg  
  inflating: /content/kaggle/train_images_jpeg/588893932.jpg  
  inflating: /content/kaggle/train_images_jpeg/589122135.jpg  
  inflating: /content/kaggle/train_images_jpeg/589247571.jpg  
  inflating: /content/kaggle/train_images_jpeg/589734688.jpg  
  inflating: /content/kaggle/train_images_jpeg/5912799.jpg  
  inflating: /content/kaggle/train_images_jpeg/591335475.jpg  
  inflating: /content/kaggle/train_images_jpeg/591372512.jpg  
  inflating: /content/kaggle/train_images_jpeg/591721064.jpg  
  inflating: /content/kaggle/train_images_jpeg/591741499.jpg  
  inflating: /content/kaggle/train_images_jpeg/591760666.jpg  
  inflating: /content/kaggle/train_images_jpeg/591792170.jpg  
  inflating: /content/kaggle/train_images_jpeg/591802054.jpg  
  inflating: /content/kaggle/train_images_jpeg/59208991.jpg  
  inflating: /content/kaggle/train_images_jpeg/592098292.jpg  
  inflating: /content/kaggle/train_images_jpeg/592236552.jpg  
  inflating: /content/kaggle/train_images_jpeg/592251506.jpg  
  inflating: /content/kaggle/train_images_jpeg/592322076.jpg  
  inflating: /content/kaggle/train_images_jpeg/592477386.jpg  
  inflating: /content/kaggle/train_images_jpeg/592844774.jpg  
  inflating: /content/kaggle/train_images_jpeg/592978315.jpg  
  inflating: /content/kaggle/train_images_jpeg/593092759.jpg  
  inflating: /content/kaggle/train_images_jpeg/593244106.jpg  
  inflating: /content/kaggle/train_images_jpeg/593295166.jpg  
  inflating: /content/kaggle/train_images_jpeg/593922825.jpg  
  inflating: /content/kaggle/train_images_jpeg/593986608.jpg  
  inflating: /content/kaggle/train_images_jpeg/594027454.jpg  
  inflating: /content/kaggle/train_images_jpeg/594438051.jpg  
  inflating: /content/kaggle/train_images_jpeg/595285213.jpg  
  inflating: /content/kaggle/train_images_jpeg/595384865.jpg  
  inflating: /content/kaggle/train_images_jpeg/595567358.jpg  
  inflating: /content/kaggle/train_images_jpeg/595787428.jpg  
  inflating: /content/kaggle/train_images_jpeg/595835562.jpg  
  inflating: /content/kaggle/train_images_jpeg/595909449.jpg  
  inflating: /content/kaggle/train_images_jpeg/596124693.jpg  
  inflating: /content/kaggle/train_images_jpeg/596572459.jpg  
  inflating: /content/kaggle/train_images_jpeg/596602212.jpg  
  inflating: /content/kaggle/train_images_jpeg/596669967.jpg  
  inflating: /content/kaggle/train_images_jpeg/596706595.jpg  
  inflating: /content/kaggle/train_images_jpeg/59686251.jpg  
  inflating: /content/kaggle/train_images_jpeg/596964772.jpg  
  inflating: /content/kaggle/train_images_jpeg/597003847.jpg  
  inflating: /content/kaggle/train_images_jpeg/597213250.jpg  
  inflating: /content/kaggle/train_images_jpeg/597269294.jpg  
  inflating: /content/kaggle/train_images_jpeg/597389720.jpg  
  inflating: /content/kaggle/train_images_jpeg/597527186.jpg  
  inflating: /content/kaggle/train_images_jpeg/598088658.jpg  
  inflating: /content/kaggle/train_images_jpeg/598311175.jpg  
  inflating: /content/kaggle/train_images_jpeg/598574502.jpg  
  inflating: /content/kaggle/train_images_jpeg/598720270.jpg  
  inflating: /content/kaggle/train_images_jpeg/598746218.jpg  
  inflating: /content/kaggle/train_images_jpeg/59894282.jpg  
  inflating: /content/kaggle/train_images_jpeg/59901561.jpg  
  inflating: /content/kaggle/train_images_jpeg/599325048.jpg  
  inflating: /content/kaggle/train_images_jpeg/599387864.jpg  
  inflating: /content/kaggle/train_images_jpeg/599867773.jpg  
  inflating: /content/kaggle/train_images_jpeg/599872588.jpg  
  inflating: /content/kaggle/train_images_jpeg/600110842.jpg  
  inflating: /content/kaggle/train_images_jpeg/60029813.jpg  
  inflating: /content/kaggle/train_images_jpeg/60038493.jpg  
  inflating: /content/kaggle/train_images_jpeg/600422438.jpg  
  inflating: /content/kaggle/train_images_jpeg/600610735.jpg  
  inflating: /content/kaggle/train_images_jpeg/600691544.jpg  
  inflating: /content/kaggle/train_images_jpeg/600736721.jpg  
  inflating: /content/kaggle/train_images_jpeg/600869262.jpg  
  inflating: /content/kaggle/train_images_jpeg/60094859.jpg  
  inflating: /content/kaggle/train_images_jpeg/601096842.jpg  
  inflating: /content/kaggle/train_images_jpeg/601263353.jpg  
  inflating: /content/kaggle/train_images_jpeg/601644904.jpg  
  inflating: /content/kaggle/train_images_jpeg/602031471.jpg  
  inflating: /content/kaggle/train_images_jpeg/602562857.jpg  
  inflating: /content/kaggle/train_images_jpeg/602798038.jpg  
  inflating: /content/kaggle/train_images_jpeg/602912992.jpg  
  inflating: /content/kaggle/train_images_jpeg/603736760.jpg  
  inflating: /content/kaggle/train_images_jpeg/603756866.jpg  
  inflating: /content/kaggle/train_images_jpeg/604445173.jpg  
  inflating: /content/kaggle/train_images_jpeg/604476990.jpg  
  inflating: /content/kaggle/train_images_jpeg/60495599.jpg  
  inflating: /content/kaggle/train_images_jpeg/605088351.jpg  
  inflating: /content/kaggle/train_images_jpeg/605469419.jpg  
  inflating: /content/kaggle/train_images_jpeg/605794963.jpg  
  inflating: /content/kaggle/train_images_jpeg/605816056.jpg  
  inflating: /content/kaggle/train_images_jpeg/605921029.jpg  
  inflating: /content/kaggle/train_images_jpeg/606006336.jpg  
  inflating: /content/kaggle/train_images_jpeg/606101170.jpg  
  inflating: /content/kaggle/train_images_jpeg/606601717.jpg  
  inflating: /content/kaggle/train_images_jpeg/606691167.jpg  
  inflating: /content/kaggle/train_images_jpeg/606831482.jpg  
  inflating: /content/kaggle/train_images_jpeg/606945473.jpg  
  inflating: /content/kaggle/train_images_jpeg/607008468.jpg  
  inflating: /content/kaggle/train_images_jpeg/607067900.jpg  
  inflating: /content/kaggle/train_images_jpeg/607207422.jpg  
  inflating: /content/kaggle/train_images_jpeg/607627857.jpg  
  inflating: /content/kaggle/train_images_jpeg/607734947.jpg  
  inflating: /content/kaggle/train_images_jpeg/607840807.jpg  
  inflating: /content/kaggle/train_images_jpeg/607886591.jpg  
  inflating: /content/kaggle/train_images_jpeg/608243264.jpg  
  inflating: /content/kaggle/train_images_jpeg/608264330.jpg  
  inflating: /content/kaggle/train_images_jpeg/608266906.jpg  
  inflating: /content/kaggle/train_images_jpeg/608792631.jpg  
  inflating: /content/kaggle/train_images_jpeg/609027712.jpg  
  inflating: /content/kaggle/train_images_jpeg/609134640.jpg  
  inflating: /content/kaggle/train_images_jpeg/609358362.jpg  
  inflating: /content/kaggle/train_images_jpeg/609480856.jpg  
  inflating: /content/kaggle/train_images_jpeg/609857978.jpg  
  inflating: /content/kaggle/train_images_jpeg/610094717.jpg  
  inflating: /content/kaggle/train_images_jpeg/6103.jpg  
  inflating: /content/kaggle/train_images_jpeg/61044687.jpg  
  inflating: /content/kaggle/train_images_jpeg/61074408.jpg  
  inflating: /content/kaggle/train_images_jpeg/610968546.jpg  
  inflating: /content/kaggle/train_images_jpeg/611122414.jpg  
  inflating: /content/kaggle/train_images_jpeg/61139702.jpg  
  inflating: /content/kaggle/train_images_jpeg/611507457.jpg  
  inflating: /content/kaggle/train_images_jpeg/611582421.jpg  
  inflating: /content/kaggle/train_images_jpeg/611767283.jpg  
  inflating: /content/kaggle/train_images_jpeg/611831978.jpg  
  inflating: /content/kaggle/train_images_jpeg/611858169.jpg  
  inflating: /content/kaggle/train_images_jpeg/612054401.jpg  
  inflating: /content/kaggle/train_images_jpeg/61216809.jpg  
  inflating: /content/kaggle/train_images_jpeg/612223117.jpg  
  inflating: /content/kaggle/train_images_jpeg/612296656.jpg  
  inflating: /content/kaggle/train_images_jpeg/612426444.jpg  
  inflating: /content/kaggle/train_images_jpeg/612647551.jpg  
  inflating: /content/kaggle/train_images_jpeg/612680278.jpg  
  inflating: /content/kaggle/train_images_jpeg/612701263.jpg  
  inflating: /content/kaggle/train_images_jpeg/612816896.jpg  
  inflating: /content/kaggle/train_images_jpeg/61297107.jpg  
  inflating: /content/kaggle/train_images_jpeg/613168943.jpg  
  inflating: /content/kaggle/train_images_jpeg/61357519.jpg  
  inflating: /content/kaggle/train_images_jpeg/613608531.jpg  
  inflating: /content/kaggle/train_images_jpeg/61393807.jpg  
  inflating: /content/kaggle/train_images_jpeg/614085740.jpg  
  inflating: /content/kaggle/train_images_jpeg/614181171.jpg  
  inflating: /content/kaggle/train_images_jpeg/614215074.jpg  
  inflating: /content/kaggle/train_images_jpeg/614350420.jpg  
  inflating: /content/kaggle/train_images_jpeg/614363476.jpg  
  inflating: /content/kaggle/train_images_jpeg/614423071.jpg  
  inflating: /content/kaggle/train_images_jpeg/614554751.jpg  
  inflating: /content/kaggle/train_images_jpeg/61492497.jpg  
  inflating: /content/kaggle/train_images_jpeg/615415014.jpg  
  inflating: /content/kaggle/train_images_jpeg/616067166.jpg  
  inflating: /content/kaggle/train_images_jpeg/616109576.jpg  
  inflating: /content/kaggle/train_images_jpeg/616514000.jpg  
  inflating: /content/kaggle/train_images_jpeg/616531930.jpg  
  inflating: /content/kaggle/train_images_jpeg/616718743.jpg  
  inflating: /content/kaggle/train_images_jpeg/616740640.jpg  
  inflating: /content/kaggle/train_images_jpeg/616745238.jpg  
  inflating: /content/kaggle/train_images_jpeg/616889374.jpg  
  inflating: /content/kaggle/train_images_jpeg/616937230.jpg  
  inflating: /content/kaggle/train_images_jpeg/617446207.jpg  
  inflating: /content/kaggle/train_images_jpeg/617446787.jpg  
  inflating: /content/kaggle/train_images_jpeg/617651411.jpg  
  inflating: /content/kaggle/train_images_jpeg/617719193.jpg  
  inflating: /content/kaggle/train_images_jpeg/617763677.jpg  
  inflating: /content/kaggle/train_images_jpeg/618049831.jpg  
  inflating: /content/kaggle/train_images_jpeg/618242268.jpg  
  inflating: /content/kaggle/train_images_jpeg/618257527.jpg  
  inflating: /content/kaggle/train_images_jpeg/618285041.jpg  
  inflating: /content/kaggle/train_images_jpeg/618525974.jpg  
  inflating: /content/kaggle/train_images_jpeg/618654809.jpg  
  inflating: /content/kaggle/train_images_jpeg/618683385.jpg  
  inflating: /content/kaggle/train_images_jpeg/618816554.jpg  
  inflating: /content/kaggle/train_images_jpeg/618916143.jpg  
  inflating: /content/kaggle/train_images_jpeg/61901680.jpg  
  inflating: /content/kaggle/train_images_jpeg/619095657.jpg  
  inflating: /content/kaggle/train_images_jpeg/619372394.jpg  
  inflating: /content/kaggle/train_images_jpeg/619658845.jpg  
  inflating: /content/kaggle/train_images_jpeg/619953066.jpg  
  inflating: /content/kaggle/train_images_jpeg/620126996.jpg  
  inflating: /content/kaggle/train_images_jpeg/620158263.jpg  
  inflating: /content/kaggle/train_images_jpeg/62053025.jpg  
  inflating: /content/kaggle/train_images_jpeg/62069424.jpg  
  inflating: /content/kaggle/train_images_jpeg/62070739.jpg  
  inflating: /content/kaggle/train_images_jpeg/620741082.jpg  
  inflating: /content/kaggle/train_images_jpeg/620752009.jpg  
  inflating: /content/kaggle/train_images_jpeg/620790397.jpg  
  inflating: /content/kaggle/train_images_jpeg/620825319.jpg  
  inflating: /content/kaggle/train_images_jpeg/620927832.jpg  
  inflating: /content/kaggle/train_images_jpeg/621125183.jpg  
  inflating: /content/kaggle/train_images_jpeg/621131184.jpg  
  inflating: /content/kaggle/train_images_jpeg/621367062.jpg  
  inflating: /content/kaggle/train_images_jpeg/621642656.jpg  
  inflating: /content/kaggle/train_images_jpeg/622130666.jpg  
  inflating: /content/kaggle/train_images_jpeg/622186063.jpg  
  inflating: /content/kaggle/train_images_jpeg/622285967.jpg  
  inflating: /content/kaggle/train_images_jpeg/622386644.jpg  
  inflating: /content/kaggle/train_images_jpeg/622555654.jpg  
  inflating: /content/kaggle/train_images_jpeg/622587109.jpg  
  inflating: /content/kaggle/train_images_jpeg/622599265.jpg  
  inflating: /content/kaggle/train_images_jpeg/623023838.jpg  
  inflating: /content/kaggle/train_images_jpeg/623333046.jpg  
  inflating: /content/kaggle/train_images_jpeg/623381434.jpg  
  inflating: /content/kaggle/train_images_jpeg/623631977.jpg  
  inflating: /content/kaggle/train_images_jpeg/624542244.jpg  
  inflating: /content/kaggle/train_images_jpeg/62457077.jpg  
  inflating: /content/kaggle/train_images_jpeg/624872321.jpg  
  inflating: /content/kaggle/train_images_jpeg/624911036.jpg  
  inflating: /content/kaggle/train_images_jpeg/624921461.jpg  
  inflating: /content/kaggle/train_images_jpeg/625159901.jpg  
  inflating: /content/kaggle/train_images_jpeg/625250328.jpg  
  inflating: /content/kaggle/train_images_jpeg/625258862.jpg  
  inflating: /content/kaggle/train_images_jpeg/625604215.jpg  
  inflating: /content/kaggle/train_images_jpeg/626727559.jpg  
  inflating: /content/kaggle/train_images_jpeg/626955644.jpg  
  inflating: /content/kaggle/train_images_jpeg/627068686.jpg  
  inflating: /content/kaggle/train_images_jpeg/627428671.jpg  
  inflating: /content/kaggle/train_images_jpeg/62771226.jpg  
  inflating: /content/kaggle/train_images_jpeg/628074703.jpg  
  inflating: /content/kaggle/train_images_jpeg/628142575.jpg  
  inflating: /content/kaggle/train_images_jpeg/628546721.jpg  
  inflating: /content/kaggle/train_images_jpeg/628791743.jpg  
  inflating: /content/kaggle/train_images_jpeg/628889573.jpg  
  inflating: /content/kaggle/train_images_jpeg/629341978.jpg  
  inflating: /content/kaggle/train_images_jpeg/629637059.jpg  
  inflating: /content/kaggle/train_images_jpeg/629698342.jpg  
  inflating: /content/kaggle/train_images_jpeg/629896725.jpg  
  inflating: /content/kaggle/train_images_jpeg/629958689.jpg  
  inflating: /content/kaggle/train_images_jpeg/630211324.jpg  
  inflating: /content/kaggle/train_images_jpeg/630240307.jpg  
  inflating: /content/kaggle/train_images_jpeg/630407730.jpg  
  inflating: /content/kaggle/train_images_jpeg/630454798.jpg  
  inflating: /content/kaggle/train_images_jpeg/630537916.jpg  
  inflating: /content/kaggle/train_images_jpeg/630797550.jpg  
  inflating: /content/kaggle/train_images_jpeg/630798966.jpg  
  inflating: /content/kaggle/train_images_jpeg/631049662.jpg  
  inflating: /content/kaggle/train_images_jpeg/631221436.jpg  
  inflating: /content/kaggle/train_images_jpeg/631309846.jpg  
  inflating: /content/kaggle/train_images_jpeg/631325296.jpg  
  inflating: /content/kaggle/train_images_jpeg/631430009.jpg  
  inflating: /content/kaggle/train_images_jpeg/631563709.jpg  
  inflating: /content/kaggle/train_images_jpeg/63159897.jpg  
  inflating: /content/kaggle/train_images_jpeg/631607680.jpg  
  inflating: /content/kaggle/train_images_jpeg/631676303.jpg  
  inflating: /content/kaggle/train_images_jpeg/631746612.jpg  
  inflating: /content/kaggle/train_images_jpeg/631859689.jpg  
  inflating: /content/kaggle/train_images_jpeg/631890170.jpg  
  inflating: /content/kaggle/train_images_jpeg/631967336.jpg  
  inflating: /content/kaggle/train_images_jpeg/632197705.jpg  
  inflating: /content/kaggle/train_images_jpeg/632236115.jpg  
  inflating: /content/kaggle/train_images_jpeg/632357010.jpg  
  inflating: /content/kaggle/train_images_jpeg/632417341.jpg  
  inflating: /content/kaggle/train_images_jpeg/632445353.jpg  
  inflating: /content/kaggle/train_images_jpeg/632517607.jpg  
  inflating: /content/kaggle/train_images_jpeg/632697564.jpg  
  inflating: /content/kaggle/train_images_jpeg/632799335.jpg  
  inflating: /content/kaggle/train_images_jpeg/633010478.jpg  
  inflating: /content/kaggle/train_images_jpeg/633081194.jpg  
  inflating: /content/kaggle/train_images_jpeg/633900413.jpg  
  inflating: /content/kaggle/train_images_jpeg/633946965.jpg  
  inflating: /content/kaggle/train_images_jpeg/634365236.jpg  
  inflating: /content/kaggle/train_images_jpeg/634618230.jpg  
  inflating: /content/kaggle/train_images_jpeg/634724499.jpg  
  inflating: /content/kaggle/train_images_jpeg/634785695.jpg  
  inflating: /content/kaggle/train_images_jpeg/634792920.jpg  
  inflating: /content/kaggle/train_images_jpeg/634816572.jpg  
  inflating: /content/kaggle/train_images_jpeg/635122883.jpg  
  inflating: /content/kaggle/train_images_jpeg/635279232.jpg  
  inflating: /content/kaggle/train_images_jpeg/635341993.jpg  
  inflating: /content/kaggle/train_images_jpeg/635511735.jpg  
  inflating: /content/kaggle/train_images_jpeg/635576141.jpg  
  inflating: /content/kaggle/train_images_jpeg/635664264.jpg  
  inflating: /content/kaggle/train_images_jpeg/63578884.jpg  
  inflating: /content/kaggle/train_images_jpeg/635946158.jpg  
  inflating: /content/kaggle/train_images_jpeg/636286001.jpg  
  inflating: /content/kaggle/train_images_jpeg/636474296.jpg  
  inflating: /content/kaggle/train_images_jpeg/636559480.jpg  
  inflating: /content/kaggle/train_images_jpeg/636816861.jpg  
  inflating: /content/kaggle/train_images_jpeg/636890802.jpg  
  inflating: /content/kaggle/train_images_jpeg/636948047.jpg  
  inflating: /content/kaggle/train_images_jpeg/63775422.jpg  
  inflating: /content/kaggle/train_images_jpeg/637906306.jpg  
  inflating: /content/kaggle/train_images_jpeg/638654515.jpg  
  inflating: /content/kaggle/train_images_jpeg/639060341.jpg  
  inflating: /content/kaggle/train_images_jpeg/639068838.jpg  
  inflating: /content/kaggle/train_images_jpeg/639229623.jpg  
  inflating: /content/kaggle/train_images_jpeg/640157848.jpg  
  inflating: /content/kaggle/train_images_jpeg/640668148.jpg  
  inflating: /content/kaggle/train_images_jpeg/640671691.jpg  
  inflating: /content/kaggle/train_images_jpeg/640674729.jpg  
  inflating: /content/kaggle/train_images_jpeg/641096322.jpg  
  inflating: /content/kaggle/train_images_jpeg/641309732.jpg  
  inflating: /content/kaggle/train_images_jpeg/641583443.jpg  
  inflating: /content/kaggle/train_images_jpeg/641590483.jpg  
  inflating: /content/kaggle/train_images_jpeg/641625656.jpg  
  inflating: /content/kaggle/train_images_jpeg/641852090.jpg  
  inflating: /content/kaggle/train_images_jpeg/641947553.jpg  
  inflating: /content/kaggle/train_images_jpeg/642333740.jpg  
  inflating: /content/kaggle/train_images_jpeg/64287317.jpg  
  inflating: /content/kaggle/train_images_jpeg/643008801.jpg  
  inflating: /content/kaggle/train_images_jpeg/643044892.jpg  
  inflating: /content/kaggle/train_images_jpeg/643163594.jpg  
  inflating: /content/kaggle/train_images_jpeg/643541195.jpg  
  inflating: /content/kaggle/train_images_jpeg/643613398.jpg  
  inflating: /content/kaggle/train_images_jpeg/643956994.jpg  
  inflating: /content/kaggle/train_images_jpeg/644131683.jpg  
  inflating: /content/kaggle/train_images_jpeg/644212609.jpg  
  inflating: /content/kaggle/train_images_jpeg/6442965.jpg  
  inflating: /content/kaggle/train_images_jpeg/644617197.jpg  
  inflating: /content/kaggle/train_images_jpeg/644666904.jpg  
  inflating: /content/kaggle/train_images_jpeg/645139700.jpg  
  inflating: /content/kaggle/train_images_jpeg/645166434.jpg  
  inflating: /content/kaggle/train_images_jpeg/645203852.jpg  
  inflating: /content/kaggle/train_images_jpeg/645674702.jpg  
  inflating: /content/kaggle/train_images_jpeg/645726700.jpg  
  inflating: /content/kaggle/train_images_jpeg/645748752.jpg  
  inflating: /content/kaggle/train_images_jpeg/645764425.jpg  
  inflating: /content/kaggle/train_images_jpeg/645991519.jpg  
  inflating: /content/kaggle/train_images_jpeg/64610911.jpg  
  inflating: /content/kaggle/train_images_jpeg/646595988.jpg  
  inflating: /content/kaggle/train_images_jpeg/646796085.jpg  
  inflating: /content/kaggle/train_images_jpeg/646841236.jpg  
  inflating: /content/kaggle/train_images_jpeg/646903835.jpg  
  inflating: /content/kaggle/train_images_jpeg/646999993.jpg  
  inflating: /content/kaggle/train_images_jpeg/647038320.jpg  
  inflating: /content/kaggle/train_images_jpeg/647141648.jpg  
  inflating: /content/kaggle/train_images_jpeg/647301407.jpg  
  inflating: /content/kaggle/train_images_jpeg/64732457.jpg  
  inflating: /content/kaggle/train_images_jpeg/647379181.jpg  
  inflating: /content/kaggle/train_images_jpeg/6477704.jpg  
  inflating: /content/kaggle/train_images_jpeg/648013564.jpg  
  inflating: /content/kaggle/train_images_jpeg/648328136.jpg  
  inflating: /content/kaggle/train_images_jpeg/648438978.jpg  
  inflating: /content/kaggle/train_images_jpeg/648490394.jpg  
  inflating: /content/kaggle/train_images_jpeg/648535358.jpg  
  inflating: /content/kaggle/train_images_jpeg/648590846.jpg  
  inflating: /content/kaggle/train_images_jpeg/648616108.jpg  
  inflating: /content/kaggle/train_images_jpeg/648870866.jpg  
  inflating: /content/kaggle/train_images_jpeg/649044628.jpg  
  inflating: /content/kaggle/train_images_jpeg/649463618.jpg  
  inflating: /content/kaggle/train_images_jpeg/650372735.jpg  
  inflating: /content/kaggle/train_images_jpeg/650458335.jpg  
  inflating: /content/kaggle/train_images_jpeg/650816529.jpg  
  inflating: /content/kaggle/train_images_jpeg/650963380.jpg  
  inflating: /content/kaggle/train_images_jpeg/651017189.jpg  
  inflating: /content/kaggle/train_images_jpeg/651041869.jpg  
  inflating: /content/kaggle/train_images_jpeg/651123589.jpg  
  inflating: /content/kaggle/train_images_jpeg/651255888.jpg  
  inflating: /content/kaggle/train_images_jpeg/651331224.jpg  
  inflating: /content/kaggle/train_images_jpeg/65139094.jpg  
  inflating: /content/kaggle/train_images_jpeg/651635547.jpg  
  inflating: /content/kaggle/train_images_jpeg/651791438.jpg  
  inflating: /content/kaggle/train_images_jpeg/652147847.jpg  
  inflating: /content/kaggle/train_images_jpeg/65235972.jpg  
  inflating: /content/kaggle/train_images_jpeg/652381513.jpg  
  inflating: /content/kaggle/train_images_jpeg/652624585.jpg  
  inflating: /content/kaggle/train_images_jpeg/65328715.jpg  
  inflating: /content/kaggle/train_images_jpeg/65344468.jpg  
  inflating: /content/kaggle/train_images_jpeg/653454326.jpg  
  inflating: /content/kaggle/train_images_jpeg/653465782.jpg  
  inflating: /content/kaggle/train_images_jpeg/653660984.jpg  
  inflating: /content/kaggle/train_images_jpeg/653790605.jpg  
  inflating: /content/kaggle/train_images_jpeg/653958117.jpg  
  inflating: /content/kaggle/train_images_jpeg/654307881.jpg  
  inflating: /content/kaggle/train_images_jpeg/654346166.jpg  
  inflating: /content/kaggle/train_images_jpeg/654445822.jpg  
  inflating: /content/kaggle/train_images_jpeg/654671746.jpg  
  inflating: /content/kaggle/train_images_jpeg/654782602.jpg  
  inflating: /content/kaggle/train_images_jpeg/654992578.jpg  
  inflating: /content/kaggle/train_images_jpeg/655836057.jpg  
  inflating: /content/kaggle/train_images_jpeg/655873382.jpg  
  inflating: /content/kaggle/train_images_jpeg/656522898.jpg  
  inflating: /content/kaggle/train_images_jpeg/65671451.jpg  
  inflating: /content/kaggle/train_images_jpeg/657031133.jpg  
  inflating: /content/kaggle/train_images_jpeg/657278738.jpg  
  inflating: /content/kaggle/train_images_jpeg/657403248.jpg  
  inflating: /content/kaggle/train_images_jpeg/657424989.jpg  
  inflating: /content/kaggle/train_images_jpeg/657542940.jpg  
  inflating: /content/kaggle/train_images_jpeg/657747231.jpg  
  inflating: /content/kaggle/train_images_jpeg/657747378.jpg  
  inflating: /content/kaggle/train_images_jpeg/657817116.jpg  
  inflating: /content/kaggle/train_images_jpeg/657823258.jpg  
  inflating: /content/kaggle/train_images_jpeg/657935270.jpg  
  inflating: /content/kaggle/train_images_jpeg/658043427.jpg  
  inflating: /content/kaggle/train_images_jpeg/658285764.jpg  
  inflating: /content/kaggle/train_images_jpeg/658300616.jpg  
  inflating: /content/kaggle/train_images_jpeg/658395701.jpg  
  inflating: /content/kaggle/train_images_jpeg/658617440.jpg  
  inflating: /content/kaggle/train_images_jpeg/658961090.jpg  
  inflating: /content/kaggle/train_images_jpeg/659315200.jpg  
  inflating: /content/kaggle/train_images_jpeg/65949096.jpg  
  inflating: /content/kaggle/train_images_jpeg/659495074.jpg  
  inflating: /content/kaggle/train_images_jpeg/659615367.jpg  
  inflating: /content/kaggle/train_images_jpeg/659696981.jpg  
  inflating: /content/kaggle/train_images_jpeg/659737430.jpg  
  inflating: /content/kaggle/train_images_jpeg/660261179.jpg  
  inflating: /content/kaggle/train_images_jpeg/660273630.jpg  
  inflating: /content/kaggle/train_images_jpeg/660374182.jpg  
  inflating: /content/kaggle/train_images_jpeg/660699898.jpg  
  inflating: /content/kaggle/train_images_jpeg/660715584.jpg  
  inflating: /content/kaggle/train_images_jpeg/660729197.jpg  
  inflating: /content/kaggle/train_images_jpeg/66116561.jpg  
  inflating: /content/kaggle/train_images_jpeg/661256835.jpg  
  inflating: /content/kaggle/train_images_jpeg/66126211.jpg  
  inflating: /content/kaggle/train_images_jpeg/661263276.jpg  
  inflating: /content/kaggle/train_images_jpeg/661610886.jpg  
  inflating: /content/kaggle/train_images_jpeg/661795879.jpg  
  inflating: /content/kaggle/train_images_jpeg/662050128.jpg  
  inflating: /content/kaggle/train_images_jpeg/662317211.jpg  
  inflating: /content/kaggle/train_images_jpeg/662372109.jpg  
  inflating: /content/kaggle/train_images_jpeg/66240294.jpg  
  inflating: /content/kaggle/train_images_jpeg/662783465.jpg  
  inflating: /content/kaggle/train_images_jpeg/662844751.jpg  
  inflating: /content/kaggle/train_images_jpeg/663146106.jpg  
  inflating: /content/kaggle/train_images_jpeg/663803096.jpg  
  inflating: /content/kaggle/train_images_jpeg/663810012.jpg  
  inflating: /content/kaggle/train_images_jpeg/664024610.jpg  
  inflating: /content/kaggle/train_images_jpeg/664137344.jpg  
  inflating: /content/kaggle/train_images_jpeg/664265007.jpg  
  inflating: /content/kaggle/train_images_jpeg/664408485.jpg  
  inflating: /content/kaggle/train_images_jpeg/66458318.jpg  
  inflating: /content/kaggle/train_images_jpeg/664583876.jpg  
  inflating: /content/kaggle/train_images_jpeg/66494240.jpg  
  inflating: /content/kaggle/train_images_jpeg/664943933.jpg  
  inflating: /content/kaggle/train_images_jpeg/664996949.jpg  
  inflating: /content/kaggle/train_images_jpeg/665478889.jpg  
  inflating: /content/kaggle/train_images_jpeg/66571398.jpg  
  inflating: /content/kaggle/train_images_jpeg/665859596.jpg  
  inflating: /content/kaggle/train_images_jpeg/666057688.jpg  
  inflating: /content/kaggle/train_images_jpeg/666145174.jpg  
  inflating: /content/kaggle/train_images_jpeg/667058681.jpg  
  inflating: /content/kaggle/train_images_jpeg/667064229.jpg  
  inflating: /content/kaggle/train_images_jpeg/66720017.jpg  
  inflating: /content/kaggle/train_images_jpeg/667282886.jpg  
  inflating: /content/kaggle/train_images_jpeg/667745883.jpg  
  inflating: /content/kaggle/train_images_jpeg/667790094.jpg  
  inflating: /content/kaggle/train_images_jpeg/668151635.jpg  
  inflating: /content/kaggle/train_images_jpeg/66820054.jpg  
  inflating: /content/kaggle/train_images_jpeg/668811521.jpg  
  inflating: /content/kaggle/train_images_jpeg/668943288.jpg  
  inflating: /content/kaggle/train_images_jpeg/669119596.jpg  
  inflating: /content/kaggle/train_images_jpeg/669360547.jpg  
  inflating: /content/kaggle/train_images_jpeg/669612316.jpg  
  inflating: /content/kaggle/train_images_jpeg/669748740.jpg  
  inflating: /content/kaggle/train_images_jpeg/670049521.jpg  
  inflating: /content/kaggle/train_images_jpeg/670363237.jpg  
  inflating: /content/kaggle/train_images_jpeg/670519295.jpg  
  inflating: /content/kaggle/train_images_jpeg/670541081.jpg  
  inflating: /content/kaggle/train_images_jpeg/670606517.jpg  
  inflating: /content/kaggle/train_images_jpeg/670877458.jpg  
  inflating: /content/kaggle/train_images_jpeg/670935164.jpg  
  inflating: /content/kaggle/train_images_jpeg/670991329.jpg  
  inflating: /content/kaggle/train_images_jpeg/671076744.jpg  
  inflating: /content/kaggle/train_images_jpeg/671675016.jpg  
  inflating: /content/kaggle/train_images_jpeg/671677199.jpg  
  inflating: /content/kaggle/train_images_jpeg/671906195.jpg  
  inflating: /content/kaggle/train_images_jpeg/671937589.jpg  
  inflating: /content/kaggle/train_images_jpeg/671949861.jpg  
  inflating: /content/kaggle/train_images_jpeg/672149291.jpg  
  inflating: /content/kaggle/train_images_jpeg/67235681.jpg  
  inflating: /content/kaggle/train_images_jpeg/672387843.jpg  
  inflating: /content/kaggle/train_images_jpeg/672634169.jpg  
  inflating: /content/kaggle/train_images_jpeg/672737517.jpg  
  inflating: /content/kaggle/train_images_jpeg/672772302.jpg  
  inflating: /content/kaggle/train_images_jpeg/673461056.jpg  
  inflating: /content/kaggle/train_images_jpeg/673860639.jpg  
  inflating: /content/kaggle/train_images_jpeg/673868311.jpg  
  inflating: /content/kaggle/train_images_jpeg/673903398.jpg  
  inflating: /content/kaggle/train_images_jpeg/673931298.jpg  
  inflating: /content/kaggle/train_images_jpeg/674072472.jpg  
  inflating: /content/kaggle/train_images_jpeg/67417136.jpg  
  inflating: /content/kaggle/train_images_jpeg/674205254.jpg  
  inflating: /content/kaggle/train_images_jpeg/674360414.jpg  
  inflating: /content/kaggle/train_images_jpeg/674380607.jpg  
  inflating: /content/kaggle/train_images_jpeg/674703368.jpg  
  inflating: /content/kaggle/train_images_jpeg/674806764.jpg  
  inflating: /content/kaggle/train_images_jpeg/674941646.jpg  
  inflating: /content/kaggle/train_images_jpeg/675146219.jpg  
  inflating: /content/kaggle/train_images_jpeg/675264849.jpg  
  inflating: /content/kaggle/train_images_jpeg/675325967.jpg  
  inflating: /content/kaggle/train_images_jpeg/67533463.jpg  
  inflating: /content/kaggle/train_images_jpeg/676226256.jpg  
  inflating: /content/kaggle/train_images_jpeg/677178045.jpg  
  inflating: /content/kaggle/train_images_jpeg/677537252.jpg  
  inflating: /content/kaggle/train_images_jpeg/677634085.jpg  
  inflating: /content/kaggle/train_images_jpeg/677816697.jpg  
  inflating: /content/kaggle/train_images_jpeg/677870514.jpg  
  inflating: /content/kaggle/train_images_jpeg/678150539.jpg  
  inflating: /content/kaggle/train_images_jpeg/678308655.jpg  
  inflating: /content/kaggle/train_images_jpeg/678699468.jpg  
  inflating: /content/kaggle/train_images_jpeg/678707458.jpg  
  inflating: /content/kaggle/train_images_jpeg/678743430.jpg  
  inflating: /content/kaggle/train_images_jpeg/678779380.jpg  
  inflating: /content/kaggle/train_images_jpeg/6788393.jpg  
  inflating: /content/kaggle/train_images_jpeg/678943117.jpg  
  inflating: /content/kaggle/train_images_jpeg/678969911.jpg  
  inflating: /content/kaggle/train_images_jpeg/679033130.jpg  
  inflating: /content/kaggle/train_images_jpeg/679212500.jpg  
  inflating: /content/kaggle/train_images_jpeg/679522078.jpg  
  inflating: /content/kaggle/train_images_jpeg/679718743.jpg  
  inflating: /content/kaggle/train_images_jpeg/679887404.jpg  
  inflating: /content/kaggle/train_images_jpeg/679977941.jpg  
  inflating: /content/kaggle/train_images_jpeg/680272982.jpg  
  inflating: /content/kaggle/train_images_jpeg/680596021.jpg  
  inflating: /content/kaggle/train_images_jpeg/680707413.jpg  
  inflating: /content/kaggle/train_images_jpeg/680852379.jpg  
  inflating: /content/kaggle/train_images_jpeg/680910518.jpg  
  inflating: /content/kaggle/train_images_jpeg/681073401.jpg  
  inflating: /content/kaggle/train_images_jpeg/681211585.jpg  
  inflating: /content/kaggle/train_images_jpeg/68141141.jpg  
  inflating: /content/kaggle/train_images_jpeg/681602202.jpg  
  inflating: /content/kaggle/train_images_jpeg/681610474.jpg  
  inflating: /content/kaggle/train_images_jpeg/681698816.jpg  
  inflating: /content/kaggle/train_images_jpeg/682135395.jpg  
  inflating: /content/kaggle/train_images_jpeg/682215276.jpg  
  inflating: /content/kaggle/train_images_jpeg/682271538.jpg  
  inflating: /content/kaggle/train_images_jpeg/682973253.jpg  
  inflating: /content/kaggle/train_images_jpeg/683096346.jpg  
  inflating: /content/kaggle/train_images_jpeg/683136495.jpg  
  inflating: /content/kaggle/train_images_jpeg/683492948.jpg  
  inflating: /content/kaggle/train_images_jpeg/684887397.jpg  
  inflating: /content/kaggle/train_images_jpeg/684911390.jpg  
  inflating: /content/kaggle/train_images_jpeg/685003567.jpg  
  inflating: /content/kaggle/train_images_jpeg/685053856.jpg  
  inflating: /content/kaggle/train_images_jpeg/685199622.jpg  
  inflating: /content/kaggle/train_images_jpeg/685497354.jpg  
  inflating: /content/kaggle/train_images_jpeg/68550961.jpg  
  inflating: /content/kaggle/train_images_jpeg/685533220.jpg  
  inflating: /content/kaggle/train_images_jpeg/685596470.jpg  
  inflating: /content/kaggle/train_images_jpeg/685742976.jpg  
  inflating: /content/kaggle/train_images_jpeg/685822440.jpg  
  inflating: /content/kaggle/train_images_jpeg/685840333.jpg  
  inflating: /content/kaggle/train_images_jpeg/685844269.jpg  
  inflating: /content/kaggle/train_images_jpeg/686071324.jpg  
  inflating: /content/kaggle/train_images_jpeg/686102337.jpg  
  inflating: /content/kaggle/train_images_jpeg/686214048.jpg  
  inflating: /content/kaggle/train_images_jpeg/686263581.jpg  
  inflating: /content/kaggle/train_images_jpeg/686316627.jpg  
  inflating: /content/kaggle/train_images_jpeg/686503891.jpg  
  inflating: /content/kaggle/train_images_jpeg/686958649.jpg  
  inflating: /content/kaggle/train_images_jpeg/687245677.jpg  
  inflating: /content/kaggle/train_images_jpeg/68735991.jpg  
  inflating: /content/kaggle/train_images_jpeg/687533013.jpg  
  inflating: /content/kaggle/train_images_jpeg/68761769.jpg  
  inflating: /content/kaggle/train_images_jpeg/68764231.jpg  
  inflating: /content/kaggle/train_images_jpeg/687693766.jpg  
  inflating: /content/kaggle/train_images_jpeg/687753518.jpg  
  inflating: /content/kaggle/train_images_jpeg/687913373.jpg  
  inflating: /content/kaggle/train_images_jpeg/687931574.jpg  
  inflating: /content/kaggle/train_images_jpeg/688011612.jpg  
  inflating: /content/kaggle/train_images_jpeg/688243919.jpg  
  inflating: /content/kaggle/train_images_jpeg/688266741.jpg  
  inflating: /content/kaggle/train_images_jpeg/688489193.jpg  
  inflating: /content/kaggle/train_images_jpeg/688733567.jpg  
  inflating: /content/kaggle/train_images_jpeg/688748124.jpg  
  inflating: /content/kaggle/train_images_jpeg/689108493.jpg  
  inflating: /content/kaggle/train_images_jpeg/689866725.jpg  
  inflating: /content/kaggle/train_images_jpeg/69003295.jpg  
  inflating: /content/kaggle/train_images_jpeg/690125781.jpg  
  inflating: /content/kaggle/train_images_jpeg/690163.jpg  
  inflating: /content/kaggle/train_images_jpeg/690221576.jpg  
  inflating: /content/kaggle/train_images_jpeg/690258961.jpg  
  inflating: /content/kaggle/train_images_jpeg/69026823.jpg  
  inflating: /content/kaggle/train_images_jpeg/690368559.jpg  
  inflating: /content/kaggle/train_images_jpeg/690399930.jpg  
  inflating: /content/kaggle/train_images_jpeg/690440568.jpg  
  inflating: /content/kaggle/train_images_jpeg/690564008.jpg  
  inflating: /content/kaggle/train_images_jpeg/690565188.jpg  
  inflating: /content/kaggle/train_images_jpeg/690578148.jpg  
  inflating: /content/kaggle/train_images_jpeg/690627061.jpg  
  inflating: /content/kaggle/train_images_jpeg/690967280.jpg  
  inflating: /content/kaggle/train_images_jpeg/69119767.jpg  
  inflating: /content/kaggle/train_images_jpeg/691231499.jpg  
  inflating: /content/kaggle/train_images_jpeg/691285209.jpg  
  inflating: /content/kaggle/train_images_jpeg/691286710.jpg  
  inflating: /content/kaggle/train_images_jpeg/691829328.jpg  
  inflating: /content/kaggle/train_images_jpeg/692019924.jpg  
  inflating: /content/kaggle/train_images_jpeg/692022283.jpg  
  inflating: /content/kaggle/train_images_jpeg/692398741.jpg  
  inflating: /content/kaggle/train_images_jpeg/692727457.jpg  
  inflating: /content/kaggle/train_images_jpeg/692997740.jpg  
  inflating: /content/kaggle/train_images_jpeg/693123459.jpg  
  inflating: /content/kaggle/train_images_jpeg/693164586.jpg  
  inflating: /content/kaggle/train_images_jpeg/693412624.jpg  
  inflating: /content/kaggle/train_images_jpeg/693609543.jpg  
  inflating: /content/kaggle/train_images_jpeg/693678702.jpg  
  inflating: /content/kaggle/train_images_jpeg/693711677.jpg  
  inflating: /content/kaggle/train_images_jpeg/694303061.jpg  
  inflating: /content/kaggle/train_images_jpeg/694387219.jpg  
  inflating: /content/kaggle/train_images_jpeg/694767625.jpg  
  inflating: /content/kaggle/train_images_jpeg/695000133.jpg  
  inflating: /content/kaggle/train_images_jpeg/695167489.jpg  
  inflating: /content/kaggle/train_images_jpeg/695172067.jpg  
  inflating: /content/kaggle/train_images_jpeg/695438825.jpg  
  inflating: /content/kaggle/train_images_jpeg/695839663.jpg  
  inflating: /content/kaggle/train_images_jpeg/695924951.jpg  
  inflating: /content/kaggle/train_images_jpeg/696062925.jpg  
  inflating: /content/kaggle/train_images_jpeg/696072814.jpg  
  inflating: /content/kaggle/train_images_jpeg/696538469.jpg  
  inflating: /content/kaggle/train_images_jpeg/696638670.jpg  
  inflating: /content/kaggle/train_images_jpeg/696867083.jpg  
  inflating: /content/kaggle/train_images_jpeg/697032846.jpg  
  inflating: /content/kaggle/train_images_jpeg/697372150.jpg  
  inflating: /content/kaggle/train_images_jpeg/697621030.jpg  
  inflating: /content/kaggle/train_images_jpeg/697821709.jpg  
  inflating: /content/kaggle/train_images_jpeg/697962684.jpg  
  inflating: /content/kaggle/train_images_jpeg/69803851.jpg  
  inflating: /content/kaggle/train_images_jpeg/698154366.jpg  
  inflating: /content/kaggle/train_images_jpeg/698230072.jpg  
  inflating: /content/kaggle/train_images_jpeg/698646619.jpg  
  inflating: /content/kaggle/train_images_jpeg/698692514.jpg  
  inflating: /content/kaggle/train_images_jpeg/69869891.jpg  
  inflating: /content/kaggle/train_images_jpeg/698853568.jpg  
  inflating: /content/kaggle/train_images_jpeg/698931163.jpg  
  inflating: /content/kaggle/train_images_jpeg/699261554.jpg  
  inflating: /content/kaggle/train_images_jpeg/699282565.jpg  
  inflating: /content/kaggle/train_images_jpeg/699330995.jpg  
  inflating: /content/kaggle/train_images_jpeg/699393181.jpg  
  inflating: /content/kaggle/train_images_jpeg/699893195.jpg  
  inflating: /content/kaggle/train_images_jpeg/699952648.jpg  
  inflating: /content/kaggle/train_images_jpeg/699957994.jpg  
  inflating: /content/kaggle/train_images_jpeg/700113045.jpg  
  inflating: /content/kaggle/train_images_jpeg/700464495.jpg  
  inflating: /content/kaggle/train_images_jpeg/700664783.jpg  
  inflating: /content/kaggle/train_images_jpeg/700772842.jpg  
  inflating: /content/kaggle/train_images_jpeg/700919274.jpg  
  inflating: /content/kaggle/train_images_jpeg/700971789.jpg  
  inflating: /content/kaggle/train_images_jpeg/701052546.jpg  
  inflating: /content/kaggle/train_images_jpeg/701148586.jpg  
  inflating: /content/kaggle/train_images_jpeg/701496880.jpg  
  inflating: /content/kaggle/train_images_jpeg/701698487.jpg  
  inflating: /content/kaggle/train_images_jpeg/701939948.jpg  
  inflating: /content/kaggle/train_images_jpeg/702121018.jpg  
  inflating: /content/kaggle/train_images_jpeg/702619228.jpg  
  inflating: /content/kaggle/train_images_jpeg/702921718.jpg  
  inflating: /content/kaggle/train_images_jpeg/702974599.jpg  
  inflating: /content/kaggle/train_images_jpeg/702998173.jpg  
  inflating: /content/kaggle/train_images_jpeg/703084766.jpg  
  inflating: /content/kaggle/train_images_jpeg/703096302.jpg  
  inflating: /content/kaggle/train_images_jpeg/703310122.jpg  
  inflating: /content/kaggle/train_images_jpeg/703444371.jpg  
  inflating: /content/kaggle/train_images_jpeg/704115558.jpg  
  inflating: /content/kaggle/train_images_jpeg/70412561.jpg  
  inflating: /content/kaggle/train_images_jpeg/704269024.jpg  
  inflating: /content/kaggle/train_images_jpeg/704485270.jpg  
  inflating: /content/kaggle/train_images_jpeg/704504922.jpg  
  inflating: /content/kaggle/train_images_jpeg/70462322.jpg  
  inflating: /content/kaggle/train_images_jpeg/704827087.jpg  
  inflating: /content/kaggle/train_images_jpeg/704856896.jpg  
  inflating: /content/kaggle/train_images_jpeg/705481569.jpg  
  inflating: /content/kaggle/train_images_jpeg/705499651.jpg  
  inflating: /content/kaggle/train_images_jpeg/705789219.jpg  
  inflating: /content/kaggle/train_images_jpeg/705886704.jpg  
  inflating: /content/kaggle/train_images_jpeg/705928796.jpg  
  inflating: /content/kaggle/train_images_jpeg/70656521.jpg  
  inflating: /content/kaggle/train_images_jpeg/706776365.jpg  
  inflating: /content/kaggle/train_images_jpeg/706806140.jpg  
  inflating: /content/kaggle/train_images_jpeg/706808191.jpg  
  inflating: /content/kaggle/train_images_jpeg/70700352.jpg  
  inflating: /content/kaggle/train_images_jpeg/707255804.jpg  
  inflating: /content/kaggle/train_images_jpeg/707347112.jpg  
  inflating: /content/kaggle/train_images_jpeg/707856389.jpg  
  inflating: /content/kaggle/train_images_jpeg/707908216.jpg  
  inflating: /content/kaggle/train_images_jpeg/708059328.jpg  
  inflating: /content/kaggle/train_images_jpeg/70816770.jpg  
  inflating: /content/kaggle/train_images_jpeg/708185327.jpg  
  inflating: /content/kaggle/train_images_jpeg/708463860.jpg  
  inflating: /content/kaggle/train_images_jpeg/708732298.jpg  
  inflating: /content/kaggle/train_images_jpeg/708801738.jpg  
  inflating: /content/kaggle/train_images_jpeg/708802382.jpg  
  inflating: /content/kaggle/train_images_jpeg/708824087.jpg  
  inflating: /content/kaggle/train_images_jpeg/708900690.jpg  
  inflating: /content/kaggle/train_images_jpeg/709094492.jpg  
  inflating: /content/kaggle/train_images_jpeg/709285563.jpg  
  inflating: /content/kaggle/train_images_jpeg/709405326.jpg  
  inflating: /content/kaggle/train_images_jpeg/70951614.jpg  
  inflating: /content/kaggle/train_images_jpeg/709663348.jpg  
  inflating: /content/kaggle/train_images_jpeg/710147759.jpg  
  inflating: /content/kaggle/train_images_jpeg/710255784.jpg  
  inflating: /content/kaggle/train_images_jpeg/710350966.jpg  
  inflating: /content/kaggle/train_images_jpeg/710380163.jpg  
  inflating: /content/kaggle/train_images_jpeg/710791285.jpg  
  inflating: /content/kaggle/train_images_jpeg/710999120.jpg  
  inflating: /content/kaggle/train_images_jpeg/711239502.jpg  
  inflating: /content/kaggle/train_images_jpeg/711417337.jpg  
  inflating: /content/kaggle/train_images_jpeg/711729648.jpg  
  inflating: /content/kaggle/train_images_jpeg/711824069.jpg  
  inflating: /content/kaggle/train_images_jpeg/712150180.jpg  
  inflating: /content/kaggle/train_images_jpeg/712373628.jpg  
  inflating: /content/kaggle/train_images_jpeg/712382120.jpg  
  inflating: /content/kaggle/train_images_jpeg/712421823.jpg  
  inflating: /content/kaggle/train_images_jpeg/712443028.jpg  
  inflating: /content/kaggle/train_images_jpeg/712488898.jpg  
  inflating: /content/kaggle/train_images_jpeg/712506424.jpg  
  inflating: /content/kaggle/train_images_jpeg/712756334.jpg  
  inflating: /content/kaggle/train_images_jpeg/713216878.jpg  
  inflating: /content/kaggle/train_images_jpeg/713250541.jpg  
  inflating: /content/kaggle/train_images_jpeg/713259486.jpg  
  inflating: /content/kaggle/train_images_jpeg/713693996.jpg  
  inflating: /content/kaggle/train_images_jpeg/714060321.jpg  
  inflating: /content/kaggle/train_images_jpeg/714473351.jpg  
  inflating: /content/kaggle/train_images_jpeg/7145099.jpg  
  inflating: /content/kaggle/train_images_jpeg/714720109.jpg  
  inflating: /content/kaggle/train_images_jpeg/714791504.jpg  
  inflating: /content/kaggle/train_images_jpeg/715057901.jpg  
  inflating: /content/kaggle/train_images_jpeg/715316118.jpg  
  inflating: /content/kaggle/train_images_jpeg/715597792.jpg  
  inflating: /content/kaggle/train_images_jpeg/715785641.jpg  
  inflating: /content/kaggle/train_images_jpeg/715889320.jpg  
  inflating: /content/kaggle/train_images_jpeg/715948482.jpg  
  inflating: /content/kaggle/train_images_jpeg/716011398.jpg  
  inflating: /content/kaggle/train_images_jpeg/7160206.jpg  
  inflating: /content/kaggle/train_images_jpeg/716052378.jpg  
  inflating: /content/kaggle/train_images_jpeg/71608311.jpg  
  inflating: /content/kaggle/train_images_jpeg/716279515.jpg  
  inflating: /content/kaggle/train_images_jpeg/716467114.jpg  
  inflating: /content/kaggle/train_images_jpeg/716707376.jpg  
  inflating: /content/kaggle/train_images_jpeg/716814677.jpg  
  inflating: /content/kaggle/train_images_jpeg/717043764.jpg  
  inflating: /content/kaggle/train_images_jpeg/717221311.jpg  
  inflating: /content/kaggle/train_images_jpeg/717332289.jpg  
  inflating: /content/kaggle/train_images_jpeg/717532306.jpg  
  inflating: /content/kaggle/train_images_jpeg/717745388.jpg  
  inflating: /content/kaggle/train_images_jpeg/717753643.jpg  
  inflating: /content/kaggle/train_images_jpeg/717891487.jpg  
  inflating: /content/kaggle/train_images_jpeg/717911960.jpg  
  inflating: /content/kaggle/train_images_jpeg/718077278.jpg  
  inflating: /content/kaggle/train_images_jpeg/718198849.jpg  
  inflating: /content/kaggle/train_images_jpeg/718245684.jpg  
  inflating: /content/kaggle/train_images_jpeg/718269749.jpg  
  inflating: /content/kaggle/train_images_jpeg/718324300.jpg  
  inflating: /content/kaggle/train_images_jpeg/71842711.jpg  
  inflating: /content/kaggle/train_images_jpeg/718497528.jpg  
  inflating: /content/kaggle/train_images_jpeg/718957379.jpg  
  inflating: /content/kaggle/train_images_jpeg/71913940.jpg  
  inflating: /content/kaggle/train_images_jpeg/719168391.jpg  
  inflating: /content/kaggle/train_images_jpeg/719222576.jpg  
  inflating: /content/kaggle/train_images_jpeg/719512192.jpg  
  inflating: /content/kaggle/train_images_jpeg/719526260.jpg  
  inflating: /content/kaggle/train_images_jpeg/719562902.jpg  
  inflating: /content/kaggle/train_images_jpeg/719731461.jpg  
  inflating: /content/kaggle/train_images_jpeg/719825434.jpg  
  inflating: /content/kaggle/train_images_jpeg/719913445.jpg  
  inflating: /content/kaggle/train_images_jpeg/720028805.jpg  
  inflating: /content/kaggle/train_images_jpeg/720072964.jpg  
  inflating: /content/kaggle/train_images_jpeg/720076710.jpg  
  inflating: /content/kaggle/train_images_jpeg/72014881.jpg  
  inflating: /content/kaggle/train_images_jpeg/720275537.jpg  
  inflating: /content/kaggle/train_images_jpeg/720304671.jpg  
  inflating: /content/kaggle/train_images_jpeg/720647277.jpg  
  inflating: /content/kaggle/train_images_jpeg/720749489.jpg  
  inflating: /content/kaggle/train_images_jpeg/720776367.jpg  
  inflating: /content/kaggle/train_images_jpeg/721126244.jpg  
  inflating: /content/kaggle/train_images_jpeg/721201325.jpg  
  inflating: /content/kaggle/train_images_jpeg/721232616.jpg  
  inflating: /content/kaggle/train_images_jpeg/721245068.jpg  
  inflating: /content/kaggle/train_images_jpeg/721430436.jpg  
  inflating: /content/kaggle/train_images_jpeg/72147766.jpg  
  inflating: /content/kaggle/train_images_jpeg/721483208.jpg  
  inflating: /content/kaggle/train_images_jpeg/722155866.jpg  
  inflating: /content/kaggle/train_images_jpeg/722419138.jpg  
  inflating: /content/kaggle/train_images_jpeg/722430028.jpg  
  inflating: /content/kaggle/train_images_jpeg/72286182.jpg  
  inflating: /content/kaggle/train_images_jpeg/72299830.jpg  
  inflating: /content/kaggle/train_images_jpeg/723119750.jpg  
  inflating: /content/kaggle/train_images_jpeg/723564013.jpg  
  inflating: /content/kaggle/train_images_jpeg/723773880.jpg  
  inflating: /content/kaggle/train_images_jpeg/723805565.jpg  
  inflating: /content/kaggle/train_images_jpeg/723891592.jpg  
  inflating: /content/kaggle/train_images_jpeg/723977410.jpg  
  inflating: /content/kaggle/train_images_jpeg/724059503.jpg  
  inflating: /content/kaggle/train_images_jpeg/724195836.jpg  
  inflating: /content/kaggle/train_images_jpeg/724302384.jpg  
  inflating: /content/kaggle/train_images_jpeg/724406669.jpg  
  inflating: /content/kaggle/train_images_jpeg/724656877.jpg  
  inflating: /content/kaggle/train_images_jpeg/725027388.jpg  
  inflating: /content/kaggle/train_images_jpeg/725034194.jpg  
  inflating: /content/kaggle/train_images_jpeg/725248159.jpg  
  inflating: /content/kaggle/train_images_jpeg/725502119.jpg  
  inflating: /content/kaggle/train_images_jpeg/725865491.jpg  
  inflating: /content/kaggle/train_images_jpeg/726063333.jpg  
  inflating: /content/kaggle/train_images_jpeg/726108789.jpg  
  inflating: /content/kaggle/train_images_jpeg/726278005.jpg  
  inflating: /content/kaggle/train_images_jpeg/726374295.jpg  
  inflating: /content/kaggle/train_images_jpeg/726377415.jpg  
  inflating: /content/kaggle/train_images_jpeg/72640810.jpg  
  inflating: /content/kaggle/train_images_jpeg/726818817.jpg  
  inflating: /content/kaggle/train_images_jpeg/726948358.jpg  
  inflating: /content/kaggle/train_images_jpeg/72715709.jpg  
  inflating: /content/kaggle/train_images_jpeg/727949301.jpg  
  inflating: /content/kaggle/train_images_jpeg/728024398.jpg  
  inflating: /content/kaggle/train_images_jpeg/728084630.jpg  
  inflating: /content/kaggle/train_images_jpeg/728194146.jpg  
  inflating: /content/kaggle/train_images_jpeg/728221316.jpg  
  inflating: /content/kaggle/train_images_jpeg/728369192.jpg  
  inflating: /content/kaggle/train_images_jpeg/728569501.jpg  
  inflating: /content/kaggle/train_images_jpeg/728690551.jpg  
  inflating: /content/kaggle/train_images_jpeg/7288550.jpg  
  inflating: /content/kaggle/train_images_jpeg/729230062.jpg  
  inflating: /content/kaggle/train_images_jpeg/72925791.jpg  
  inflating: /content/kaggle/train_images_jpeg/729514787.jpg  
  inflating: /content/kaggle/train_images_jpeg/729571986.jpg  
  inflating: /content/kaggle/train_images_jpeg/730246469.jpg  
  inflating: /content/kaggle/train_images_jpeg/730367123.jpg  
  inflating: /content/kaggle/train_images_jpeg/730431773.jpg  
  inflating: /content/kaggle/train_images_jpeg/730805822.jpg  
  inflating: /content/kaggle/train_images_jpeg/731031258.jpg  
  inflating: /content/kaggle/train_images_jpeg/731084892.jpg  
  inflating: /content/kaggle/train_images_jpeg/731497931.jpg  
  inflating: /content/kaggle/train_images_jpeg/731606877.jpg  
  inflating: /content/kaggle/train_images_jpeg/731638651.jpg  
  inflating: /content/kaggle/train_images_jpeg/731897320.jpg  
  inflating: /content/kaggle/train_images_jpeg/732124818.jpg  
  inflating: /content/kaggle/train_images_jpeg/732377500.jpg  
  inflating: /content/kaggle/train_images_jpeg/732483696.jpg  
  inflating: /content/kaggle/train_images_jpeg/732531942.jpg  
  inflating: /content/kaggle/train_images_jpeg/732560190.jpg  
  inflating: /content/kaggle/train_images_jpeg/732588563.jpg  
  inflating: /content/kaggle/train_images_jpeg/732613479.jpg  
  inflating: /content/kaggle/train_images_jpeg/73287115.jpg  
  inflating: /content/kaggle/train_images_jpeg/732968835.jpg  
  inflating: /content/kaggle/train_images_jpeg/733045784.jpg  
  inflating: /content/kaggle/train_images_jpeg/733232478.jpg  
  inflating: /content/kaggle/train_images_jpeg/733445038.jpg  
  inflating: /content/kaggle/train_images_jpeg/733543752.jpg  
  inflating: /content/kaggle/train_images_jpeg/733701690.jpg  
  inflating: /content/kaggle/train_images_jpeg/733770850.jpg  
  inflating: /content/kaggle/train_images_jpeg/734091779.jpg  
  inflating: /content/kaggle/train_images_jpeg/734163390.jpg  
  inflating: /content/kaggle/train_images_jpeg/734530855.jpg  
  inflating: /content/kaggle/train_images_jpeg/734583205.jpg  
  inflating: /content/kaggle/train_images_jpeg/734701008.jpg  
  inflating: /content/kaggle/train_images_jpeg/735041254.jpg  
  inflating: /content/kaggle/train_images_jpeg/73533711.jpg  
  inflating: /content/kaggle/train_images_jpeg/735529446.jpg  
  inflating: /content/kaggle/train_images_jpeg/736521224.jpg  
  inflating: /content/kaggle/train_images_jpeg/736522598.jpg  
  inflating: /content/kaggle/train_images_jpeg/736571688.jpg  
  inflating: /content/kaggle/train_images_jpeg/736694812.jpg  
  inflating: /content/kaggle/train_images_jpeg/736834551.jpg  
  inflating: /content/kaggle/train_images_jpeg/736896439.jpg  
  inflating: /content/kaggle/train_images_jpeg/736957194.jpg  
  inflating: /content/kaggle/train_images_jpeg/737157935.jpg  
  inflating: /content/kaggle/train_images_jpeg/73728059.jpg  
  inflating: /content/kaggle/train_images_jpeg/737465791.jpg  
  inflating: /content/kaggle/train_images_jpeg/737529075.jpg  
  inflating: /content/kaggle/train_images_jpeg/737556184.jpg  
  inflating: /content/kaggle/train_images_jpeg/737753256.jpg  
  inflating: /content/kaggle/train_images_jpeg/738238956.jpg  
  inflating: /content/kaggle/train_images_jpeg/738338306.jpg  
  inflating: /content/kaggle/train_images_jpeg/738403041.jpg  
  inflating: /content/kaggle/train_images_jpeg/738435591.jpg  
  inflating: /content/kaggle/train_images_jpeg/738553844.jpg  
  inflating: /content/kaggle/train_images_jpeg/738656611.jpg  
  inflating: /content/kaggle/train_images_jpeg/739227863.jpg  
  inflating: /content/kaggle/train_images_jpeg/739247147.jpg  
  inflating: /content/kaggle/train_images_jpeg/739320335.jpg  
  inflating: /content/kaggle/train_images_jpeg/739346655.jpg  
  inflating: /content/kaggle/train_images_jpeg/740035863.jpg  
  inflating: /content/kaggle/train_images_jpeg/740762568.jpg  
  inflating: /content/kaggle/train_images_jpeg/741358374.jpg  
  inflating: /content/kaggle/train_images_jpeg/741807266.jpg  
  inflating: /content/kaggle/train_images_jpeg/742038371.jpg  
  inflating: /content/kaggle/train_images_jpeg/742154911.jpg  
  inflating: /content/kaggle/train_images_jpeg/742278677.jpg  
  inflating: /content/kaggle/train_images_jpeg/742410118.jpg  
  inflating: /content/kaggle/train_images_jpeg/742519691.jpg  
  inflating: /content/kaggle/train_images_jpeg/742539602.jpg  
  inflating: /content/kaggle/train_images_jpeg/742622446.jpg  
  inflating: /content/kaggle/train_images_jpeg/742898185.jpg  
  inflating: /content/kaggle/train_images_jpeg/743105570.jpg  
  inflating: /content/kaggle/train_images_jpeg/743135503.jpg  
  inflating: /content/kaggle/train_images_jpeg/743348334.jpg  
  inflating: /content/kaggle/train_images_jpeg/743721638.jpg  
  inflating: /content/kaggle/train_images_jpeg/743850893.jpg  
  inflating: /content/kaggle/train_images_jpeg/743945725.jpg  
  inflating: /content/kaggle/train_images_jpeg/743999758.jpg  
  inflating: /content/kaggle/train_images_jpeg/744348515.jpg  
  inflating: /content/kaggle/train_images_jpeg/744371772.jpg  
  inflating: /content/kaggle/train_images_jpeg/744383303.jpg  
  inflating: /content/kaggle/train_images_jpeg/744419664.jpg  
  inflating: /content/kaggle/train_images_jpeg/744619434.jpg  
  inflating: /content/kaggle/train_images_jpeg/744676370.jpg  
  inflating: /content/kaggle/train_images_jpeg/744968127.jpg  
  inflating: /content/kaggle/train_images_jpeg/744972013.jpg  
  inflating: /content/kaggle/train_images_jpeg/745112623.jpg  
  inflating: /content/kaggle/train_images_jpeg/745135323.jpg  
  inflating: /content/kaggle/train_images_jpeg/745226266.jpg  
  inflating: /content/kaggle/train_images_jpeg/745442190.jpg  
  inflating: /content/kaggle/train_images_jpeg/74548158.jpg  
  inflating: /content/kaggle/train_images_jpeg/745566741.jpg  
  inflating: /content/kaggle/train_images_jpeg/74571802.jpg  
  inflating: /content/kaggle/train_images_jpeg/745723934.jpg  
  inflating: /content/kaggle/train_images_jpeg/745792080.jpg  
  inflating: /content/kaggle/train_images_jpeg/746494129.jpg  
  inflating: /content/kaggle/train_images_jpeg/74649970.jpg  
  inflating: /content/kaggle/train_images_jpeg/746746526.jpg  
  inflating: /content/kaggle/train_images_jpeg/746879421.jpg  
  inflating: /content/kaggle/train_images_jpeg/747082270.jpg  
  inflating: /content/kaggle/train_images_jpeg/747646454.jpg  
  inflating: /content/kaggle/train_images_jpeg/747698769.jpg  
  inflating: /content/kaggle/train_images_jpeg/747749936.jpg  
  inflating: /content/kaggle/train_images_jpeg/747761920.jpg  
  inflating: /content/kaggle/train_images_jpeg/747770020.jpg  
  inflating: /content/kaggle/train_images_jpeg/748029556.jpg  
  inflating: /content/kaggle/train_images_jpeg/748035819.jpg  
  inflating: /content/kaggle/train_images_jpeg/748154559.jpg  
  inflating: /content/kaggle/train_images_jpeg/748237612.jpg  
  inflating: /content/kaggle/train_images_jpeg/748345018.jpg  
  inflating: /content/kaggle/train_images_jpeg/748404648.jpg  
  inflating: /content/kaggle/train_images_jpeg/748448917.jpg  
  inflating: /content/kaggle/train_images_jpeg/748623930.jpg  
  inflating: /content/kaggle/train_images_jpeg/748745239.jpg  
  inflating: /content/kaggle/train_images_jpeg/749023134.jpg  
  inflating: /content/kaggle/train_images_jpeg/749210924.jpg  
  inflating: /content/kaggle/train_images_jpeg/749454717.jpg  
  inflating: /content/kaggle/train_images_jpeg/74966012.jpg  
  inflating: /content/kaggle/train_images_jpeg/750060449.jpg  
  inflating: /content/kaggle/train_images_jpeg/750376884.jpg  
  inflating: /content/kaggle/train_images_jpeg/750488061.jpg  
  inflating: /content/kaggle/train_images_jpeg/750645140.jpg  
  inflating: /content/kaggle/train_images_jpeg/75068408.jpg  
  inflating: /content/kaggle/train_images_jpeg/750828465.jpg  
  inflating: /content/kaggle/train_images_jpeg/751463025.jpg  
  inflating: /content/kaggle/train_images_jpeg/751472775.jpg  
  inflating: /content/kaggle/train_images_jpeg/752038369.jpg  
  inflating: /content/kaggle/train_images_jpeg/752076516.jpg  
  inflating: /content/kaggle/train_images_jpeg/75207996.jpg  
  inflating: /content/kaggle/train_images_jpeg/752382759.jpg  
  inflating: /content/kaggle/train_images_jpeg/752869166.jpg  
  inflating: /content/kaggle/train_images_jpeg/752884975.jpg  
  inflating: /content/kaggle/train_images_jpeg/753116208.jpg  
  inflating: /content/kaggle/train_images_jpeg/753470251.jpg  
  inflating: /content/kaggle/train_images_jpeg/753617544.jpg  
  inflating: /content/kaggle/train_images_jpeg/753837203.jpg  
  inflating: /content/kaggle/train_images_jpeg/753901704.jpg  
  inflating: /content/kaggle/train_images_jpeg/754110483.jpg  
  inflating: /content/kaggle/train_images_jpeg/754271436.jpg  
  inflating: /content/kaggle/train_images_jpeg/754482252.jpg  
  inflating: /content/kaggle/train_images_jpeg/755073612.jpg  
  inflating: /content/kaggle/train_images_jpeg/755119269.jpg  
  inflating: /content/kaggle/train_images_jpeg/755437879.jpg  
  inflating: /content/kaggle/train_images_jpeg/755497707.jpg  
  inflating: /content/kaggle/train_images_jpeg/755729450.jpg  
  inflating: /content/kaggle/train_images_jpeg/755912815.jpg  
  inflating: /content/kaggle/train_images_jpeg/755941592.jpg  
  inflating: /content/kaggle/train_images_jpeg/75598343.jpg  
  inflating: /content/kaggle/train_images_jpeg/756009491.jpg  
  inflating: /content/kaggle/train_images_jpeg/756195820.jpg  
  inflating: /content/kaggle/train_images_jpeg/756368308.jpg  
  inflating: /content/kaggle/train_images_jpeg/756826989.jpg  
  inflating: /content/kaggle/train_images_jpeg/756993867.jpg  
  inflating: /content/kaggle/train_images_jpeg/757527381.jpg  
  inflating: /content/kaggle/train_images_jpeg/758001650.jpg  
  inflating: /content/kaggle/train_images_jpeg/758155419.jpg  
  inflating: /content/kaggle/train_images_jpeg/758535635.jpg  
  inflating: /content/kaggle/train_images_jpeg/758980708.jpg  
  inflating: /content/kaggle/train_images_jpeg/75951556.jpg  
  inflating: /content/kaggle/train_images_jpeg/759526675.jpg  
  inflating: /content/kaggle/train_images_jpeg/759532134.jpg  
  inflating: /content/kaggle/train_images_jpeg/759559409.jpg  
  inflating: /content/kaggle/train_images_jpeg/759626803.jpg  
  inflating: /content/kaggle/train_images_jpeg/759934720.jpg  
  inflating: /content/kaggle/train_images_jpeg/76026574.jpg  
  inflating: /content/kaggle/train_images_jpeg/760333191.jpg  
  inflating: /content/kaggle/train_images_jpeg/760603911.jpg  
  inflating: /content/kaggle/train_images_jpeg/760650876.jpg  
  inflating: /content/kaggle/train_images_jpeg/760745341.jpg  
  inflating: /content/kaggle/train_images_jpeg/76080816.jpg  
  inflating: /content/kaggle/train_images_jpeg/760863006.jpg  
  inflating: /content/kaggle/train_images_jpeg/760916412.jpg  
  inflating: /content/kaggle/train_images_jpeg/761160675.jpg  
  inflating: /content/kaggle/train_images_jpeg/761651651.jpg  
  inflating: /content/kaggle/train_images_jpeg/761719454.jpg  
  inflating: /content/kaggle/train_images_jpeg/761767350.jpg  
  inflating: /content/kaggle/train_images_jpeg/762063619.jpg  
  inflating: /content/kaggle/train_images_jpeg/762338204.jpg  
  inflating: /content/kaggle/train_images_jpeg/762372916.jpg  
  inflating: /content/kaggle/train_images_jpeg/762558370.jpg  
  inflating: /content/kaggle/train_images_jpeg/762652990.jpg  
  inflating: /content/kaggle/train_images_jpeg/763303438.jpg  
  inflating: /content/kaggle/train_images_jpeg/7635457.jpg  
  inflating: /content/kaggle/train_images_jpeg/763642259.jpg  
  inflating: /content/kaggle/train_images_jpeg/76382862.jpg  
  inflating: /content/kaggle/train_images_jpeg/763846038.jpg  
  inflating: /content/kaggle/train_images_jpeg/764093492.jpg  
  inflating: /content/kaggle/train_images_jpeg/764276739.jpg  
  inflating: /content/kaggle/train_images_jpeg/764628702.jpg  
  inflating: /content/kaggle/train_images_jpeg/764713577.jpg  
  inflating: /content/kaggle/train_images_jpeg/764879606.jpg  
  inflating: /content/kaggle/train_images_jpeg/764956722.jpg  
  inflating: /content/kaggle/train_images_jpeg/765160322.jpg  
  inflating: /content/kaggle/train_images_jpeg/765925416.jpg  
  inflating: /content/kaggle/train_images_jpeg/76610968.jpg  
  inflating: /content/kaggle/train_images_jpeg/766741415.jpg  
  inflating: /content/kaggle/train_images_jpeg/766864157.jpg  
  inflating: /content/kaggle/train_images_jpeg/766908244.jpg  
  inflating: /content/kaggle/train_images_jpeg/767516217.jpg  
  inflating: /content/kaggle/train_images_jpeg/76754228.jpg  
  inflating: /content/kaggle/train_images_jpeg/767824748.jpg  
  inflating: /content/kaggle/train_images_jpeg/76786311.jpg  
  inflating: /content/kaggle/train_images_jpeg/767882051.jpg  
  inflating: /content/kaggle/train_images_jpeg/767931500.jpg  
  inflating: /content/kaggle/train_images_jpeg/768298131.jpg  
  inflating: /content/kaggle/train_images_jpeg/768729652.jpg  
  inflating: /content/kaggle/train_images_jpeg/768744313.jpg  
  inflating: /content/kaggle/train_images_jpeg/768801643.jpg  
  inflating: /content/kaggle/train_images_jpeg/76889034.jpg  
  inflating: /content/kaggle/train_images_jpeg/768948562.jpg  
  inflating: /content/kaggle/train_images_jpeg/76900399.jpg  
  inflating: /content/kaggle/train_images_jpeg/769509727.jpg  
  inflating: /content/kaggle/train_images_jpeg/769621297.jpg  
  inflating: /content/kaggle/train_images_jpeg/769737121.jpg  
  inflating: /content/kaggle/train_images_jpeg/770022346.jpg  
  inflating: /content/kaggle/train_images_jpeg/770144532.jpg  
  inflating: /content/kaggle/train_images_jpeg/770243890.jpg  
  inflating: /content/kaggle/train_images_jpeg/770348865.jpg  
  inflating: /content/kaggle/train_images_jpeg/770763357.jpg  
  inflating: /content/kaggle/train_images_jpeg/770913881.jpg  
  inflating: /content/kaggle/train_images_jpeg/771092021.jpg  
  inflating: /content/kaggle/train_images_jpeg/771269957.jpg  
  inflating: /content/kaggle/train_images_jpeg/771444014.jpg  
  inflating: /content/kaggle/train_images_jpeg/771588286.jpg  
  inflating: /content/kaggle/train_images_jpeg/772210592.jpg  
  inflating: /content/kaggle/train_images_jpeg/772317210.jpg  
  inflating: /content/kaggle/train_images_jpeg/772651285.jpg  
  inflating: /content/kaggle/train_images_jpeg/773007484.jpg  
  inflating: /content/kaggle/train_images_jpeg/773130398.jpg  
  inflating: /content/kaggle/train_images_jpeg/773139109.jpg  
  inflating: /content/kaggle/train_images_jpeg/773221073.jpg  
  inflating: /content/kaggle/train_images_jpeg/773525225.jpg  
  inflating: /content/kaggle/train_images_jpeg/773722195.jpg  
  inflating: /content/kaggle/train_images_jpeg/77379532.jpg  
  inflating: /content/kaggle/train_images_jpeg/77416532.jpg  
  inflating: /content/kaggle/train_images_jpeg/774557036.jpg  
  inflating: /content/kaggle/train_images_jpeg/774618628.jpg  
  inflating: /content/kaggle/train_images_jpeg/774796489.jpg  
  inflating: /content/kaggle/train_images_jpeg/774801310.jpg  
  inflating: /content/kaggle/train_images_jpeg/774942626.jpg  
  inflating: /content/kaggle/train_images_jpeg/775786945.jpg  
  inflating: /content/kaggle/train_images_jpeg/775831061.jpg  
  inflating: /content/kaggle/train_images_jpeg/775841859.jpg  
  inflating: /content/kaggle/train_images_jpeg/776473897.jpg  
  inflating: /content/kaggle/train_images_jpeg/776814328.jpg  
  inflating: /content/kaggle/train_images_jpeg/777180004.jpg  
  inflating: /content/kaggle/train_images_jpeg/777515553.jpg  
  inflating: /content/kaggle/train_images_jpeg/778084917.jpg  
  inflating: /content/kaggle/train_images_jpeg/778101302.jpg  
  inflating: /content/kaggle/train_images_jpeg/778148477.jpg  
  inflating: /content/kaggle/train_images_jpeg/778751547.jpg  
  inflating: /content/kaggle/train_images_jpeg/77896504.jpg  
  inflating: /content/kaggle/train_images_jpeg/779284958.jpg  
  inflating: /content/kaggle/train_images_jpeg/779647083.jpg  
  inflating: /content/kaggle/train_images_jpeg/779704473.jpg  
  inflating: /content/kaggle/train_images_jpeg/779799514.jpg  
  inflating: /content/kaggle/train_images_jpeg/77981157.jpg  
  inflating: /content/kaggle/train_images_jpeg/779832601.jpg  
  inflating: /content/kaggle/train_images_jpeg/779905140.jpg  
  inflating: /content/kaggle/train_images_jpeg/780018709.jpg  
  inflating: /content/kaggle/train_images_jpeg/780244327.jpg  
  inflating: /content/kaggle/train_images_jpeg/780779910.jpg  
  inflating: /content/kaggle/train_images_jpeg/780806888.jpg  
  inflating: /content/kaggle/train_images_jpeg/780810143.jpg  
  inflating: /content/kaggle/train_images_jpeg/780812090.jpg  
  inflating: /content/kaggle/train_images_jpeg/78106943.jpg  
  inflating: /content/kaggle/train_images_jpeg/781215669.jpg  
  inflating: /content/kaggle/train_images_jpeg/781490175.jpg  
  inflating: /content/kaggle/train_images_jpeg/781539722.jpg  
  inflating: /content/kaggle/train_images_jpeg/781625622.jpg  
  inflating: /content/kaggle/train_images_jpeg/781748642.jpg  
  inflating: /content/kaggle/train_images_jpeg/781807650.jpg  
  inflating: /content/kaggle/train_images_jpeg/781931652.jpg  
  inflating: /content/kaggle/train_images_jpeg/782026162.jpg  
  inflating: /content/kaggle/train_images_jpeg/782115033.jpg  
  inflating: /content/kaggle/train_images_jpeg/782478171.jpg  
  inflating: /content/kaggle/train_images_jpeg/782489487.jpg  
  inflating: /content/kaggle/train_images_jpeg/782802185.jpg  
  inflating: /content/kaggle/train_images_jpeg/7830631.jpg  
  inflating: /content/kaggle/train_images_jpeg/783137555.jpg  
  inflating: /content/kaggle/train_images_jpeg/78347787.jpg  
  inflating: /content/kaggle/train_images_jpeg/783533670.jpg  
  inflating: /content/kaggle/train_images_jpeg/783558367.jpg  
  inflating: /content/kaggle/train_images_jpeg/783577117.jpg  
  inflating: /content/kaggle/train_images_jpeg/783771621.jpg  
  inflating: /content/kaggle/train_images_jpeg/784183735.jpg  
  inflating: /content/kaggle/train_images_jpeg/785146800.jpg  
  inflating: /content/kaggle/train_images_jpeg/785210463.jpg  
  inflating: /content/kaggle/train_images_jpeg/785251696.jpg  
  inflating: /content/kaggle/train_images_jpeg/785755916.jpg  
  inflating: /content/kaggle/train_images_jpeg/786134670.jpg  
  inflating: /content/kaggle/train_images_jpeg/786431540.jpg  
  inflating: /content/kaggle/train_images_jpeg/786525788.jpg  
  inflating: /content/kaggle/train_images_jpeg/786703663.jpg  
  inflating: /content/kaggle/train_images_jpeg/787052620.jpg  
  inflating: /content/kaggle/train_images_jpeg/787314434.jpg  
  inflating: /content/kaggle/train_images_jpeg/787415998.jpg  
  inflating: /content/kaggle/train_images_jpeg/78766531.jpg  
  inflating: /content/kaggle/train_images_jpeg/787756871.jpg  
  inflating: /content/kaggle/train_images_jpeg/787849373.jpg  
  inflating: /content/kaggle/train_images_jpeg/787914923.jpg  
  inflating: /content/kaggle/train_images_jpeg/788188732.jpg  
  inflating: /content/kaggle/train_images_jpeg/788479472.jpg  
  inflating: /content/kaggle/train_images_jpeg/789395846.jpg  
  inflating: /content/kaggle/train_images_jpeg/78946276.jpg  
  inflating: /content/kaggle/train_images_jpeg/790193480.jpg  
  inflating: /content/kaggle/train_images_jpeg/790473247.jpg  
  inflating: /content/kaggle/train_images_jpeg/790568397.jpg  
  inflating: /content/kaggle/train_images_jpeg/790574591.jpg  
  inflating: /content/kaggle/train_images_jpeg/790690044.jpg  
  inflating: /content/kaggle/train_images_jpeg/790756634.jpg  
  inflating: /content/kaggle/train_images_jpeg/791132731.jpg  
  inflating: /content/kaggle/train_images_jpeg/791404140.jpg  
  inflating: /content/kaggle/train_images_jpeg/79165028.jpg  
  inflating: /content/kaggle/train_images_jpeg/791667524.jpg  
  inflating: /content/kaggle/train_images_jpeg/791971573.jpg  
  inflating: /content/kaggle/train_images_jpeg/792105357.jpg  
  inflating: /content/kaggle/train_images_jpeg/792213146.jpg  
  inflating: /content/kaggle/train_images_jpeg/792366511.jpg  
  inflating: /content/kaggle/train_images_jpeg/792369876.jpg  
  inflating: /content/kaggle/train_images_jpeg/792936600.jpg  
  inflating: /content/kaggle/train_images_jpeg/792953439.jpg  
  inflating: /content/kaggle/train_images_jpeg/792990285.jpg  
  inflating: /content/kaggle/train_images_jpeg/793076912.jpg  
  inflating: /content/kaggle/train_images_jpeg/793174767.jpg  
  inflating: /content/kaggle/train_images_jpeg/793206643.jpg  
  inflating: /content/kaggle/train_images_jpeg/793578252.jpg  
  inflating: /content/kaggle/train_images_jpeg/793897139.jpg  
  inflating: /content/kaggle/train_images_jpeg/793903784.jpg  
  inflating: /content/kaggle/train_images_jpeg/794210543.jpg  
  inflating: /content/kaggle/train_images_jpeg/794333846.jpg  
  inflating: /content/kaggle/train_images_jpeg/794665522.jpg  
  inflating: /content/kaggle/train_images_jpeg/794817264.jpg  
  inflating: /content/kaggle/train_images_jpeg/794895924.jpg  
  inflating: /content/kaggle/train_images_jpeg/795110663.jpg  
  inflating: /content/kaggle/train_images_jpeg/795263399.jpg  
  inflating: /content/kaggle/train_images_jpeg/795280732.jpg  
  inflating: /content/kaggle/train_images_jpeg/795383461.jpg  
  inflating: /content/kaggle/train_images_jpeg/795781797.jpg  
  inflating: /content/kaggle/train_images_jpeg/795796251.jpg  
  inflating: /content/kaggle/train_images_jpeg/796369691.jpg  
  inflating: /content/kaggle/train_images_jpeg/796761175.jpg  
  inflating: /content/kaggle/train_images_jpeg/796933103.jpg  
  inflating: /content/kaggle/train_images_jpeg/797009430.jpg  
  inflating: /content/kaggle/train_images_jpeg/797094434.jpg  
  inflating: /content/kaggle/train_images_jpeg/797310513.jpg  
  inflating: /content/kaggle/train_images_jpeg/797580411.jpg  
  inflating: /content/kaggle/train_images_jpeg/797589607.jpg  
  inflating: /content/kaggle/train_images_jpeg/798006612.jpg  
  inflating: /content/kaggle/train_images_jpeg/798023657.jpg  
  inflating: /content/kaggle/train_images_jpeg/798065416.jpg  
  inflating: /content/kaggle/train_images_jpeg/798586903.jpg  
  inflating: /content/kaggle/train_images_jpeg/79867712.jpg  
  inflating: /content/kaggle/train_images_jpeg/799030211.jpg  
  inflating: /content/kaggle/train_images_jpeg/799279391.jpg  
  inflating: /content/kaggle/train_images_jpeg/800065702.jpg  
  inflating: /content/kaggle/train_images_jpeg/800250438.jpg  
  inflating: /content/kaggle/train_images_jpeg/800501715.jpg  
  inflating: /content/kaggle/train_images_jpeg/800593866.jpg  
  inflating: /content/kaggle/train_images_jpeg/801173555.jpg  
  inflating: /content/kaggle/train_images_jpeg/801343155.jpg  
  inflating: /content/kaggle/train_images_jpeg/801531661.jpg  
  inflating: /content/kaggle/train_images_jpeg/801551318.jpg  
  inflating: /content/kaggle/train_images_jpeg/801908113.jpg  
  inflating: /content/kaggle/train_images_jpeg/802174212.jpg  
  inflating: /content/kaggle/train_images_jpeg/802266352.jpg  
  inflating: /content/kaggle/train_images_jpeg/802386066.jpg  
  inflating: /content/kaggle/train_images_jpeg/802718522.jpg  
  inflating: /content/kaggle/train_images_jpeg/803019874.jpg  
  inflating: /content/kaggle/train_images_jpeg/803137962.jpg  
  inflating: /content/kaggle/train_images_jpeg/803511182.jpg  
  inflating: /content/kaggle/train_images_jpeg/803527097.jpg  
  inflating: /content/kaggle/train_images_jpeg/803715275.jpg  
  inflating: /content/kaggle/train_images_jpeg/803734282.jpg  
  inflating: /content/kaggle/train_images_jpeg/803873425.jpg  
  inflating: /content/kaggle/train_images_jpeg/804056394.jpg  
  inflating: /content/kaggle/train_images_jpeg/804347789.jpg  
  inflating: /content/kaggle/train_images_jpeg/804353681.jpg  
  inflating: /content/kaggle/train_images_jpeg/804506814.jpg  
  inflating: /content/kaggle/train_images_jpeg/804513680.jpg  
  inflating: /content/kaggle/train_images_jpeg/804520437.jpg  
  inflating: /content/kaggle/train_images_jpeg/804653240.jpg  
  inflating: /content/kaggle/train_images_jpeg/80482467.jpg  
  inflating: /content/kaggle/train_images_jpeg/804847403.jpg  
  inflating: /content/kaggle/train_images_jpeg/80488129.jpg  
  inflating: /content/kaggle/train_images_jpeg/804903970.jpg  
  inflating: /content/kaggle/train_images_jpeg/805005298.jpg  
  inflating: /content/kaggle/train_images_jpeg/805152902.jpg  
  inflating: /content/kaggle/train_images_jpeg/805519444.jpg  
  inflating: /content/kaggle/train_images_jpeg/805711898.jpg  
  inflating: /content/kaggle/train_images_jpeg/805835204.jpg  
  inflating: /content/kaggle/train_images_jpeg/805915725.jpg  
  inflating: /content/kaggle/train_images_jpeg/806175300.jpg  
  inflating: /content/kaggle/train_images_jpeg/806185900.jpg  
  inflating: /content/kaggle/train_images_jpeg/806357910.jpg  
  inflating: /content/kaggle/train_images_jpeg/806456552.jpg  
  inflating: /content/kaggle/train_images_jpeg/806670613.jpg  
  inflating: /content/kaggle/train_images_jpeg/806702626.jpg  
  inflating: /content/kaggle/train_images_jpeg/806943895.jpg  
  inflating: /content/kaggle/train_images_jpeg/807063038.jpg  
  inflating: /content/kaggle/train_images_jpeg/807086334.jpg  
  inflating: /content/kaggle/train_images_jpeg/807190211.jpg  
  inflating: /content/kaggle/train_images_jpeg/807322814.jpg  
  inflating: /content/kaggle/train_images_jpeg/807555228.jpg  
  inflating: /content/kaggle/train_images_jpeg/807698612.jpg  
  inflating: /content/kaggle/train_images_jpeg/807777679.jpg  
  inflating: /content/kaggle/train_images_jpeg/807976846.jpg  
  inflating: /content/kaggle/train_images_jpeg/808180923.jpg  
  inflating: /content/kaggle/train_images_jpeg/808194984.jpg  
  inflating: /content/kaggle/train_images_jpeg/808416790.jpg  
  inflating: /content/kaggle/train_images_jpeg/808606006.jpg  
  inflating: /content/kaggle/train_images_jpeg/808870213.jpg  
  inflating: /content/kaggle/train_images_jpeg/809104607.jpg  
  inflating: /content/kaggle/train_images_jpeg/809330872.jpg  
  inflating: /content/kaggle/train_images_jpeg/809359953.jpg  
  inflating: /content/kaggle/train_images_jpeg/809489252.jpg  
  inflating: /content/kaggle/train_images_jpeg/809808575.jpg  
  inflating: /content/kaggle/train_images_jpeg/80998969.jpg  
  inflating: /content/kaggle/train_images_jpeg/81000729.jpg  
  inflating: /content/kaggle/train_images_jpeg/810282945.jpg  
  inflating: /content/kaggle/train_images_jpeg/810351903.jpg  
  inflating: /content/kaggle/train_images_jpeg/810511060.jpg  
  inflating: /content/kaggle/train_images_jpeg/810720134.jpg  
  inflating: /content/kaggle/train_images_jpeg/810859265.jpg  
  inflating: /content/kaggle/train_images_jpeg/810886166.jpg  
  inflating: /content/kaggle/train_images_jpeg/811026048.jpg  
  inflating: /content/kaggle/train_images_jpeg/811520495.jpg  
  inflating: /content/kaggle/train_images_jpeg/81164598.jpg  
  inflating: /content/kaggle/train_images_jpeg/811696349.jpg  
  inflating: /content/kaggle/train_images_jpeg/811732946.jpg  
  inflating: /content/kaggle/train_images_jpeg/811928525.jpg  
  inflating: /content/kaggle/train_images_jpeg/812377482.jpg  
  inflating: /content/kaggle/train_images_jpeg/812408252.jpg  
  inflating: /content/kaggle/train_images_jpeg/812524479.jpg  
  inflating: /content/kaggle/train_images_jpeg/812733394.jpg  
  inflating: /content/kaggle/train_images_jpeg/8129389.jpg  
  inflating: /content/kaggle/train_images_jpeg/813017538.jpg  
  inflating: /content/kaggle/train_images_jpeg/813060428.jpg  
  inflating: /content/kaggle/train_images_jpeg/813110259.jpg  
  inflating: /content/kaggle/train_images_jpeg/813217011.jpg  
  inflating: /content/kaggle/train_images_jpeg/813262235.jpg  
  inflating: /content/kaggle/train_images_jpeg/813361567.jpg  
  inflating: /content/kaggle/train_images_jpeg/813435800.jpg  
  inflating: /content/kaggle/train_images_jpeg/813509621.jpg  
  inflating: /content/kaggle/train_images_jpeg/813688651.jpg  
  inflating: /content/kaggle/train_images_jpeg/813697698.jpg  
  inflating: /content/kaggle/train_images_jpeg/813744167.jpg  
  inflating: /content/kaggle/train_images_jpeg/813751338.jpg  
  inflating: /content/kaggle/train_images_jpeg/814020712.jpg  
  inflating: /content/kaggle/train_images_jpeg/814026139.jpg  
  inflating: /content/kaggle/train_images_jpeg/814045052.jpg  
  inflating: /content/kaggle/train_images_jpeg/814122857.jpg  
  inflating: /content/kaggle/train_images_jpeg/814185128.jpg  
  inflating: /content/kaggle/train_images_jpeg/814288392.jpg  
  inflating: /content/kaggle/train_images_jpeg/814547184.jpg  
  inflating: /content/kaggle/train_images_jpeg/814722861.jpg  
  inflating: /content/kaggle/train_images_jpeg/815181959.jpg  
  inflating: /content/kaggle/train_images_jpeg/815227743.jpg  
  inflating: /content/kaggle/train_images_jpeg/815702740.jpg  
  inflating: /content/kaggle/train_images_jpeg/815758241.jpg  
  inflating: /content/kaggle/train_images_jpeg/815952257.jpg  
  inflating: /content/kaggle/train_images_jpeg/816404060.jpg  
  inflating: /content/kaggle/train_images_jpeg/816584530.jpg  
  inflating: /content/kaggle/train_images_jpeg/816689138.jpg  
  inflating: /content/kaggle/train_images_jpeg/816704728.jpg  
  inflating: /content/kaggle/train_images_jpeg/816704735.jpg  
  inflating: /content/kaggle/train_images_jpeg/816935625.jpg  
  inflating: /content/kaggle/train_images_jpeg/817366566.jpg  
  inflating: /content/kaggle/train_images_jpeg/817459754.jpg  
  inflating: /content/kaggle/train_images_jpeg/817545586.jpg  
  inflating: /content/kaggle/train_images_jpeg/817778981.jpg  
  inflating: /content/kaggle/train_images_jpeg/817893600.jpg  
  inflating: /content/kaggle/train_images_jpeg/818188540.jpg  
  inflating: /content/kaggle/train_images_jpeg/81845086.jpg  
  inflating: /content/kaggle/train_images_jpeg/819599194.jpg  
  inflating: /content/kaggle/train_images_jpeg/819600313.jpg  
  inflating: /content/kaggle/train_images_jpeg/819817921.jpg  
  inflating: /content/kaggle/train_images_jpeg/820562857.jpg  
  inflating: /content/kaggle/train_images_jpeg/82105739.jpg  
  inflating: /content/kaggle/train_images_jpeg/821382382.jpg  
  inflating: /content/kaggle/train_images_jpeg/821592762.jpg  
  inflating: /content/kaggle/train_images_jpeg/821706868.jpg  
  inflating: /content/kaggle/train_images_jpeg/821895788.jpg  
  inflating: /content/kaggle/train_images_jpeg/822120250.jpg  
  inflating: /content/kaggle/train_images_jpeg/822187943.jpg  
  inflating: /content/kaggle/train_images_jpeg/822444900.jpg  
  inflating: /content/kaggle/train_images_jpeg/822532439.jpg  
  inflating: /content/kaggle/train_images_jpeg/822641071.jpg  
  inflating: /content/kaggle/train_images_jpeg/82290706.jpg  
  inflating: /content/kaggle/train_images_jpeg/823167906.jpg  
  inflating: /content/kaggle/train_images_jpeg/823276084.jpg  
  inflating: /content/kaggle/train_images_jpeg/823280173.jpg  
  inflating: /content/kaggle/train_images_jpeg/823298994.jpg  
  inflating: /content/kaggle/train_images_jpeg/823483380.jpg  
  inflating: /content/kaggle/train_images_jpeg/823568510.jpg  
  inflating: /content/kaggle/train_images_jpeg/823914480.jpg  
  inflating: /content/kaggle/train_images_jpeg/824321777.jpg  
  inflating: /content/kaggle/train_images_jpeg/824361434.jpg  
  inflating: /content/kaggle/train_images_jpeg/824408929.jpg  
  inflating: /content/kaggle/train_images_jpeg/824489541.jpg  
  inflating: /content/kaggle/train_images_jpeg/824766892.jpg  
  inflating: /content/kaggle/train_images_jpeg/824811574.jpg  
  inflating: /content/kaggle/train_images_jpeg/825263308.jpg  
  inflating: /content/kaggle/train_images_jpeg/82533757.jpg  
  inflating: /content/kaggle/train_images_jpeg/825340900.jpg  
  inflating: /content/kaggle/train_images_jpeg/825527127.jpg  
  inflating: /content/kaggle/train_images_jpeg/825551560.jpg  
  inflating: /content/kaggle/train_images_jpeg/825637783.jpg  
  inflating: /content/kaggle/train_images_jpeg/825877957.jpg  
  inflating: /content/kaggle/train_images_jpeg/826144344.jpg  
  inflating: /content/kaggle/train_images_jpeg/826231979.jpg  
  inflating: /content/kaggle/train_images_jpeg/826288261.jpg  
  inflating: /content/kaggle/train_images_jpeg/826306862.jpg  
  inflating: /content/kaggle/train_images_jpeg/826682979.jpg  
  inflating: /content/kaggle/train_images_jpeg/827007782.jpg  
  inflating: /content/kaggle/train_images_jpeg/827085399.jpg  
  inflating: /content/kaggle/train_images_jpeg/827134808.jpg  
  inflating: /content/kaggle/train_images_jpeg/827159844.jpg  
  inflating: /content/kaggle/train_images_jpeg/827284043.jpg  
  inflating: /content/kaggle/train_images_jpeg/827738585.jpg  
  inflating: /content/kaggle/train_images_jpeg/827746278.jpg  
  inflating: /content/kaggle/train_images_jpeg/828383067.jpg  
  inflating: /content/kaggle/train_images_jpeg/828472143.jpg  
  inflating: /content/kaggle/train_images_jpeg/82853961.jpg  
  inflating: /content/kaggle/train_images_jpeg/828576182.jpg  
  inflating: /content/kaggle/train_images_jpeg/828740814.jpg  
  inflating: /content/kaggle/train_images_jpeg/829018445.jpg  
  inflating: /content/kaggle/train_images_jpeg/829043523.jpg  
  inflating: /content/kaggle/train_images_jpeg/829062180.jpg  
  inflating: /content/kaggle/train_images_jpeg/829236675.jpg  
  inflating: /content/kaggle/train_images_jpeg/829442901.jpg  
  inflating: /content/kaggle/train_images_jpeg/829448982.jpg  
  inflating: /content/kaggle/train_images_jpeg/82972530.jpg  
  inflating: /content/kaggle/train_images_jpeg/829746450.jpg  
  inflating: /content/kaggle/train_images_jpeg/829835342.jpg  
  inflating: /content/kaggle/train_images_jpeg/829974709.jpg  
  inflating: /content/kaggle/train_images_jpeg/830055343.jpg  
  inflating: /content/kaggle/train_images_jpeg/830213771.jpg  
  inflating: /content/kaggle/train_images_jpeg/830231464.jpg  
  inflating: /content/kaggle/train_images_jpeg/830369134.jpg  
  inflating: /content/kaggle/train_images_jpeg/830380663.jpg  
  inflating: /content/kaggle/train_images_jpeg/830574932.jpg  
  inflating: /content/kaggle/train_images_jpeg/830740908.jpg  
  inflating: /content/kaggle/train_images_jpeg/830772376.jpg  
  inflating: /content/kaggle/train_images_jpeg/830793434.jpg  
  inflating: /content/kaggle/train_images_jpeg/830812751.jpg  
  inflating: /content/kaggle/train_images_jpeg/831001239.jpg  
  inflating: /content/kaggle/train_images_jpeg/831187317.jpg  
  inflating: /content/kaggle/train_images_jpeg/832048490.jpg  
  inflating: /content/kaggle/train_images_jpeg/832387974.jpg  
  inflating: /content/kaggle/train_images_jpeg/832440144.jpg  
  inflating: /content/kaggle/train_images_jpeg/832593154.jpg  
  inflating: /content/kaggle/train_images_jpeg/832729024.jpg  
  inflating: /content/kaggle/train_images_jpeg/832785383.jpg  
  inflating: /content/kaggle/train_images_jpeg/832869230.jpg  
  inflating: /content/kaggle/train_images_jpeg/833082515.jpg  
  inflating: /content/kaggle/train_images_jpeg/833188663.jpg  
  inflating: /content/kaggle/train_images_jpeg/83335504.jpg  
  inflating: /content/kaggle/train_images_jpeg/83337985.jpg  
  inflating: /content/kaggle/train_images_jpeg/833453231.jpg  
  inflating: /content/kaggle/train_images_jpeg/833472737.jpg  
  inflating: /content/kaggle/train_images_jpeg/833499440.jpg  
  inflating: /content/kaggle/train_images_jpeg/833599102.jpg  
  inflating: /content/kaggle/train_images_jpeg/833990099.jpg  
  inflating: /content/kaggle/train_images_jpeg/833991576.jpg  
  inflating: /content/kaggle/train_images_jpeg/834011850.jpg  
  inflating: /content/kaggle/train_images_jpeg/834333640.jpg  
  inflating: /content/kaggle/train_images_jpeg/834357600.jpg  
  inflating: /content/kaggle/train_images_jpeg/834601546.jpg  
  inflating: /content/kaggle/train_images_jpeg/835290707.jpg  
  inflating: /content/kaggle/train_images_jpeg/836250152.jpg  
  inflating: /content/kaggle/train_images_jpeg/836310616.jpg  
  inflating: /content/kaggle/train_images_jpeg/836320036.jpg  
  inflating: /content/kaggle/train_images_jpeg/836430127.jpg  
  inflating: /content/kaggle/train_images_jpeg/836589560.jpg  
  inflating: /content/kaggle/train_images_jpeg/83715695.jpg  
  inflating: /content/kaggle/train_images_jpeg/837412690.jpg  
  inflating: /content/kaggle/train_images_jpeg/837521873.jpg  
  inflating: /content/kaggle/train_images_jpeg/837916123.jpg  
  inflating: /content/kaggle/train_images_jpeg/838106879.jpg  
  inflating: /content/kaggle/train_images_jpeg/838121109.jpg  
  inflating: /content/kaggle/train_images_jpeg/838136657.jpg  
  inflating: /content/kaggle/train_images_jpeg/83814661.jpg  
  inflating: /content/kaggle/train_images_jpeg/83815023.jpg  
  inflating: /content/kaggle/train_images_jpeg/838198963.jpg  
  inflating: /content/kaggle/train_images_jpeg/838294593.jpg  
  inflating: /content/kaggle/train_images_jpeg/838404479.jpg  
  inflating: /content/kaggle/train_images_jpeg/83870062.jpg  
  inflating: /content/kaggle/train_images_jpeg/838734529.jpg  
  inflating: /content/kaggle/train_images_jpeg/839547710.jpg  
  inflating: /content/kaggle/train_images_jpeg/839709957.jpg  
  inflating: /content/kaggle/train_images_jpeg/839823259.jpg  
  inflating: /content/kaggle/train_images_jpeg/840009401.jpg  
  inflating: /content/kaggle/train_images_jpeg/84024270.jpg  
  inflating: /content/kaggle/train_images_jpeg/840541858.jpg  
  inflating: /content/kaggle/train_images_jpeg/840828184.jpg  
  inflating: /content/kaggle/train_images_jpeg/840889363.jpg  
  inflating: /content/kaggle/train_images_jpeg/841248971.jpg  
  inflating: /content/kaggle/train_images_jpeg/841447930.jpg  
  inflating: /content/kaggle/train_images_jpeg/841741628.jpg  
  inflating: /content/kaggle/train_images_jpeg/842361914.jpg  
  inflating: /content/kaggle/train_images_jpeg/842480567.jpg  
  inflating: /content/kaggle/train_images_jpeg/84269918.jpg  
  inflating: /content/kaggle/train_images_jpeg/842889608.jpg  
  inflating: /content/kaggle/train_images_jpeg/842973014.jpg  
  inflating: /content/kaggle/train_images_jpeg/843004516.jpg  
  inflating: /content/kaggle/train_images_jpeg/843145973.jpg  
  inflating: /content/kaggle/train_images_jpeg/84339133.jpg  
  inflating: /content/kaggle/train_images_jpeg/843483418.jpg  
  inflating: /content/kaggle/train_images_jpeg/843529789.jpg  
  inflating: /content/kaggle/train_images_jpeg/843818406.jpg  
  inflating: /content/kaggle/train_images_jpeg/844267975.jpg  
  inflating: /content/kaggle/train_images_jpeg/844410022.jpg  
  inflating: /content/kaggle/train_images_jpeg/844432443.jpg  
  inflating: /content/kaggle/train_images_jpeg/845131319.jpg  
  inflating: /content/kaggle/train_images_jpeg/845640217.jpg  
  inflating: /content/kaggle/train_images_jpeg/845869703.jpg  
  inflating: /content/kaggle/train_images_jpeg/845926406.jpg  
  inflating: /content/kaggle/train_images_jpeg/84598209.jpg  
  inflating: /content/kaggle/train_images_jpeg/846123439.jpg  
  inflating: /content/kaggle/train_images_jpeg/846141770.jpg  
  inflating: /content/kaggle/train_images_jpeg/846277174.jpg  
  inflating: /content/kaggle/train_images_jpeg/84635797.jpg  
  inflating: /content/kaggle/train_images_jpeg/846434156.jpg  
  inflating: /content/kaggle/train_images_jpeg/846591139.jpg  
  inflating: /content/kaggle/train_images_jpeg/846734911.jpg  
  inflating: /content/kaggle/train_images_jpeg/846824837.jpg  
  inflating: /content/kaggle/train_images_jpeg/84689733.jpg  
  inflating: /content/kaggle/train_images_jpeg/847112619.jpg  
  inflating: /content/kaggle/train_images_jpeg/847187108.jpg  
  inflating: /content/kaggle/train_images_jpeg/847229985.jpg  
  inflating: /content/kaggle/train_images_jpeg/847288162.jpg  
  inflating: /content/kaggle/train_images_jpeg/847610100.jpg  
  inflating: /content/kaggle/train_images_jpeg/847847826.jpg  
  inflating: /content/kaggle/train_images_jpeg/84787134.jpg  
  inflating: /content/kaggle/train_images_jpeg/847938979.jpg  
  inflating: /content/kaggle/train_images_jpeg/847946899.jpg  
  inflating: /content/kaggle/train_images_jpeg/848013707.jpg  
  inflating: /content/kaggle/train_images_jpeg/848032997.jpg  
  inflating: /content/kaggle/train_images_jpeg/848164169.jpg  
  inflating: /content/kaggle/train_images_jpeg/848445335.jpg  
  inflating: /content/kaggle/train_images_jpeg/848551484.jpg  
  inflating: /content/kaggle/train_images_jpeg/84878474.jpg  
  inflating: /content/kaggle/train_images_jpeg/848914861.jpg  
  inflating: /content/kaggle/train_images_jpeg/849133698.jpg  
  inflating: /content/kaggle/train_images_jpeg/849182498.jpg  
  inflating: /content/kaggle/train_images_jpeg/849184144.jpg  
  inflating: /content/kaggle/train_images_jpeg/849308241.jpg  
  inflating: /content/kaggle/train_images_jpeg/850135313.jpg  
  inflating: /content/kaggle/train_images_jpeg/850170128.jpg  
  inflating: /content/kaggle/train_images_jpeg/85027801.jpg  
  inflating: /content/kaggle/train_images_jpeg/850402862.jpg  
  inflating: /content/kaggle/train_images_jpeg/851063850.jpg  
  inflating: /content/kaggle/train_images_jpeg/851274376.jpg  
  inflating: /content/kaggle/train_images_jpeg/851313778.jpg  
  inflating: /content/kaggle/train_images_jpeg/851345669.jpg  
  inflating: /content/kaggle/train_images_jpeg/851450770.jpg  
  inflating: /content/kaggle/train_images_jpeg/851525462.jpg  
  inflating: /content/kaggle/train_images_jpeg/851527428.jpg  
  inflating: /content/kaggle/train_images_jpeg/851594010.jpg  
  inflating: /content/kaggle/train_images_jpeg/851691285.jpg  
  inflating: /content/kaggle/train_images_jpeg/851791464.jpg  
  inflating: /content/kaggle/train_images_jpeg/852177343.jpg  
  inflating: /content/kaggle/train_images_jpeg/85222011.jpg  
  inflating: /content/kaggle/train_images_jpeg/852377476.jpg  
  inflating: /content/kaggle/train_images_jpeg/852424690.jpg  
  inflating: /content/kaggle/train_images_jpeg/852636262.jpg  
  inflating: /content/kaggle/train_images_jpeg/8526431.jpg  
  inflating: /content/kaggle/train_images_jpeg/852760236.jpg  
  inflating: /content/kaggle/train_images_jpeg/852886751.jpg  
  inflating: /content/kaggle/train_images_jpeg/853854962.jpg  
  inflating: /content/kaggle/train_images_jpeg/854018271.jpg  
  inflating: /content/kaggle/train_images_jpeg/854102052.jpg  
  inflating: /content/kaggle/train_images_jpeg/854205384.jpg  
  inflating: /content/kaggle/train_images_jpeg/854309880.jpg  
  inflating: /content/kaggle/train_images_jpeg/85453943.jpg  
  inflating: /content/kaggle/train_images_jpeg/854627770.jpg  
  inflating: /content/kaggle/train_images_jpeg/854773586.jpg  
  inflating: /content/kaggle/train_images_jpeg/854883118.jpg  
  inflating: /content/kaggle/train_images_jpeg/855456135.jpg  
  inflating: /content/kaggle/train_images_jpeg/855496041.jpg  
  inflating: /content/kaggle/train_images_jpeg/856327781.jpg  
  inflating: /content/kaggle/train_images_jpeg/856446971.jpg  
  inflating: /content/kaggle/train_images_jpeg/85709703.jpg  
  inflating: /content/kaggle/train_images_jpeg/857136897.jpg  
  inflating: /content/kaggle/train_images_jpeg/857300948.jpg  
  inflating: /content/kaggle/train_images_jpeg/85739324.jpg  
  inflating: /content/kaggle/train_images_jpeg/857551546.jpg  
  inflating: /content/kaggle/train_images_jpeg/857708502.jpg  
  inflating: /content/kaggle/train_images_jpeg/857728426.jpg  
  inflating: /content/kaggle/train_images_jpeg/857836383.jpg  
  inflating: /content/kaggle/train_images_jpeg/857910285.jpg  
  inflating: /content/kaggle/train_images_jpeg/857934902.jpg  
  inflating: /content/kaggle/train_images_jpeg/857983591.jpg  
  inflating: /content/kaggle/train_images_jpeg/858147094.jpg  
  inflating: /content/kaggle/train_images_jpeg/858578370.jpg  
  inflating: /content/kaggle/train_images_jpeg/858590964.jpg  
  inflating: /content/kaggle/train_images_jpeg/85888563.jpg  
  inflating: /content/kaggle/train_images_jpeg/859362925.jpg  
  inflating: /content/kaggle/train_images_jpeg/860103938.jpg  
  inflating: /content/kaggle/train_images_jpeg/860267524.jpg  
  inflating: /content/kaggle/train_images_jpeg/860380969.jpg  
  inflating: /content/kaggle/train_images_jpeg/860415279.jpg  
  inflating: /content/kaggle/train_images_jpeg/860744310.jpg  
  inflating: /content/kaggle/train_images_jpeg/860758884.jpg  
  inflating: /content/kaggle/train_images_jpeg/860785504.jpg  
  inflating: /content/kaggle/train_images_jpeg/860826658.jpg  
  inflating: /content/kaggle/train_images_jpeg/860926146.jpg  
  inflating: /content/kaggle/train_images_jpeg/862068300.jpg  
  inflating: /content/kaggle/train_images_jpeg/862141742.jpg  
  inflating: /content/kaggle/train_images_jpeg/862706097.jpg  
  inflating: /content/kaggle/train_images_jpeg/86271785.jpg  
  inflating: /content/kaggle/train_images_jpeg/863348541.jpg  
  inflating: /content/kaggle/train_images_jpeg/863369540.jpg  
  inflating: /content/kaggle/train_images_jpeg/863550761.jpg  
  inflating: /content/kaggle/train_images_jpeg/863785025.jpg  
  inflating: /content/kaggle/train_images_jpeg/864235203.jpg  
  inflating: /content/kaggle/train_images_jpeg/864600398.jpg  
  inflating: /content/kaggle/train_images_jpeg/864636811.jpg  
  inflating: /content/kaggle/train_images_jpeg/864816883.jpg  
  inflating: /content/kaggle/train_images_jpeg/864903108.jpg  
  inflating: /content/kaggle/train_images_jpeg/864933566.jpg  
  inflating: /content/kaggle/train_images_jpeg/865580599.jpg  
  inflating: /content/kaggle/train_images_jpeg/865733342.jpg  
  inflating: /content/kaggle/train_images_jpeg/866479018.jpg  
  inflating: /content/kaggle/train_images_jpeg/866496354.jpg  
  inflating: /content/kaggle/train_images_jpeg/866506259.jpg  
  inflating: /content/kaggle/train_images_jpeg/866605488.jpg  
  inflating: /content/kaggle/train_images_jpeg/867025399.jpg  
  inflating: /content/kaggle/train_images_jpeg/867127390.jpg  
  inflating: /content/kaggle/train_images_jpeg/867622395.jpg  
  inflating: /content/kaggle/train_images_jpeg/867855885.jpg  
  inflating: /content/kaggle/train_images_jpeg/868228069.jpg  
  inflating: /content/kaggle/train_images_jpeg/868275841.jpg  
  inflating: /content/kaggle/train_images_jpeg/868625768.jpg  
  inflating: /content/kaggle/train_images_jpeg/86890165.jpg  
  inflating: /content/kaggle/train_images_jpeg/870197588.jpg  
  inflating: /content/kaggle/train_images_jpeg/870659549.jpg  
  inflating: /content/kaggle/train_images_jpeg/870679029.jpg  
  inflating: /content/kaggle/train_images_jpeg/870967605.jpg  
  inflating: /content/kaggle/train_images_jpeg/871035730.jpg  
  inflating: /content/kaggle/train_images_jpeg/871044756.jpg  
  inflating: /content/kaggle/train_images_jpeg/871153188.jpg  
  inflating: /content/kaggle/train_images_jpeg/871251409.jpg  
  inflating: /content/kaggle/train_images_jpeg/871333676.jpg  
  inflating: /content/kaggle/train_images_jpeg/871530899.jpg  
  inflating: /content/kaggle/train_images_jpeg/87170987.jpg  
  inflating: /content/kaggle/train_images_jpeg/871711168.jpg  
  inflating: /content/kaggle/train_images_jpeg/871726672.jpg  
  inflating: /content/kaggle/train_images_jpeg/871966628.jpg  
  inflating: /content/kaggle/train_images_jpeg/872344634.jpg  
  inflating: /content/kaggle/train_images_jpeg/872498616.jpg  
  inflating: /content/kaggle/train_images_jpeg/872590456.jpg  
  inflating: /content/kaggle/train_images_jpeg/872771572.jpg  
  inflating: /content/kaggle/train_images_jpeg/872791534.jpg  
  inflating: /content/kaggle/train_images_jpeg/872798260.jpg  
  inflating: /content/kaggle/train_images_jpeg/872856215.jpg  
  inflating: /content/kaggle/train_images_jpeg/872867609.jpg  
  inflating: /content/kaggle/train_images_jpeg/872917593.jpg  
  inflating: /content/kaggle/train_images_jpeg/87295869.jpg  
  inflating: /content/kaggle/train_images_jpeg/87302244.jpg  
  inflating: /content/kaggle/train_images_jpeg/873095310.jpg  
  inflating: /content/kaggle/train_images_jpeg/873125819.jpg  
  inflating: /content/kaggle/train_images_jpeg/873205488.jpg  
  inflating: /content/kaggle/train_images_jpeg/873468650.jpg  
  inflating: /content/kaggle/train_images_jpeg/873526870.jpg  
  inflating: /content/kaggle/train_images_jpeg/873637313.jpg  
  inflating: /content/kaggle/train_images_jpeg/873720819.jpg  
  inflating: /content/kaggle/train_images_jpeg/873753078.jpg  
  inflating: /content/kaggle/train_images_jpeg/874590064.jpg  
  inflating: /content/kaggle/train_images_jpeg/87470037.jpg  
  inflating: /content/kaggle/train_images_jpeg/874716908.jpg  
  inflating: /content/kaggle/train_images_jpeg/874878736.jpg  
  inflating: /content/kaggle/train_images_jpeg/875205703.jpg  
  inflating: /content/kaggle/train_images_jpeg/875229192.jpg  
  inflating: /content/kaggle/train_images_jpeg/875360512.jpg  
  inflating: /content/kaggle/train_images_jpeg/875582353.jpg  
  inflating: /content/kaggle/train_images_jpeg/87567596.jpg  
  inflating: /content/kaggle/train_images_jpeg/875836279.jpg  
  inflating: /content/kaggle/train_images_jpeg/875889242.jpg  
  inflating: /content/kaggle/train_images_jpeg/876450779.jpg  
  inflating: /content/kaggle/train_images_jpeg/87653700.jpg  
  inflating: /content/kaggle/train_images_jpeg/876588489.jpg  
  inflating: /content/kaggle/train_images_jpeg/876612201.jpg  
  inflating: /content/kaggle/train_images_jpeg/87664918.jpg  
  inflating: /content/kaggle/train_images_jpeg/876666484.jpg  
  inflating: /content/kaggle/train_images_jpeg/876953624.jpg  
  inflating: /content/kaggle/train_images_jpeg/87703299.jpg  
  inflating: /content/kaggle/train_images_jpeg/877430309.jpg  
  inflating: /content/kaggle/train_images_jpeg/877739255.jpg  
  inflating: /content/kaggle/train_images_jpeg/878020784.jpg  
  inflating: /content/kaggle/train_images_jpeg/87817214.jpg  
  inflating: /content/kaggle/train_images_jpeg/878183173.jpg  
  inflating: /content/kaggle/train_images_jpeg/878188830.jpg  
  inflating: /content/kaggle/train_images_jpeg/878287964.jpg  
  inflating: /content/kaggle/train_images_jpeg/878628068.jpg  
  inflating: /content/kaggle/train_images_jpeg/878720080.jpg  
  inflating: /content/kaggle/train_images_jpeg/878936941.jpg  
  inflating: /content/kaggle/train_images_jpeg/879089403.jpg  
  inflating: /content/kaggle/train_images_jpeg/879360102.jpg  
  inflating: /content/kaggle/train_images_jpeg/879395678.jpg  
  inflating: /content/kaggle/train_images_jpeg/879939600.jpg  
  inflating: /content/kaggle/train_images_jpeg/879965131.jpg  
  inflating: /content/kaggle/train_images_jpeg/880178968.jpg  
  inflating: /content/kaggle/train_images_jpeg/880913529.jpg  
  inflating: /content/kaggle/train_images_jpeg/880947570.jpg  
  inflating: /content/kaggle/train_images_jpeg/881020012.jpg  
  inflating: /content/kaggle/train_images_jpeg/881299929.jpg  
  inflating: /content/kaggle/train_images_jpeg/881681381.jpg  
  inflating: /content/kaggle/train_images_jpeg/881721336.jpg  
  inflating: /content/kaggle/train_images_jpeg/881727330.jpg  
  inflating: /content/kaggle/train_images_jpeg/882292084.jpg  
  inflating: /content/kaggle/train_images_jpeg/883103193.jpg  
  inflating: /content/kaggle/train_images_jpeg/883338295.jpg  
  inflating: /content/kaggle/train_images_jpeg/883362689.jpg  
  inflating: /content/kaggle/train_images_jpeg/883429890.jpg  
  inflating: /content/kaggle/train_images_jpeg/883807735.jpg  
  inflating: /content/kaggle/train_images_jpeg/884267453.jpg  
  inflating: /content/kaggle/train_images_jpeg/88427493.jpg  
  inflating: /content/kaggle/train_images_jpeg/88427642.jpg  
  inflating: /content/kaggle/train_images_jpeg/884360889.jpg  
  inflating: /content/kaggle/train_images_jpeg/884573629.jpg  
  inflating: /content/kaggle/train_images_jpeg/884612746.jpg  
  inflating: /content/kaggle/train_images_jpeg/884672332.jpg  
  inflating: /content/kaggle/train_images_jpeg/885231391.jpg  
  inflating: /content/kaggle/train_images_jpeg/885374983.jpg  
  inflating: /content/kaggle/train_images_jpeg/885474029.jpg  
  inflating: /content/kaggle/train_images_jpeg/886180513.jpg  
  inflating: /content/kaggle/train_images_jpeg/886212263.jpg  
  inflating: /content/kaggle/train_images_jpeg/886449535.jpg  
  inflating: /content/kaggle/train_images_jpeg/886468951.jpg  
  inflating: /content/kaggle/train_images_jpeg/886507028.jpg  
  inflating: /content/kaggle/train_images_jpeg/886793145.jpg  
  inflating: /content/kaggle/train_images_jpeg/886973933.jpg  
  inflating: /content/kaggle/train_images_jpeg/887146964.jpg  
  inflating: /content/kaggle/train_images_jpeg/887272418.jpg  
  inflating: /content/kaggle/train_images_jpeg/887328137.jpg  
  inflating: /content/kaggle/train_images_jpeg/887896841.jpg  
  inflating: /content/kaggle/train_images_jpeg/888139689.jpg  
  inflating: /content/kaggle/train_images_jpeg/888266861.jpg  
  inflating: /content/kaggle/train_images_jpeg/888332390.jpg  
  inflating: /content/kaggle/train_images_jpeg/888355689.jpg  
  inflating: /content/kaggle/train_images_jpeg/888503637.jpg  
  inflating: /content/kaggle/train_images_jpeg/888578440.jpg  
  inflating: /content/kaggle/train_images_jpeg/88884986.jpg  
  inflating: /content/kaggle/train_images_jpeg/888983519.jpg  
  inflating: /content/kaggle/train_images_jpeg/889052134.jpg  
  inflating: /content/kaggle/train_images_jpeg/889645201.jpg  
  inflating: /content/kaggle/train_images_jpeg/889769958.jpg  
  inflating: /content/kaggle/train_images_jpeg/889797204.jpg  
  inflating: /content/kaggle/train_images_jpeg/889990340.jpg  
  inflating: /content/kaggle/train_images_jpeg/890004895.jpg  
  inflating: /content/kaggle/train_images_jpeg/890232152.jpg  
  inflating: /content/kaggle/train_images_jpeg/890494248.jpg  
  inflating: /content/kaggle/train_images_jpeg/890852512.jpg  
  inflating: /content/kaggle/train_images_jpeg/891029839.jpg  
  inflating: /content/kaggle/train_images_jpeg/891320496.jpg  
  inflating: /content/kaggle/train_images_jpeg/891426683.jpg  
  inflating: /content/kaggle/train_images_jpeg/891797832.jpg  
  inflating: /content/kaggle/train_images_jpeg/891874541.jpg  
  inflating: /content/kaggle/train_images_jpeg/891967804.jpg  
  inflating: /content/kaggle/train_images_jpeg/892025744.jpg  
  inflating: /content/kaggle/train_images_jpeg/893035.jpg  
  inflating: /content/kaggle/train_images_jpeg/893103956.jpg  
  inflating: /content/kaggle/train_images_jpeg/893564766.jpg  
  inflating: /content/kaggle/train_images_jpeg/89393849.jpg  
  inflating: /content/kaggle/train_images_jpeg/894286115.jpg  
  inflating: /content/kaggle/train_images_jpeg/89450181.jpg  
  inflating: /content/kaggle/train_images_jpeg/894506110.jpg  
  inflating: /content/kaggle/train_images_jpeg/894849758.jpg  
  inflating: /content/kaggle/train_images_jpeg/895206716.jpg  
  inflating: /content/kaggle/train_images_jpeg/895280240.jpg  
  inflating: /content/kaggle/train_images_jpeg/895356426.jpg  
  inflating: /content/kaggle/train_images_jpeg/89587006.jpg  
  inflating: /content/kaggle/train_images_jpeg/895910836.jpg  
  inflating: /content/kaggle/train_images_jpeg/896047900.jpg  
  inflating: /content/kaggle/train_images_jpeg/896277237.jpg  
  inflating: /content/kaggle/train_images_jpeg/896983896.jpg  
  inflating: /content/kaggle/train_images_jpeg/897274381.jpg  
  inflating: /content/kaggle/train_images_jpeg/897533656.jpg  
  inflating: /content/kaggle/train_images_jpeg/897638042.jpg  
  inflating: /content/kaggle/train_images_jpeg/897739604.jpg  
  inflating: /content/kaggle/train_images_jpeg/897745173.jpg  
  inflating: /content/kaggle/train_images_jpeg/897925605.jpg  
  inflating: /content/kaggle/train_images_jpeg/897929380.jpg  
  inflating: /content/kaggle/train_images_jpeg/898210047.jpg  
  inflating: /content/kaggle/train_images_jpeg/898358711.jpg  
  inflating: /content/kaggle/train_images_jpeg/898386629.jpg  
  inflating: /content/kaggle/train_images_jpeg/898578569.jpg  
  inflating: /content/kaggle/train_images_jpeg/898753077.jpg  
  inflating: /content/kaggle/train_images_jpeg/899172508.jpg  
  inflating: /content/kaggle/train_images_jpeg/899398361.jpg  
  inflating: /content/kaggle/train_images_jpeg/899918978.jpg  
  inflating: /content/kaggle/train_images_jpeg/900061330.jpg  
  inflating: /content/kaggle/train_images_jpeg/900061372.jpg  
  inflating: /content/kaggle/train_images_jpeg/900067937.jpg  
  inflating: /content/kaggle/train_images_jpeg/900415263.jpg  
  inflating: /content/kaggle/train_images_jpeg/900445109.jpg  
  inflating: /content/kaggle/train_images_jpeg/900587637.jpg  
  inflating: /content/kaggle/train_images_jpeg/90091578.jpg  
  inflating: /content/kaggle/train_images_jpeg/901055316.jpg  
  inflating: /content/kaggle/train_images_jpeg/901063337.jpg  
  inflating: /content/kaggle/train_images_jpeg/901196930.jpg  
  inflating: /content/kaggle/train_images_jpeg/901274607.jpg  
  inflating: /content/kaggle/train_images_jpeg/901404486.jpg  
  inflating: /content/kaggle/train_images_jpeg/901443823.jpg  
  inflating: /content/kaggle/train_images_jpeg/901886086.jpg  
  inflating: /content/kaggle/train_images_jpeg/902007589.jpg  
  inflating: /content/kaggle/train_images_jpeg/902139572.jpg  
  inflating: /content/kaggle/train_images_jpeg/902299178.jpg  
  inflating: /content/kaggle/train_images_jpeg/902300140.jpg  
  inflating: /content/kaggle/train_images_jpeg/902429772.jpg  
  inflating: /content/kaggle/train_images_jpeg/903186998.jpg  
  inflating: /content/kaggle/train_images_jpeg/903252353.jpg  
  inflating: /content/kaggle/train_images_jpeg/903309442.jpg  
  inflating: /content/kaggle/train_images_jpeg/90333661.jpg  
  inflating: /content/kaggle/train_images_jpeg/903439156.jpg  
  inflating: /content/kaggle/train_images_jpeg/90391907.jpg  
  inflating: /content/kaggle/train_images_jpeg/904192489.jpg  
  inflating: /content/kaggle/train_images_jpeg/904658704.jpg  
  inflating: /content/kaggle/train_images_jpeg/904699922.jpg  
  inflating: /content/kaggle/train_images_jpeg/904750787.jpg  
  inflating: /content/kaggle/train_images_jpeg/904785196.jpg  
  inflating: /content/kaggle/train_images_jpeg/904850856.jpg  
  inflating: /content/kaggle/train_images_jpeg/905336234.jpg  
  inflating: /content/kaggle/train_images_jpeg/905387859.jpg  
  inflating: /content/kaggle/train_images_jpeg/90543852.jpg  
  inflating: /content/kaggle/train_images_jpeg/905776324.jpg  
  inflating: /content/kaggle/train_images_jpeg/90606533.jpg  
  inflating: /content/kaggle/train_images_jpeg/906115763.jpg  
  inflating: /content/kaggle/train_images_jpeg/90625412.jpg  
  inflating: /content/kaggle/train_images_jpeg/90670123.jpg  
  inflating: /content/kaggle/train_images_jpeg/906750363.jpg  
  inflating: /content/kaggle/train_images_jpeg/906773049.jpg  
  inflating: /content/kaggle/train_images_jpeg/907434734.jpg  
  inflating: /content/kaggle/train_images_jpeg/907691648.jpg  
  inflating: /content/kaggle/train_images_jpeg/907755458.jpg  
  inflating: /content/kaggle/train_images_jpeg/90800414.jpg  
  inflating: /content/kaggle/train_images_jpeg/908540232.jpg  
  inflating: /content/kaggle/train_images_jpeg/908770281.jpg  
  inflating: /content/kaggle/train_images_jpeg/909032861.jpg  
  inflating: /content/kaggle/train_images_jpeg/909125892.jpg  
  inflating: /content/kaggle/train_images_jpeg/909499250.jpg  
  inflating: /content/kaggle/train_images_jpeg/909719809.jpg  
  inflating: /content/kaggle/train_images_jpeg/910008110.jpg  
  inflating: /content/kaggle/train_images_jpeg/91058248.jpg  
  inflating: /content/kaggle/train_images_jpeg/910617288.jpg  
  inflating: /content/kaggle/train_images_jpeg/910735649.jpg  
  inflating: /content/kaggle/train_images_jpeg/910870110.jpg  
  inflating: /content/kaggle/train_images_jpeg/911144460.jpg  
  inflating: /content/kaggle/train_images_jpeg/911151169.jpg  
  inflating: /content/kaggle/train_images_jpeg/911449508.jpg  
  inflating: /content/kaggle/train_images_jpeg/911861181.jpg  
  inflating: /content/kaggle/train_images_jpeg/912150703.jpg  
  inflating: /content/kaggle/train_images_jpeg/912628381.jpg  
  inflating: /content/kaggle/train_images_jpeg/91285032.jpg  
  inflating: /content/kaggle/train_images_jpeg/912860596.jpg  
  inflating: /content/kaggle/train_images_jpeg/912912811.jpg  
  inflating: /content/kaggle/train_images_jpeg/912959875.jpg  
  inflating: /content/kaggle/train_images_jpeg/913152954.jpg  
  inflating: /content/kaggle/train_images_jpeg/913261951.jpg  
  inflating: /content/kaggle/train_images_jpeg/913294875.jpg  
  inflating: /content/kaggle/train_images_jpeg/913436788.jpg  
  inflating: /content/kaggle/train_images_jpeg/913480541.jpg  
  inflating: /content/kaggle/train_images_jpeg/913567043.jpg  
  inflating: /content/kaggle/train_images_jpeg/913589859.jpg  
  inflating: /content/kaggle/train_images_jpeg/913877640.jpg  
  inflating: /content/kaggle/train_images_jpeg/913968833.jpg  
  inflating: /content/kaggle/train_images_jpeg/914090622.jpg  
  inflating: /content/kaggle/train_images_jpeg/914202291.jpg  
  inflating: /content/kaggle/train_images_jpeg/91429187.jpg  
  inflating: /content/kaggle/train_images_jpeg/914936842.jpg  
  inflating: /content/kaggle/train_images_jpeg/915371714.jpg  
  inflating: /content/kaggle/train_images_jpeg/915715866.jpg  
  inflating: /content/kaggle/train_images_jpeg/915719493.jpg  
  inflating: /content/kaggle/train_images_jpeg/915934159.jpg  
  inflating: /content/kaggle/train_images_jpeg/916184661.jpg  
  inflating: /content/kaggle/train_images_jpeg/916221971.jpg  
  inflating: /content/kaggle/train_images_jpeg/916237184.jpg  
  inflating: /content/kaggle/train_images_jpeg/916448505.jpg  
  inflating: /content/kaggle/train_images_jpeg/916669333.jpg  
  inflating: /content/kaggle/train_images_jpeg/917014359.jpg  
  inflating: /content/kaggle/train_images_jpeg/917042560.jpg  
  inflating: /content/kaggle/train_images_jpeg/917153346.jpg  
  inflating: /content/kaggle/train_images_jpeg/91726136.jpg  
  inflating: /content/kaggle/train_images_jpeg/917306689.jpg  
  inflating: /content/kaggle/train_images_jpeg/917489819.jpg  
  inflating: /content/kaggle/train_images_jpeg/917739753.jpg  
  inflating: /content/kaggle/train_images_jpeg/91815905.jpg  
  inflating: /content/kaggle/train_images_jpeg/918168306.jpg  
  inflating: /content/kaggle/train_images_jpeg/918301064.jpg  
  inflating: /content/kaggle/train_images_jpeg/918306924.jpg  
  inflating: /content/kaggle/train_images_jpeg/91850516.jpg  
  inflating: /content/kaggle/train_images_jpeg/918534391.jpg  
  inflating: /content/kaggle/train_images_jpeg/918535914.jpg  
  inflating: /content/kaggle/train_images_jpeg/918605153.jpg  
  inflating: /content/kaggle/train_images_jpeg/918675350.jpg  
  inflating: /content/kaggle/train_images_jpeg/918696208.jpg  
  inflating: /content/kaggle/train_images_jpeg/918823473.jpg  
  inflating: /content/kaggle/train_images_jpeg/919127864.jpg  
  inflating: /content/kaggle/train_images_jpeg/919479322.jpg  
  inflating: /content/kaggle/train_images_jpeg/919514433.jpg  
  inflating: /content/kaggle/train_images_jpeg/919581401.jpg  
  inflating: /content/kaggle/train_images_jpeg/919597577.jpg  
  inflating: /content/kaggle/train_images_jpeg/920229727.jpg  
  inflating: /content/kaggle/train_images_jpeg/920295213.jpg  
  inflating: /content/kaggle/train_images_jpeg/920401054.jpg  
  inflating: /content/kaggle/train_images_jpeg/920600492.jpg  
  inflating: /content/kaggle/train_images_jpeg/920623788.jpg  
  inflating: /content/kaggle/train_images_jpeg/920702050.jpg  
  inflating: /content/kaggle/train_images_jpeg/920981656.jpg  
  inflating: /content/kaggle/train_images_jpeg/92128754.jpg  
  inflating: /content/kaggle/train_images_jpeg/921425159.jpg  
  inflating: /content/kaggle/train_images_jpeg/921779789.jpg  
  inflating: /content/kaggle/train_images_jpeg/921830074.jpg  
  inflating: /content/kaggle/train_images_jpeg/921927890.jpg  
  inflating: /content/kaggle/train_images_jpeg/921975951.jpg  
  inflating: /content/kaggle/train_images_jpeg/922000226.jpg  
  inflating: /content/kaggle/train_images_jpeg/922100024.jpg  
  inflating: /content/kaggle/train_images_jpeg/922395842.jpg  
  inflating: /content/kaggle/train_images_jpeg/9224019.jpg  
  inflating: /content/kaggle/train_images_jpeg/922729409.jpg  
  inflating: /content/kaggle/train_images_jpeg/922756535.jpg  
  inflating: /content/kaggle/train_images_jpeg/922802657.jpg  
  inflating: /content/kaggle/train_images_jpeg/922887047.jpg  
  inflating: /content/kaggle/train_images_jpeg/923034542.jpg  
  inflating: /content/kaggle/train_images_jpeg/923294415.jpg  
  inflating: /content/kaggle/train_images_jpeg/92340091.jpg  
  inflating: /content/kaggle/train_images_jpeg/923499439.jpg  
  inflating: /content/kaggle/train_images_jpeg/923718.jpg  
  inflating: /content/kaggle/train_images_jpeg/923880010.jpg  
  inflating: /content/kaggle/train_images_jpeg/923936404.jpg  
  inflating: /content/kaggle/train_images_jpeg/923965406.jpg  
  inflating: /content/kaggle/train_images_jpeg/923987815.jpg  
  inflating: /content/kaggle/train_images_jpeg/924036255.jpg  
  inflating: /content/kaggle/train_images_jpeg/924049818.jpg  
  inflating: /content/kaggle/train_images_jpeg/92439956.jpg  
  inflating: /content/kaggle/train_images_jpeg/925327697.jpg  
  inflating: /content/kaggle/train_images_jpeg/925427672.jpg  
  inflating: /content/kaggle/train_images_jpeg/9255514.jpg  
  inflating: /content/kaggle/train_images_jpeg/925707812.jpg  
  inflating: /content/kaggle/train_images_jpeg/925945591.jpg  
  inflating: /content/kaggle/train_images_jpeg/926848319.jpg  
  inflating: /content/kaggle/train_images_jpeg/927165736.jpg  
  inflating: /content/kaggle/train_images_jpeg/927454705.jpg  
  inflating: /content/kaggle/train_images_jpeg/927566387.jpg  
  inflating: /content/kaggle/train_images_jpeg/927713688.jpg  
  inflating: /content/kaggle/train_images_jpeg/927745791.jpg  
  inflating: /content/kaggle/train_images_jpeg/929286178.jpg  
  inflating: /content/kaggle/train_images_jpeg/929341901.jpg  
  inflating: /content/kaggle/train_images_jpeg/929638503.jpg  
  inflating: /content/kaggle/train_images_jpeg/929695181.jpg  
  inflating: /content/kaggle/train_images_jpeg/930097123.jpg  
  inflating: /content/kaggle/train_images_jpeg/9312065.jpg  
  inflating: /content/kaggle/train_images_jpeg/931787054.jpg  
  inflating: /content/kaggle/train_images_jpeg/931943521.jpg  
  inflating: /content/kaggle/train_images_jpeg/93194372.jpg  
  inflating: /content/kaggle/train_images_jpeg/932287482.jpg  
  inflating: /content/kaggle/train_images_jpeg/932462711.jpg  
  inflating: /content/kaggle/train_images_jpeg/932643551.jpg  
  inflating: /content/kaggle/train_images_jpeg/932915192.jpg  
  inflating: /content/kaggle/train_images_jpeg/932971696.jpg  
  inflating: /content/kaggle/train_images_jpeg/932990043.jpg  
  inflating: /content/kaggle/train_images_jpeg/933070130.jpg  
  inflating: /content/kaggle/train_images_jpeg/933074739.jpg  
  inflating: /content/kaggle/train_images_jpeg/933311576.jpg  
  inflating: /content/kaggle/train_images_jpeg/933957288.jpg  
  inflating: /content/kaggle/train_images_jpeg/934025261.jpg  
  inflating: /content/kaggle/train_images_jpeg/934902236.jpg  
  inflating: /content/kaggle/train_images_jpeg/935569912.jpg  
  inflating: /content/kaggle/train_images_jpeg/935603838.jpg  
  inflating: /content/kaggle/train_images_jpeg/935621798.jpg  
  inflating: /content/kaggle/train_images_jpeg/935723534.jpg  
  inflating: /content/kaggle/train_images_jpeg/936011517.jpg  
  inflating: /content/kaggle/train_images_jpeg/936336303.jpg  
  inflating: /content/kaggle/train_images_jpeg/936438569.jpg  
  inflating: /content/kaggle/train_images_jpeg/93658953.jpg  
  inflating: /content/kaggle/train_images_jpeg/936775758.jpg  
  inflating: /content/kaggle/train_images_jpeg/936942979.jpg  
  inflating: /content/kaggle/train_images_jpeg/937045512.jpg  
  inflating: /content/kaggle/train_images_jpeg/937960341.jpg  
  inflating: /content/kaggle/train_images_jpeg/938396942.jpg  
  inflating: /content/kaggle/train_images_jpeg/938595992.jpg  
  inflating: /content/kaggle/train_images_jpeg/938742634.jpg  
  inflating: /content/kaggle/train_images_jpeg/938751255.jpg  
  inflating: /content/kaggle/train_images_jpeg/938858274.jpg  
  inflating: /content/kaggle/train_images_jpeg/938932168.jpg  
  inflating: /content/kaggle/train_images_jpeg/939109747.jpg  
  inflating: /content/kaggle/train_images_jpeg/939153733.jpg  
  inflating: /content/kaggle/train_images_jpeg/939241436.jpg  
  inflating: /content/kaggle/train_images_jpeg/939534770.jpg  
  inflating: /content/kaggle/train_images_jpeg/93955818.jpg  
  inflating: /content/kaggle/train_images_jpeg/939566384.jpg  
  inflating: /content/kaggle/train_images_jpeg/93971994.jpg  
  inflating: /content/kaggle/train_images_jpeg/939773003.jpg  
  inflating: /content/kaggle/train_images_jpeg/939849436.jpg  
  inflating: /content/kaggle/train_images_jpeg/939861475.jpg  
  inflating: /content/kaggle/train_images_jpeg/93993180.jpg  
  inflating: /content/kaggle/train_images_jpeg/940055437.jpg  
  inflating: /content/kaggle/train_images_jpeg/940080842.jpg  
  inflating: /content/kaggle/train_images_jpeg/940186959.jpg  
  inflating: /content/kaggle/train_images_jpeg/94072059.jpg  
  inflating: /content/kaggle/train_images_jpeg/940742966.jpg  
  inflating: /content/kaggle/train_images_jpeg/940939729.jpg  
  inflating: /content/kaggle/train_images_jpeg/940947597.jpg  
  inflating: /content/kaggle/train_images_jpeg/941078633.jpg  
  inflating: /content/kaggle/train_images_jpeg/941512047.jpg  
  inflating: /content/kaggle/train_images_jpeg/94157515.jpg  
  inflating: /content/kaggle/train_images_jpeg/94205320.jpg  
  inflating: /content/kaggle/train_images_jpeg/942420393.jpg  
  inflating: /content/kaggle/train_images_jpeg/942584104.jpg  
  inflating: /content/kaggle/train_images_jpeg/942738737.jpg  
  inflating: /content/kaggle/train_images_jpeg/942754311.jpg  
  inflating: /content/kaggle/train_images_jpeg/942994246.jpg  
  inflating: /content/kaggle/train_images_jpeg/943096902.jpg  
  inflating: /content/kaggle/train_images_jpeg/943110824.jpg  
  inflating: /content/kaggle/train_images_jpeg/943323109.jpg  
  inflating: /content/kaggle/train_images_jpeg/943360126.jpg  
  inflating: /content/kaggle/train_images_jpeg/943634756.jpg  
  inflating: /content/kaggle/train_images_jpeg/943699790.jpg  
  inflating: /content/kaggle/train_images_jpeg/943969763.jpg  
  inflating: /content/kaggle/train_images_jpeg/944255811.jpg  
  inflating: /content/kaggle/train_images_jpeg/944398652.jpg  
  inflating: /content/kaggle/train_images_jpeg/944726140.jpg  
  inflating: /content/kaggle/train_images_jpeg/944732366.jpg  
  inflating: /content/kaggle/train_images_jpeg/944920581.jpg  
  inflating: /content/kaggle/train_images_jpeg/94506249.jpg  
  inflating: /content/kaggle/train_images_jpeg/945272909.jpg  
  inflating: /content/kaggle/train_images_jpeg/94536090.jpg  
  inflating: /content/kaggle/train_images_jpeg/9454129.jpg  
  inflating: /content/kaggle/train_images_jpeg/945491819.jpg  
  inflating: /content/kaggle/train_images_jpeg/945680317.jpg  
  inflating: /content/kaggle/train_images_jpeg/94587407.jpg  
  inflating: /content/kaggle/train_images_jpeg/945966296.jpg  
  inflating: /content/kaggle/train_images_jpeg/946164219.jpg  
  inflating: /content/kaggle/train_images_jpeg/947208202.jpg  
  inflating: /content/kaggle/train_images_jpeg/947245045.jpg  
  inflating: /content/kaggle/train_images_jpeg/947554618.jpg  
  inflating: /content/kaggle/train_images_jpeg/947599962.jpg  
  inflating: /content/kaggle/train_images_jpeg/948186989.jpg  
  inflating: /content/kaggle/train_images_jpeg/948363257.jpg  
  inflating: /content/kaggle/train_images_jpeg/948559323.jpg  
  inflating: /content/kaggle/train_images_jpeg/948754372.jpg  
  inflating: /content/kaggle/train_images_jpeg/94882276.jpg  
  inflating: /content/kaggle/train_images_jpeg/948836344.jpg  
  inflating: /content/kaggle/train_images_jpeg/948846771.jpg  
  inflating: /content/kaggle/train_images_jpeg/949046024.jpg  
  inflating: /content/kaggle/train_images_jpeg/94958616.jpg  
  inflating: /content/kaggle/train_images_jpeg/949963080.jpg  
  inflating: /content/kaggle/train_images_jpeg/949971770.jpg  
  inflating: /content/kaggle/train_images_jpeg/950405197.jpg  
  inflating: /content/kaggle/train_images_jpeg/950677455.jpg  
  inflating: /content/kaggle/train_images_jpeg/950886267.jpg  
  inflating: /content/kaggle/train_images_jpeg/951048679.jpg  
  inflating: /content/kaggle/train_images_jpeg/95121846.jpg  
  inflating: /content/kaggle/train_images_jpeg/951326010.jpg  
  inflating: /content/kaggle/train_images_jpeg/951448683.jpg  
  inflating: /content/kaggle/train_images_jpeg/9516242.jpg  
  inflating: /content/kaggle/train_images_jpeg/951654457.jpg  
  inflating: /content/kaggle/train_images_jpeg/951757474.jpg  
  inflating: /content/kaggle/train_images_jpeg/951959546.jpg  
  inflating: /content/kaggle/train_images_jpeg/952111080.jpg  
  inflating: /content/kaggle/train_images_jpeg/952146173.jpg  
  inflating: /content/kaggle/train_images_jpeg/952303505.jpg  
  inflating: /content/kaggle/train_images_jpeg/952391818.jpg  
  inflating: /content/kaggle/train_images_jpeg/952519185.jpg  
  inflating: /content/kaggle/train_images_jpeg/952920056.jpg  
  inflating: /content/kaggle/train_images_jpeg/953218056.jpg  
  inflating: /content/kaggle/train_images_jpeg/95322868.jpg  
  inflating: /content/kaggle/train_images_jpeg/953313732.jpg  
  inflating: /content/kaggle/train_images_jpeg/953375887.jpg  
  inflating: /content/kaggle/train_images_jpeg/953808797.jpg  
  inflating: /content/kaggle/train_images_jpeg/953844785.jpg  
  inflating: /content/kaggle/train_images_jpeg/953936588.jpg  
  inflating: /content/kaggle/train_images_jpeg/954479560.jpg  
  inflating: /content/kaggle/train_images_jpeg/954749288.jpg  
  inflating: /content/kaggle/train_images_jpeg/954778743.jpg  
  inflating: /content/kaggle/train_images_jpeg/9548002.jpg  
  inflating: /content/kaggle/train_images_jpeg/955110808.jpg  
  inflating: /content/kaggle/train_images_jpeg/955346673.jpg  
  inflating: /content/kaggle/train_images_jpeg/95553397.jpg  
  inflating: /content/kaggle/train_images_jpeg/955794248.jpg  
  inflating: /content/kaggle/train_images_jpeg/956312100.jpg  
  inflating: /content/kaggle/train_images_jpeg/956315464.jpg  
  inflating: /content/kaggle/train_images_jpeg/956343434.jpg  
  inflating: /content/kaggle/train_images_jpeg/956840852.jpg  
  inflating: /content/kaggle/train_images_jpeg/957199549.jpg  
  inflating: /content/kaggle/train_images_jpeg/957437817.jpg  
  inflating: /content/kaggle/train_images_jpeg/957970680.jpg  
  inflating: /content/kaggle/train_images_jpeg/958074553.jpg  
  inflating: /content/kaggle/train_images_jpeg/958289716.jpg  
  inflating: /content/kaggle/train_images_jpeg/958465343.jpg  
  inflating: /content/kaggle/train_images_jpeg/958551982.jpg  
  inflating: /content/kaggle/train_images_jpeg/958879588.jpg  
  inflating: /content/kaggle/train_images_jpeg/959014862.jpg  
  inflating: /content/kaggle/train_images_jpeg/959693086.jpg  
  inflating: /content/kaggle/train_images_jpeg/959863341.jpg  
  inflating: /content/kaggle/train_images_jpeg/96006478.jpg  
  inflating: /content/kaggle/train_images_jpeg/960202242.jpg  
  inflating: /content/kaggle/train_images_jpeg/960261822.jpg  
  inflating: /content/kaggle/train_images_jpeg/960297309.jpg  
  inflating: /content/kaggle/train_images_jpeg/96041444.jpg  
  inflating: /content/kaggle/train_images_jpeg/960648391.jpg  
  inflating: /content/kaggle/train_images_jpeg/960773451.jpg  
  inflating: /content/kaggle/train_images_jpeg/961575661.jpg  
  inflating: /content/kaggle/train_images_jpeg/961826850.jpg  
  inflating: /content/kaggle/train_images_jpeg/961914208.jpg  
  inflating: /content/kaggle/train_images_jpeg/961915557.jpg  
  inflating: /content/kaggle/train_images_jpeg/962347612.jpg  
  inflating: /content/kaggle/train_images_jpeg/96246425.jpg  
  inflating: /content/kaggle/train_images_jpeg/962558857.jpg  
  inflating: /content/kaggle/train_images_jpeg/963168720.jpg  
  inflating: /content/kaggle/train_images_jpeg/963176335.jpg  
  inflating: /content/kaggle/train_images_jpeg/963450221.jpg  
  inflating: /content/kaggle/train_images_jpeg/963790461.jpg  
  inflating: /content/kaggle/train_images_jpeg/964030938.jpg  
  inflating: /content/kaggle/train_images_jpeg/964359867.jpg  
  inflating: /content/kaggle/train_images_jpeg/964482896.jpg  
  inflating: /content/kaggle/train_images_jpeg/964570288.jpg  
  inflating: /content/kaggle/train_images_jpeg/964655123.jpg  
  inflating: /content/kaggle/train_images_jpeg/965026603.jpg  
  inflating: /content/kaggle/train_images_jpeg/965133347.jpg  
  inflating: /content/kaggle/train_images_jpeg/965889493.jpg  
  inflating: /content/kaggle/train_images_jpeg/965919968.jpg  
  inflating: /content/kaggle/train_images_jpeg/966050678.jpg  
  inflating: /content/kaggle/train_images_jpeg/966306135.jpg  
  inflating: /content/kaggle/train_images_jpeg/966432144.jpg  
  inflating: /content/kaggle/train_images_jpeg/966652545.jpg  
  inflating: /content/kaggle/train_images_jpeg/966788042.jpg  
  inflating: /content/kaggle/train_images_jpeg/967123833.jpg  
  inflating: /content/kaggle/train_images_jpeg/967319500.jpg  
  inflating: /content/kaggle/train_images_jpeg/967603965.jpg  
  inflating: /content/kaggle/train_images_jpeg/967831491.jpg  
  inflating: /content/kaggle/train_images_jpeg/967883712.jpg  
  inflating: /content/kaggle/train_images_jpeg/968449352.jpg  
  inflating: /content/kaggle/train_images_jpeg/968472833.jpg  
  inflating: /content/kaggle/train_images_jpeg/968790449.jpg  
  inflating: /content/kaggle/train_images_jpeg/968853775.jpg  
  inflating: /content/kaggle/train_images_jpeg/968865165.jpg  
  inflating: /content/kaggle/train_images_jpeg/969069572.jpg  
  inflating: /content/kaggle/train_images_jpeg/96912752.jpg  
  inflating: /content/kaggle/train_images_jpeg/969194504.jpg  
  inflating: /content/kaggle/train_images_jpeg/969211018.jpg  
  inflating: /content/kaggle/train_images_jpeg/969351419.jpg  
  inflating: /content/kaggle/train_images_jpeg/969719974.jpg  
  inflating: /content/kaggle/train_images_jpeg/969749670.jpg  
  inflating: /content/kaggle/train_images_jpeg/969938724.jpg  
  inflating: /content/kaggle/train_images_jpeg/970041120.jpg  
  inflating: /content/kaggle/train_images_jpeg/970540696.jpg  
  inflating: /content/kaggle/train_images_jpeg/970669415.jpg  
  inflating: /content/kaggle/train_images_jpeg/970899436.jpg  
  inflating: /content/kaggle/train_images_jpeg/970946808.jpg  
  inflating: /content/kaggle/train_images_jpeg/971188113.jpg  
  inflating: /content/kaggle/train_images_jpeg/971500459.jpg  
  inflating: /content/kaggle/train_images_jpeg/971639298.jpg  
  inflating: /content/kaggle/train_images_jpeg/971713914.jpg  
  inflating: /content/kaggle/train_images_jpeg/972419188.jpg  
  inflating: /content/kaggle/train_images_jpeg/972622677.jpg  
  inflating: /content/kaggle/train_images_jpeg/972649867.jpg  
  inflating: /content/kaggle/train_images_jpeg/972793378.jpg  
  inflating: /content/kaggle/train_images_jpeg/972840038.jpg  
  inflating: /content/kaggle/train_images_jpeg/972873188.jpg  
  inflating: /content/kaggle/train_images_jpeg/97287651.jpg  
  inflating: /content/kaggle/train_images_jpeg/972959733.jpg  
  inflating: /content/kaggle/train_images_jpeg/973300702.jpg  
  inflating: /content/kaggle/train_images_jpeg/973746900.jpg  
  inflating: /content/kaggle/train_images_jpeg/97383533.jpg  
  inflating: /content/kaggle/train_images_jpeg/974073314.jpg  
  inflating: /content/kaggle/train_images_jpeg/974489379.jpg  
  inflating: /content/kaggle/train_images_jpeg/974614447.jpg  
  inflating: /content/kaggle/train_images_jpeg/975110881.jpg  
  inflating: /content/kaggle/train_images_jpeg/975158492.jpg  
  inflating: /content/kaggle/train_images_jpeg/975311959.jpg  
  inflating: /content/kaggle/train_images_jpeg/975534940.jpg  
  inflating: /content/kaggle/train_images_jpeg/975560905.jpg  
  inflating: /content/kaggle/train_images_jpeg/976098356.jpg  
  inflating: /content/kaggle/train_images_jpeg/976138379.jpg  
  inflating: /content/kaggle/train_images_jpeg/976558597.jpg  
  inflating: /content/kaggle/train_images_jpeg/976680630.jpg  
  inflating: /content/kaggle/train_images_jpeg/976801924.jpg  
  inflating: /content/kaggle/train_images_jpeg/976902576.jpg  
  inflating: /content/kaggle/train_images_jpeg/976955239.jpg  
  inflating: /content/kaggle/train_images_jpeg/976976000.jpg  
  inflating: /content/kaggle/train_images_jpeg/977106252.jpg  
  inflating: /content/kaggle/train_images_jpeg/977380491.jpg  
  inflating: /content/kaggle/train_images_jpeg/977617704.jpg  
  inflating: /content/kaggle/train_images_jpeg/977709534.jpg  
  inflating: /content/kaggle/train_images_jpeg/977735708.jpg  
  inflating: /content/kaggle/train_images_jpeg/978029996.jpg  
  inflating: /content/kaggle/train_images_jpeg/978111352.jpg  
  inflating: /content/kaggle/train_images_jpeg/978618490.jpg  
  inflating: /content/kaggle/train_images_jpeg/978877878.jpg  
  inflating: /content/kaggle/train_images_jpeg/979088794.jpg  
  inflating: /content/kaggle/train_images_jpeg/979089486.jpg  
  inflating: /content/kaggle/train_images_jpeg/979574790.jpg  
  inflating: /content/kaggle/train_images_jpeg/979671168.jpg  
  inflating: /content/kaggle/train_images_jpeg/979717744.jpg  
  inflating: /content/kaggle/train_images_jpeg/979858694.jpg  
  inflating: /content/kaggle/train_images_jpeg/979927449.jpg  
  inflating: /content/kaggle/train_images_jpeg/980174544.jpg  
  inflating: /content/kaggle/train_images_jpeg/980401006.jpg  
  inflating: /content/kaggle/train_images_jpeg/980448273.jpg  
  inflating: /content/kaggle/train_images_jpeg/980682914.jpg  
  inflating: /content/kaggle/train_images_jpeg/980911264.jpg  
  inflating: /content/kaggle/train_images_jpeg/981211210.jpg  
  inflating: /content/kaggle/train_images_jpeg/981248959.jpg  
  inflating: /content/kaggle/train_images_jpeg/98151706.jpg  
  inflating: /content/kaggle/train_images_jpeg/981946821.jpg  
  inflating: /content/kaggle/train_images_jpeg/981961513.jpg  
  inflating: /content/kaggle/train_images_jpeg/982230894.jpg  
  inflating: /content/kaggle/train_images_jpeg/982241079.jpg  
  inflating: /content/kaggle/train_images_jpeg/982255022.jpg  
  inflating: /content/kaggle/train_images_jpeg/982343142.jpg  
  inflating: /content/kaggle/train_images_jpeg/982426232.jpg  
  inflating: /content/kaggle/train_images_jpeg/982556736.jpg  
  inflating: /content/kaggle/train_images_jpeg/982733151.jpg  
  inflating: /content/kaggle/train_images_jpeg/982829407.jpg  
  inflating: /content/kaggle/train_images_jpeg/982968211.jpg  
  inflating: /content/kaggle/train_images_jpeg/983014273.jpg  
  inflating: /content/kaggle/train_images_jpeg/983360921.jpg  
  inflating: /content/kaggle/train_images_jpeg/983368345.jpg  
  inflating: /content/kaggle/train_images_jpeg/984082173.jpg  
  inflating: /content/kaggle/train_images_jpeg/984192870.jpg  
  inflating: /content/kaggle/train_images_jpeg/984417293.jpg  
  inflating: /content/kaggle/train_images_jpeg/984672636.jpg  
  inflating: /content/kaggle/train_images_jpeg/984892057.jpg  
  inflating: /content/kaggle/train_images_jpeg/985972952.jpg  
  inflating: /content/kaggle/train_images_jpeg/986134312.jpg  
  inflating: /content/kaggle/train_images_jpeg/986273020.jpg  
  inflating: /content/kaggle/train_images_jpeg/986387276.jpg  
  inflating: /content/kaggle/train_images_jpeg/986788190.jpg  
  inflating: /content/kaggle/train_images_jpeg/986854149.jpg  
  inflating: /content/kaggle/train_images_jpeg/986888785.jpg  
  inflating: /content/kaggle/train_images_jpeg/986965803.jpg  
  inflating: /content/kaggle/train_images_jpeg/986999751.jpg  
  inflating: /content/kaggle/train_images_jpeg/987080644.jpg  
  inflating: /content/kaggle/train_images_jpeg/987098553.jpg  
  inflating: /content/kaggle/train_images_jpeg/987159645.jpg  
  inflating: /content/kaggle/train_images_jpeg/987636835.jpg  
  inflating: /content/kaggle/train_images_jpeg/988174802.jpg  
  inflating: /content/kaggle/train_images_jpeg/988306549.jpg  
  inflating: /content/kaggle/train_images_jpeg/988318054.jpg  
  inflating: /content/kaggle/train_images_jpeg/989030666.jpg  
  inflating: /content/kaggle/train_images_jpeg/989119004.jpg  
  inflating: /content/kaggle/train_images_jpeg/989164337.jpg  
  inflating: /content/kaggle/train_images_jpeg/989239917.jpg  
  inflating: /content/kaggle/train_images_jpeg/990558315.jpg  
  inflating: /content/kaggle/train_images_jpeg/99056821.jpg  
  inflating: /content/kaggle/train_images_jpeg/990768027.jpg  
  inflating: /content/kaggle/train_images_jpeg/990890343.jpg  
  inflating: /content/kaggle/train_images_jpeg/991522911.jpg  
  inflating: /content/kaggle/train_images_jpeg/991676292.jpg  
  inflating: /content/kaggle/train_images_jpeg/991916399.jpg  
  inflating: /content/kaggle/train_images_jpeg/99202708.jpg  
  inflating: /content/kaggle/train_images_jpeg/992163916.jpg  
  inflating: /content/kaggle/train_images_jpeg/992224132.jpg  
  inflating: /content/kaggle/train_images_jpeg/992352996.jpg  
  inflating: /content/kaggle/train_images_jpeg/992748624.jpg  
  inflating: /content/kaggle/train_images_jpeg/992964459.jpg  
  inflating: /content/kaggle/train_images_jpeg/993130539.jpg  
  inflating: /content/kaggle/train_images_jpeg/993366541.jpg  
  inflating: /content/kaggle/train_images_jpeg/993844551.jpg  
  inflating: /content/kaggle/train_images_jpeg/99391680.jpg  
  inflating: /content/kaggle/train_images_jpeg/993984792.jpg  
  inflating: /content/kaggle/train_images_jpeg/994252979.jpg  
  inflating: /content/kaggle/train_images_jpeg/994445094.jpg  
  inflating: /content/kaggle/train_images_jpeg/994621972.jpg  
  inflating: /content/kaggle/train_images_jpeg/994727955.jpg  
  inflating: /content/kaggle/train_images_jpeg/995075067.jpg  
  inflating: /content/kaggle/train_images_jpeg/995123333.jpg  
  inflating: /content/kaggle/train_images_jpeg/995155483.jpg  
  inflating: /content/kaggle/train_images_jpeg/995221528.jpg  
  inflating: /content/kaggle/train_images_jpeg/99645916.jpg  
  inflating: /content/kaggle/train_images_jpeg/996534381.jpg  
  inflating: /content/kaggle/train_images_jpeg/996539252.jpg  
  inflating: /content/kaggle/train_images_jpeg/996762577.jpg  
  inflating: /content/kaggle/train_images_jpeg/996927503.jpg  
  inflating: /content/kaggle/train_images_jpeg/996947690.jpg  
  inflating: /content/kaggle/train_images_jpeg/996957803.jpg  
  inflating: /content/kaggle/train_images_jpeg/997161074.jpg  
  inflating: /content/kaggle/train_images_jpeg/997179968.jpg  
  inflating: /content/kaggle/train_images_jpeg/997289539.jpg  
  inflating: /content/kaggle/train_images_jpeg/997485103.jpg  
  inflating: /content/kaggle/train_images_jpeg/997651546.jpg  
  inflating: /content/kaggle/train_images_jpeg/997857988.jpg  
  inflating: /content/kaggle/train_images_jpeg/997910101.jpg  
  inflating: /content/kaggle/train_images_jpeg/997973414.jpg  
  inflating: /content/kaggle/train_images_jpeg/998910982.jpg  
  inflating: /content/kaggle/train_images_jpeg/999068805.jpg  
  inflating: /content/kaggle/train_images_jpeg/999329392.jpg  
  inflating: /content/kaggle/train_images_jpeg/999474432.jpg  
  inflating: /content/kaggle/train_images_jpeg/999616605.jpg  
  inflating: /content/kaggle/train_images_jpeg/999998473.jpg
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">torchsummary</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">torch</span><span class="o">==</span><span class="mf">1.7.0</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">torchvision</span><span class="o">==</span><span class="mf">0.8.1</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">scikit</span><span class="o">-</span><span class="n">learn</span><span class="o">==</span><span class="mf">0.23.2</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">albumentations</span><span class="o">==</span><span class="mf">0.5.1</span>

<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">geffnet</span><span class="o">==</span><span class="mf">1.0.0</span>
<span class="err">!</span><span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">q</span> <span class="n">torchtoolbox</span><span class="o">==</span><span class="mf">0.1.5</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[K     |████████████████████████████████| 6.8MB 14.0MB/s 
[K     |████████████████████████████████| 81kB 7.2MB/s 
[K     |████████████████████████████████| 952kB 16.7MB/s 
[K     |████████████████████████████████| 37.6MB 147kB/s 
[K     |████████████████████████████████| 61kB 6.6MB/s 
[?25h
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">import</span> <span class="nn">PIL.Image</span>
<span class="kn">import</span> <span class="nn">albumentations</span>
<span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">sklearn</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">albumentations.pytorch.transforms</span> <span class="kn">import</span> <span class="n">ToTensorV2</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">Image</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">StratifiedKFold</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">from</span> <span class="nn">torchsummary</span> <span class="kn">import</span> <span class="n">summary</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">models</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>


<span class="kn">import</span> <span class="nn">geffnet</span>
<span class="kn">from</span> <span class="nn">IPython.core.interactiveshell</span> <span class="kn">import</span> <span class="n">InteractiveShell</span>
<span class="n">InteractiveShell</span><span class="o">.</span><span class="n">ast_node_interactivity</span> <span class="o">=</span> <span class="s2">&quot;all&quot;</span>
</code></pre></div>
<h1 id="config">Config</h1>
<div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">GlobalConfig</span><span class="p">:</span>
    <span class="n">seed</span> <span class="o">=</span> <span class="mi">1930</span>
    <span class="n">num_classes</span> <span class="o">=</span> <span class="mi">11</span>
    <span class="n">class_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">9</span><span class="p">,</span><span class="mi">10</span><span class="p">]</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">16</span>
    <span class="n">n_epochs</span> <span class="o">=</span> <span class="mi">15</span>
    <span class="n">tensor_size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">64</span><span class="p">,</span><span class="mi">64</span><span class="p">)</span>

    <span class="c1"># unpack the key dict</span>
    <span class="n">scheduler</span> <span class="o">=</span> <span class="s1">&#39;CosineAnnealingWarmRestarts&#39;</span>
    <span class="n">scheduler_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;StepLR&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;step_size&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span><span class="mf">0.3</span><span class="p">,</span> <span class="s1">&#39;last_epoch&#39;</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">},</span>

                <span class="s1">&#39;ReduceLROnPlateau&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;mode&#39;</span><span class="p">:</span><span class="s1">&#39;max&#39;</span><span class="p">,</span> <span class="s1">&#39;factor&#39;</span><span class="p">:</span><span class="mf">0.5</span><span class="p">,</span> <span class="s1">&#39;patience&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;threshold&#39;</span><span class="p">:</span><span class="mf">0.0001</span><span class="p">,</span>
                                      <span class="s1">&#39;threshold_mode&#39;</span><span class="p">:</span><span class="s1">&#39;rel&#39;</span><span class="p">,</span> <span class="s1">&#39;cooldown&#39;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;min_lr&#39;</span><span class="p">:</span><span class="mf">1e-5</span><span class="p">,</span>
                                      <span class="s1">&#39;eps&#39;</span><span class="p">:</span><span class="mf">1e-08</span><span class="p">,</span> <span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">},</span>

                <span class="s1">&#39;CosineAnnealingWarmRestarts&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;T_0&#39;</span><span class="p">:</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;T_mult&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;eta_min&#39;</span><span class="p">:</span><span class="mf">1e-6</span><span class="p">,</span> <span class="s1">&#39;last_epoch&#39;</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span>
                                                <span class="s1">&#39;verbose&#39;</span><span class="p">:</span><span class="kc">True</span><span class="p">}}</span>

    <span class="c1"># do scheduler.step after optimizer.step</span>
    <span class="n">train_step_scheduler</span> <span class="o">=</span> <span class="kc">False</span>  
    <span class="n">val_step_scheduler</span> <span class="o">=</span> <span class="kc">True</span>

    <span class="c1"># optimizer</span>
    <span class="n">optimizer</span> <span class="o">=</span> <span class="s1">&#39;AdamW&#39;</span>
    <span class="n">optimizer_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;AdamW&#39;</span><span class="p">:{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span><span class="mf">1e-3</span><span class="p">,</span> <span class="s1">&#39;betas&#39;</span><span class="p">:(</span><span class="mf">0.9</span><span class="p">,</span><span class="mf">0.999</span><span class="p">),</span> <span class="s1">&#39;eps&#39;</span><span class="p">:</span><span class="mf">1e-08</span><span class="p">,</span>
                                 <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span><span class="mf">1e-6</span><span class="p">,</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">},</span> 
                        <span class="s1">&#39;Adam&#39;</span><span class="p">:{</span><span class="s1">&#39;lr&#39;</span><span class="p">:</span><span class="mf">1e-4</span><span class="p">,</span><span class="s1">&#39;betas&#39;</span><span class="p">:(</span><span class="mf">0.9</span><span class="p">,</span><span class="mf">0.999</span><span class="p">),</span> <span class="s1">&#39;eps&#39;</span><span class="p">:</span><span class="mf">1e-08</span><span class="p">,</span>
                                 <span class="s1">&#39;weight_decay&#39;</span><span class="p">:</span><span class="mf">1e-6</span><span class="p">,</span><span class="s1">&#39;amsgrad&#39;</span><span class="p">:</span><span class="kc">False</span><span class="p">},}</span>

    <span class="c1"># criterion</span>
    <span class="n">criterion</span> <span class="o">=</span> <span class="s1">&#39;BCEWithLogitsLoss&#39;</span>
    <span class="n">criterion_val</span> <span class="o">=</span> <span class="s1">&#39;BCEWithLogitsLoss&#39;</span>
    <span class="n">criterion_params</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;BCEWithLogitsLoss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;weight&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;size_average&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span>
                                             <span class="s1">&#39;reduce&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span> <span class="s1">&#39;reduction&#39;</span><span class="p">:</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;pos_weight&#39;</span><span class="p">:</span> <span class="kc">None</span><span class="p">},</span>
                        <span class="s1">&#39;CrossEntropyLoss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;weight&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span><span class="s1">&#39;size_average&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span>
                                             <span class="s1">&#39;ignore_index&#39;</span><span class="p">:</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span><span class="s1">&#39;reduce&#39;</span><span class="p">:</span><span class="kc">None</span><span class="p">,</span>
                                             <span class="s1">&#39;reduction&#39;</span><span class="p">:</span><span class="s1">&#39;mean&#39;</span><span class="p">},</span>
                        <span class="s1">&#39;LabelSmoothingLoss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;classes&#39;</span><span class="p">:</span><span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;smoothing&#39;</span><span class="p">:</span><span class="mf">0.05</span><span class="p">,</span> <span class="s1">&#39;dim&#39;</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">},</span>
                        <span class="s1">&#39;FocalCosineLoss&#39;</span><span class="p">:</span> <span class="p">{</span><span class="s1">&#39;alpha&#39;</span><span class="p">:</span><span class="mi">1</span><span class="p">,</span> <span class="s1">&#39;gamma&#39;</span><span class="p">:</span><span class="mi">2</span> <span class="p">,</span> <span class="s1">&#39;xent&#39;</span><span class="p">:</span><span class="mf">0.1</span><span class="p">}}</span>



    <span class="n">image_col_name</span> <span class="o">=</span> <span class="s1">&#39;image_id&#39;</span>
    <span class="n">class_col_name</span> <span class="o">=</span> <span class="s1">&#39;label&#39;</span>
    <span class="n">paths</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;train_path&#39;</span><span class="p">:</span> <span class="s1">&#39;/content/kaggle/train_images_jpeg/&#39;</span><span class="p">,</span>
             <span class="s1">&#39;test_path&#39;</span><span class="p">:</span> <span class="s1">&#39;../input/siim-isic-melanoma-classification/jpeg/test&#39;</span><span class="p">,</span>
             <span class="s1">&#39;csv_path&#39;</span><span class="p">:</span> <span class="s1">&#39;/content/drive/My Drive/Cassava/input/cassava-leaf-disease-classification/train.csv&#39;</span><span class="p">,</span>
             <span class="s1">&#39;log_path&#39;</span><span class="p">:</span> <span class="s1">&#39;./log.text&#39;</span><span class="p">,</span>
             <span class="s1">&#39;save_path&#39;</span><span class="p">:</span> <span class="s1">&#39;/content/drive/My Drive/Cassava/weights/tf_effnet_b4_ns/18-Jan-V1&#39;</span><span class="p">,</span>
             <span class="s1">&#39;model_weight_path_folder&#39;</span><span class="p">:</span> <span class="s1">&#39;/content/drive/My Drive/pretrained-effnet-weights&#39;</span><span class="p">,</span>
             <span class="s1">&#39;image_path&#39;</span> <span class="p">:</span> <span class="s1">&#39;/content/drive/My Drive/deep-learning-notes/notebooks/images&#39;</span><span class="p">}</span>

    <span class="n">model_name</span> <span class="o">=</span> <span class="s1">&#39;tf_efficientnet_b5_ns&#39;</span>
    <span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="n">config</span> <span class="o">=</span> <span class="n">GlobalConfig</span>
</code></pre></div>
<h1 id="utils">Utils</h1>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1930</span><span class="p">):</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;I love my Grandpa so the seed number is </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">seed</span><span class="p">))</span>

    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYTHONHASHSEED&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span>
        <span class="n">seed</span><span class="p">)</span>  <span class="c1"># set PYTHONHASHSEED env var at fixed value</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># pytorch (both CPU and CUDA)</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>  <span class="c1"># for numpy pseudo-random generator</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span>
        <span class="n">seed</span><span class="p">)</span>  <span class="c1"># set fixed value for python built-in pseudo-random generator</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">False</span>


<span class="k">def</span> <span class="nf">seed_worker</span><span class="p">(</span><span class="n">_worker_id</span><span class="p">):</span>
    <span class="n">worker_seed</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">initial_seed</span><span class="p">()</span> <span class="o">%</span> <span class="mi">2</span><span class="o">**</span><span class="mi">32</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">worker_seed</span><span class="p">)</span>

<span class="c1">######################################################################</span>
<span class="n">seed_all</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="c1">######################################################################</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>I love my Grandpa so the seed number is 1930
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">make_rand_tensors</span><span class="p">(</span><span class="n">config</span><span class="p">):</span>
    <span class="c1"># Create a batch size of 8 random images with 3 channels and 64x64 -&gt; [N,C,W,H]</span>
    <span class="n">rand_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">tensor_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">rand_tensor</span>

<span class="k">def</span> <span class="nf">torchsummary_wrapper</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">image_size</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">):</span>

    <span class="n">model_summary</span> <span class="o">=</span> <span class="n">summary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">image_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model_summary</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">display_image</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">page_num</span><span class="p">):</span>
    <span class="n">image</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">paths</span><span class="p">[</span><span class="s1">&#39;hongnan_notes&#39;</span><span class="p">],</span> <span class="n">page_num</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Image</span><span class="p">(</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<h1 id="learning-the-syntax-of-pytorch">Learning the Syntax of PyTorch</h1>
<p><code>torch.view()</code> <a href="https://stackoverflow.com/questions/42479902/how-does-the-view-method-work-in-pytorch">reference</a></p>
<h3 id="torchnn-vs-torchnnfunctional">torch.nn vs torch.nn.functional</h3>
<p><a href="https://discuss.pytorch.org/t/whats-the-difference-between-nn-relu-vs-f-relu/27599/3">torch.nn.Relu vs torch.nn.functional.Relu</a></p>
<p><a href="https://stackoverflow.com/questions/53419474/using-dropout-in-pytorch-nn-dropout-vs-f-dropout">using-dropout-in-pytorch-nn-dropout-vs-f-dropout</a></p>
<h1 id="building-neural-networks">Building Neural Networks</h1>
<h2 id="convolutional-layers">Convolutional Layers</h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">lr_scheduler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>   <span class="c1"># interactive mode</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="err">!</span><span class="n">unzip</span> <span class="s1">&#39;/content/drive/My Drive/deep-learning-notes/notebooks/hymenoptera_data.zip&#39;</span> <span class="o">-</span><span class="n">d</span> <span class="s1">&#39;/content/&#39;</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Archive:  /content/drive/My Drive/deep-learning-notes/notebooks/hymenoptera_data.zip
   creating: /content/hymenoptera_data/
   creating: /content/hymenoptera_data/train/
   creating: /content/hymenoptera_data/train/ants/
  inflating: /content/hymenoptera_data/train/ants/0013035.jpg  
  inflating: /content/hymenoptera_data/train/ants/1030023514_aad5c608f9.jpg  
  inflating: /content/hymenoptera_data/train/ants/1095476100_3906d8afde.jpg  
  inflating: /content/hymenoptera_data/train/ants/1099452230_d1949d3250.jpg  
  inflating: /content/hymenoptera_data/train/ants/116570827_e9c126745d.jpg  
  inflating: /content/hymenoptera_data/train/ants/1225872729_6f0856588f.jpg  
  inflating: /content/hymenoptera_data/train/ants/1262877379_64fcada201.jpg  
  inflating: /content/hymenoptera_data/train/ants/1269756697_0bce92cdab.jpg  
  inflating: /content/hymenoptera_data/train/ants/1286984635_5119e80de1.jpg  
  inflating: /content/hymenoptera_data/train/ants/132478121_2a430adea2.jpg  
  inflating: /content/hymenoptera_data/train/ants/1360291657_dc248c5eea.jpg  
  inflating: /content/hymenoptera_data/train/ants/1368913450_e146e2fb6d.jpg  
  inflating: /content/hymenoptera_data/train/ants/1473187633_63ccaacea6.jpg  
  inflating: /content/hymenoptera_data/train/ants/148715752_302c84f5a4.jpg  
  inflating: /content/hymenoptera_data/train/ants/1489674356_09d48dde0a.jpg  
  inflating: /content/hymenoptera_data/train/ants/149244013_c529578289.jpg  
  inflating: /content/hymenoptera_data/train/ants/150801003_3390b73135.jpg  
  inflating: /content/hymenoptera_data/train/ants/150801171_cd86f17ed8.jpg  
  inflating: /content/hymenoptera_data/train/ants/154124431_65460430f2.jpg  
  inflating: /content/hymenoptera_data/train/ants/162603798_40b51f1654.jpg  
  inflating: /content/hymenoptera_data/train/ants/1660097129_384bf54490.jpg  
  inflating: /content/hymenoptera_data/train/ants/167890289_dd5ba923f3.jpg  
  inflating: /content/hymenoptera_data/train/ants/1693954099_46d4c20605.jpg  
  inflating: /content/hymenoptera_data/train/ants/175998972.jpg  
  inflating: /content/hymenoptera_data/train/ants/178538489_bec7649292.jpg  
  inflating: /content/hymenoptera_data/train/ants/1804095607_0341701e1c.jpg  
  inflating: /content/hymenoptera_data/train/ants/1808777855_2a895621d7.jpg  
  inflating: /content/hymenoptera_data/train/ants/188552436_605cc9b36b.jpg  
  inflating: /content/hymenoptera_data/train/ants/1917341202_d00a7f9af5.jpg  
  inflating: /content/hymenoptera_data/train/ants/1924473702_daa9aacdbe.jpg  
  inflating: /content/hymenoptera_data/train/ants/196057951_63bf063b92.jpg  
  inflating: /content/hymenoptera_data/train/ants/196757565_326437f5fe.jpg  
  inflating: /content/hymenoptera_data/train/ants/201558278_fe4caecc76.jpg  
  inflating: /content/hymenoptera_data/train/ants/201790779_527f4c0168.jpg  
  inflating: /content/hymenoptera_data/train/ants/2019439677_2db655d361.jpg  
  inflating: /content/hymenoptera_data/train/ants/207947948_3ab29d7207.jpg  
  inflating: /content/hymenoptera_data/train/ants/20935278_9190345f6b.jpg  
  inflating: /content/hymenoptera_data/train/ants/224655713_3956f7d39a.jpg  
  inflating: /content/hymenoptera_data/train/ants/2265824718_2c96f485da.jpg  
  inflating: /content/hymenoptera_data/train/ants/2265825502_fff99cfd2d.jpg  
  inflating: /content/hymenoptera_data/train/ants/226951206_d6bf946504.jpg  
  inflating: /content/hymenoptera_data/train/ants/2278278459_6b99605e50.jpg  
  inflating: /content/hymenoptera_data/train/ants/2288450226_a6e96e8fdf.jpg  
  inflating: /content/hymenoptera_data/train/ants/2288481644_83ff7e4572.jpg  
  inflating: /content/hymenoptera_data/train/ants/2292213964_ca51ce4bef.jpg  
  inflating: /content/hymenoptera_data/train/ants/24335309_c5ea483bb8.jpg  
  inflating: /content/hymenoptera_data/train/ants/245647475_9523dfd13e.jpg  
  inflating: /content/hymenoptera_data/train/ants/255434217_1b2b3fe0a4.jpg  
  inflating: /content/hymenoptera_data/train/ants/258217966_d9d90d18d3.jpg  
  inflating: /content/hymenoptera_data/train/ants/275429470_b2d7d9290b.jpg  
  inflating: /content/hymenoptera_data/train/ants/28847243_e79fe052cd.jpg  
  inflating: /content/hymenoptera_data/train/ants/318052216_84dff3f98a.jpg  
  inflating: /content/hymenoptera_data/train/ants/334167043_cbd1adaeb9.jpg  
  inflating: /content/hymenoptera_data/train/ants/339670531_94b75ae47a.jpg  
  inflating: /content/hymenoptera_data/train/ants/342438950_a3da61deab.jpg  
  inflating: /content/hymenoptera_data/train/ants/36439863_0bec9f554f.jpg  
  inflating: /content/hymenoptera_data/train/ants/374435068_7eee412ec4.jpg  
  inflating: /content/hymenoptera_data/train/ants/382971067_0bfd33afe0.jpg  
  inflating: /content/hymenoptera_data/train/ants/384191229_5779cf591b.jpg  
  inflating: /content/hymenoptera_data/train/ants/386190770_672743c9a7.jpg  
  inflating: /content/hymenoptera_data/train/ants/392382602_1b7bed32fa.jpg  
  inflating: /content/hymenoptera_data/train/ants/403746349_71384f5b58.jpg  
  inflating: /content/hymenoptera_data/train/ants/408393566_b5b694119b.jpg  
  inflating: /content/hymenoptera_data/train/ants/424119020_6d57481dab.jpg  
  inflating: /content/hymenoptera_data/train/ants/424873399_47658a91fb.jpg  
  inflating: /content/hymenoptera_data/train/ants/450057712_771b3bfc91.jpg  
  inflating: /content/hymenoptera_data/train/ants/45472593_bfd624f8dc.jpg  
  inflating: /content/hymenoptera_data/train/ants/459694881_ac657d3187.jpg  
  inflating: /content/hymenoptera_data/train/ants/460372577_f2f6a8c9fc.jpg  
  inflating: /content/hymenoptera_data/train/ants/460874319_0a45ab4d05.jpg  
  inflating: /content/hymenoptera_data/train/ants/466430434_4000737de9.jpg  
  inflating: /content/hymenoptera_data/train/ants/470127037_513711fd21.jpg  
  inflating: /content/hymenoptera_data/train/ants/474806473_ca6caab245.jpg  
  inflating: /content/hymenoptera_data/train/ants/475961153_b8c13fd405.jpg  
  inflating: /content/hymenoptera_data/train/ants/484293231_e53cfc0c89.jpg  
  inflating: /content/hymenoptera_data/train/ants/49375974_e28ba6f17e.jpg  
  inflating: /content/hymenoptera_data/train/ants/506249802_207cd979b4.jpg  
  inflating: /content/hymenoptera_data/train/ants/506249836_717b73f540.jpg  
  inflating: /content/hymenoptera_data/train/ants/512164029_c0a66b8498.jpg  
  inflating: /content/hymenoptera_data/train/ants/512863248_43c8ce579b.jpg  
  inflating: /content/hymenoptera_data/train/ants/518773929_734dbc5ff4.jpg  
  inflating: /content/hymenoptera_data/train/ants/522163566_fec115ca66.jpg  
  inflating: /content/hymenoptera_data/train/ants/522415432_2218f34bf8.jpg  
  inflating: /content/hymenoptera_data/train/ants/531979952_bde12b3bc0.jpg  
  inflating: /content/hymenoptera_data/train/ants/533848102_70a85ad6dd.jpg  
  inflating: /content/hymenoptera_data/train/ants/535522953_308353a07c.jpg  
  inflating: /content/hymenoptera_data/train/ants/540889389_48bb588b21.jpg  
  inflating: /content/hymenoptera_data/train/ants/541630764_dbd285d63c.jpg  
  inflating: /content/hymenoptera_data/train/ants/543417860_b14237f569.jpg  
  inflating: /content/hymenoptera_data/train/ants/560966032_988f4d7bc4.jpg  
  inflating: /content/hymenoptera_data/train/ants/5650366_e22b7e1065.jpg  
  inflating: /content/hymenoptera_data/train/ants/6240329_72c01e663e.jpg  
  inflating: /content/hymenoptera_data/train/ants/6240338_93729615ec.jpg  
  inflating: /content/hymenoptera_data/train/ants/649026570_e58656104b.jpg  
  inflating: /content/hymenoptera_data/train/ants/662541407_ff8db781e7.jpg  
  inflating: /content/hymenoptera_data/train/ants/67270775_e9fdf77e9d.jpg  
  inflating: /content/hymenoptera_data/train/ants/6743948_2b8c096dda.jpg  
  inflating: /content/hymenoptera_data/train/ants/684133190_35b62c0c1d.jpg  
  inflating: /content/hymenoptera_data/train/ants/69639610_95e0de17aa.jpg  
  inflating: /content/hymenoptera_data/train/ants/707895295_009cf23188.jpg  
  inflating: /content/hymenoptera_data/train/ants/7759525_1363d24e88.jpg  
  inflating: /content/hymenoptera_data/train/ants/795000156_a9900a4a71.jpg  
  inflating: /content/hymenoptera_data/train/ants/822537660_caf4ba5514.jpg  
  inflating: /content/hymenoptera_data/train/ants/82852639_52b7f7f5e3.jpg  
  inflating: /content/hymenoptera_data/train/ants/841049277_b28e58ad05.jpg  
  inflating: /content/hymenoptera_data/train/ants/886401651_f878e888cd.jpg  
  inflating: /content/hymenoptera_data/train/ants/892108839_f1aad4ca46.jpg  
  inflating: /content/hymenoptera_data/train/ants/938946700_ca1c669085.jpg  
  inflating: /content/hymenoptera_data/train/ants/957233405_25c1d1187b.jpg  
  inflating: /content/hymenoptera_data/train/ants/9715481_b3cb4114ff.jpg  
  inflating: /content/hymenoptera_data/train/ants/998118368_6ac1d91f81.jpg  
  inflating: /content/hymenoptera_data/train/ants/ant photos.jpg  
  inflating: /content/hymenoptera_data/train/ants/Ant_1.jpg  
  inflating: /content/hymenoptera_data/train/ants/army-ants-red-picture.jpg  
  inflating: /content/hymenoptera_data/train/ants/formica.jpeg  
  inflating: /content/hymenoptera_data/train/ants/hormiga_co_por.jpg  
  inflating: /content/hymenoptera_data/train/ants/imageNotFound.gif  
  inflating: /content/hymenoptera_data/train/ants/kurokusa.jpg  
  inflating: /content/hymenoptera_data/train/ants/MehdiabadiAnt2_600.jpg  
  inflating: /content/hymenoptera_data/train/ants/Nepenthes_rafflesiana_ant.jpg  
  inflating: /content/hymenoptera_data/train/ants/swiss-army-ant.jpg  
  inflating: /content/hymenoptera_data/train/ants/termite-vs-ant.jpg  
  inflating: /content/hymenoptera_data/train/ants/trap-jaw-ant-insect-bg.jpg  
  inflating: /content/hymenoptera_data/train/ants/VietnameseAntMimicSpider.jpg  
   creating: /content/hymenoptera_data/train/bees/
  inflating: /content/hymenoptera_data/train/bees/1092977343_cb42b38d62.jpg  
  inflating: /content/hymenoptera_data/train/bees/1093831624_fb5fbe2308.jpg  
  inflating: /content/hymenoptera_data/train/bees/1097045929_1753d1c765.jpg  
  inflating: /content/hymenoptera_data/train/bees/1232245714_f862fbe385.jpg  
  inflating: /content/hymenoptera_data/train/bees/129236073_0985e91c7d.jpg  
  inflating: /content/hymenoptera_data/train/bees/1295655112_7813f37d21.jpg  
  inflating: /content/hymenoptera_data/train/bees/132511197_0b86ad0fff.jpg  
  inflating: /content/hymenoptera_data/train/bees/132826773_dbbcb117b9.jpg  
  inflating: /content/hymenoptera_data/train/bees/150013791_969d9a968b.jpg  
  inflating: /content/hymenoptera_data/train/bees/1508176360_2972117c9d.jpg  
  inflating: /content/hymenoptera_data/train/bees/154600396_53e1252e52.jpg  
  inflating: /content/hymenoptera_data/train/bees/16838648_415acd9e3f.jpg  
  inflating: /content/hymenoptera_data/train/bees/1691282715_0addfdf5e8.jpg  
  inflating: /content/hymenoptera_data/train/bees/17209602_fe5a5a746f.jpg  
  inflating: /content/hymenoptera_data/train/bees/174142798_e5ad6d76e0.jpg  
  inflating: /content/hymenoptera_data/train/bees/1799726602_8580867f71.jpg  
  inflating: /content/hymenoptera_data/train/bees/1807583459_4fe92b3133.jpg  
  inflating: /content/hymenoptera_data/train/bees/196430254_46bd129ae7.jpg  
  inflating: /content/hymenoptera_data/train/bees/196658222_3fffd79c67.jpg  
  inflating: /content/hymenoptera_data/train/bees/198508668_97d818b6c4.jpg  
  inflating: /content/hymenoptera_data/train/bees/2031225713_50ed499635.jpg  
  inflating: /content/hymenoptera_data/train/bees/2037437624_2d7bce461f.jpg  
  inflating: /content/hymenoptera_data/train/bees/2053200300_8911ef438a.jpg  
  inflating: /content/hymenoptera_data/train/bees/205835650_e6f2614bee.jpg  
  inflating: /content/hymenoptera_data/train/bees/208702903_42fb4d9748.jpg  
  inflating: /content/hymenoptera_data/train/bees/21399619_3e61e5bb6f.jpg  
  inflating: /content/hymenoptera_data/train/bees/2227611847_ec72d40403.jpg  
  inflating: /content/hymenoptera_data/train/bees/2321139806_d73d899e66.jpg  
  inflating: /content/hymenoptera_data/train/bees/2330918208_8074770c20.jpg  
  inflating: /content/hymenoptera_data/train/bees/2345177635_caf07159b3.jpg  
  inflating: /content/hymenoptera_data/train/bees/2358061370_9daabbd9ac.jpg  
  inflating: /content/hymenoptera_data/train/bees/2364597044_3c3e3fc391.jpg  
  inflating: /content/hymenoptera_data/train/bees/2384149906_2cd8b0b699.jpg  
  inflating: /content/hymenoptera_data/train/bees/2397446847_04ef3cd3e1.jpg  
  inflating: /content/hymenoptera_data/train/bees/2405441001_b06c36fa72.jpg  
  inflating: /content/hymenoptera_data/train/bees/2445215254_51698ff797.jpg  
  inflating: /content/hymenoptera_data/train/bees/2452236943_255bfd9e58.jpg  
  inflating: /content/hymenoptera_data/train/bees/2467959963_a7831e9ff0.jpg  
  inflating: /content/hymenoptera_data/train/bees/2470492904_837e97800d.jpg  
  inflating: /content/hymenoptera_data/train/bees/2477324698_3d4b1b1cab.jpg  
  inflating: /content/hymenoptera_data/train/bees/2477349551_e75c97cf4d.jpg  
  inflating: /content/hymenoptera_data/train/bees/2486729079_62df0920be.jpg  
  inflating: /content/hymenoptera_data/train/bees/2486746709_c43cec0e42.jpg  
  inflating: /content/hymenoptera_data/train/bees/2493379287_4100e1dacc.jpg  
  inflating: /content/hymenoptera_data/train/bees/2495722465_879acf9d85.jpg  
  inflating: /content/hymenoptera_data/train/bees/2528444139_fa728b0f5b.jpg  
  inflating: /content/hymenoptera_data/train/bees/2538361678_9da84b77e3.jpg  
  inflating: /content/hymenoptera_data/train/bees/2551813042_8a070aeb2b.jpg  
  inflating: /content/hymenoptera_data/train/bees/2580598377_a4caecdb54.jpg  
  inflating: /content/hymenoptera_data/train/bees/2601176055_8464e6aa71.jpg  
  inflating: /content/hymenoptera_data/train/bees/2610833167_79bf0bcae5.jpg  
  inflating: /content/hymenoptera_data/train/bees/2610838525_fe8e3cae47.jpg  
  inflating: /content/hymenoptera_data/train/bees/2617161745_fa3ebe85b4.jpg  
  inflating: /content/hymenoptera_data/train/bees/2625499656_e3415e374d.jpg  
  inflating: /content/hymenoptera_data/train/bees/2634617358_f32fd16bea.jpg  
  inflating: /content/hymenoptera_data/train/bees/2638074627_6b3ae746a0.jpg  
  inflating: /content/hymenoptera_data/train/bees/2645107662_b73a8595cc.jpg  
  inflating: /content/hymenoptera_data/train/bees/2651621464_a2fa8722eb.jpg  
  inflating: /content/hymenoptera_data/train/bees/2652877533_a564830cbf.jpg  
  inflating: /content/hymenoptera_data/train/bees/266644509_d30bb16a1b.jpg  
  inflating: /content/hymenoptera_data/train/bees/2683605182_9d2a0c66cf.jpg  
  inflating: /content/hymenoptera_data/train/bees/2704348794_eb5d5178c2.jpg  
  inflating: /content/hymenoptera_data/train/bees/2707440199_cd170bd512.jpg  
  inflating: /content/hymenoptera_data/train/bees/2710368626_cb42882dc8.jpg  
  inflating: /content/hymenoptera_data/train/bees/2722592222_258d473e17.jpg  
  inflating: /content/hymenoptera_data/train/bees/2728759455_ce9bb8cd7a.jpg  
  inflating: /content/hymenoptera_data/train/bees/2756397428_1d82a08807.jpg  
  inflating: /content/hymenoptera_data/train/bees/2765347790_da6cf6cb40.jpg  
  inflating: /content/hymenoptera_data/train/bees/2781170484_5d61835d63.jpg  
  inflating: /content/hymenoptera_data/train/bees/279113587_b4843db199.jpg  
  inflating: /content/hymenoptera_data/train/bees/2792000093_e8ae0718cf.jpg  
  inflating: /content/hymenoptera_data/train/bees/2801728106_833798c909.jpg  
  inflating: /content/hymenoptera_data/train/bees/2822388965_f6dca2a275.jpg  
  inflating: /content/hymenoptera_data/train/bees/2861002136_52c7c6f708.jpg  
  inflating: /content/hymenoptera_data/train/bees/2908916142_a7ac8b57a8.jpg  
  inflating: /content/hymenoptera_data/train/bees/29494643_e3410f0d37.jpg  
  inflating: /content/hymenoptera_data/train/bees/2959730355_416a18c63c.jpg  
  inflating: /content/hymenoptera_data/train/bees/2962405283_22718d9617.jpg  
  inflating: /content/hymenoptera_data/train/bees/3006264892_30e9cced70.jpg  
  inflating: /content/hymenoptera_data/train/bees/3030189811_01d095b793.jpg  
  inflating: /content/hymenoptera_data/train/bees/3030772428_8578335616.jpg  
  inflating: /content/hymenoptera_data/train/bees/3044402684_3853071a87.jpg  
  inflating: /content/hymenoptera_data/train/bees/3074585407_9854eb3153.jpg  
  inflating: /content/hymenoptera_data/train/bees/3079610310_ac2d0ae7bc.jpg  
  inflating: /content/hymenoptera_data/train/bees/3090975720_71f12e6de4.jpg  
  inflating: /content/hymenoptera_data/train/bees/3100226504_c0d4f1e3f1.jpg  
  inflating: /content/hymenoptera_data/train/bees/342758693_c56b89b6b6.jpg  
  inflating: /content/hymenoptera_data/train/bees/354167719_22dca13752.jpg  
  inflating: /content/hymenoptera_data/train/bees/359928878_b3b418c728.jpg  
  inflating: /content/hymenoptera_data/train/bees/365759866_b15700c59b.jpg  
  inflating: /content/hymenoptera_data/train/bees/36900412_92b81831ad.jpg  
  inflating: /content/hymenoptera_data/train/bees/39672681_1302d204d1.jpg  
  inflating: /content/hymenoptera_data/train/bees/39747887_42df2855ee.jpg  
  inflating: /content/hymenoptera_data/train/bees/421515404_e87569fd8b.jpg  
  inflating: /content/hymenoptera_data/train/bees/444532809_9e931e2279.jpg  
  inflating: /content/hymenoptera_data/train/bees/446296270_d9e8b93ecf.jpg  
  inflating: /content/hymenoptera_data/train/bees/452462677_7be43af8ff.jpg  
  inflating: /content/hymenoptera_data/train/bees/452462695_40a4e5b559.jpg  
  inflating: /content/hymenoptera_data/train/bees/457457145_5f86eb7e9c.jpg  
  inflating: /content/hymenoptera_data/train/bees/465133211_80e0c27f60.jpg  
  inflating: /content/hymenoptera_data/train/bees/469333327_358ba8fe8a.jpg  
  inflating: /content/hymenoptera_data/train/bees/472288710_2abee16fa0.jpg  
  inflating: /content/hymenoptera_data/train/bees/473618094_8ffdcab215.jpg  
  inflating: /content/hymenoptera_data/train/bees/476347960_52edd72b06.jpg  
  inflating: /content/hymenoptera_data/train/bees/478701318_bbd5e557b8.jpg  
  inflating: /content/hymenoptera_data/train/bees/507288830_f46e8d4cb2.jpg  
  inflating: /content/hymenoptera_data/train/bees/509247772_2db2d01374.jpg  
  inflating: /content/hymenoptera_data/train/bees/513545352_fd3e7c7c5d.jpg  
  inflating: /content/hymenoptera_data/train/bees/522104315_5d3cb2758e.jpg  
  inflating: /content/hymenoptera_data/train/bees/537309131_532bfa59ea.jpg  
  inflating: /content/hymenoptera_data/train/bees/586041248_3032e277a9.jpg  
  inflating: /content/hymenoptera_data/train/bees/760526046_547e8b381f.jpg  
  inflating: /content/hymenoptera_data/train/bees/760568592_45a52c847f.jpg  
  inflating: /content/hymenoptera_data/train/bees/774440991_63a4aa0cbe.jpg  
  inflating: /content/hymenoptera_data/train/bees/85112639_6e860b0469.jpg  
  inflating: /content/hymenoptera_data/train/bees/873076652_eb098dab2d.jpg  
  inflating: /content/hymenoptera_data/train/bees/90179376_abc234e5f4.jpg  
  inflating: /content/hymenoptera_data/train/bees/92663402_37f379e57a.jpg  
  inflating: /content/hymenoptera_data/train/bees/95238259_98470c5b10.jpg  
  inflating: /content/hymenoptera_data/train/bees/969455125_58c797ef17.jpg  
  inflating: /content/hymenoptera_data/train/bees/98391118_bdb1e80cce.jpg  
   creating: /content/hymenoptera_data/val/
   creating: /content/hymenoptera_data/val/ants/
  inflating: /content/hymenoptera_data/val/ants/10308379_1b6c72e180.jpg  
  inflating: /content/hymenoptera_data/val/ants/1053149811_f62a3410d3.jpg  
  inflating: /content/hymenoptera_data/val/ants/1073564163_225a64f170.jpg  
  inflating: /content/hymenoptera_data/val/ants/1119630822_cd325ea21a.jpg  
  inflating: /content/hymenoptera_data/val/ants/1124525276_816a07c17f.jpg  
  inflating: /content/hymenoptera_data/val/ants/11381045_b352a47d8c.jpg  
  inflating: /content/hymenoptera_data/val/ants/119785936_dd428e40c3.jpg  
  inflating: /content/hymenoptera_data/val/ants/1247887232_edcb61246c.jpg  
  inflating: /content/hymenoptera_data/val/ants/1262751255_c56c042b7b.jpg  
  inflating: /content/hymenoptera_data/val/ants/1337725712_2eb53cd742.jpg  
  inflating: /content/hymenoptera_data/val/ants/1358854066_5ad8015f7f.jpg  
  inflating: /content/hymenoptera_data/val/ants/1440002809_b268d9a66a.jpg  
  inflating: /content/hymenoptera_data/val/ants/147542264_79506478c2.jpg  
  inflating: /content/hymenoptera_data/val/ants/152286280_411648ec27.jpg  
  inflating: /content/hymenoptera_data/val/ants/153320619_2aeb5fa0ee.jpg  
  inflating: /content/hymenoptera_data/val/ants/153783656_85f9c3ac70.jpg  
  inflating: /content/hymenoptera_data/val/ants/157401988_d0564a9d02.jpg  
  inflating: /content/hymenoptera_data/val/ants/159515240_d5981e20d1.jpg  
  inflating: /content/hymenoptera_data/val/ants/161076144_124db762d6.jpg  
  inflating: /content/hymenoptera_data/val/ants/161292361_c16e0bf57a.jpg  
  inflating: /content/hymenoptera_data/val/ants/170652283_ecdaff5d1a.jpg  
  inflating: /content/hymenoptera_data/val/ants/17081114_79b9a27724.jpg  
  inflating: /content/hymenoptera_data/val/ants/172772109_d0a8e15fb0.jpg  
  inflating: /content/hymenoptera_data/val/ants/1743840368_b5ccda82b7.jpg  
  inflating: /content/hymenoptera_data/val/ants/181942028_961261ef48.jpg  
  inflating: /content/hymenoptera_data/val/ants/183260961_64ab754c97.jpg  
  inflating: /content/hymenoptera_data/val/ants/2039585088_c6f47c592e.jpg  
  inflating: /content/hymenoptera_data/val/ants/205398178_c395c5e460.jpg  
  inflating: /content/hymenoptera_data/val/ants/208072188_f293096296.jpg  
  inflating: /content/hymenoptera_data/val/ants/209615353_eeb38ba204.jpg  
  inflating: /content/hymenoptera_data/val/ants/2104709400_8831b4fc6f.jpg  
  inflating: /content/hymenoptera_data/val/ants/212100470_b485e7b7b9.jpg  
  inflating: /content/hymenoptera_data/val/ants/2127908701_d49dc83c97.jpg  
  inflating: /content/hymenoptera_data/val/ants/2191997003_379df31291.jpg  
  inflating: /content/hymenoptera_data/val/ants/2211974567_ee4606b493.jpg  
  inflating: /content/hymenoptera_data/val/ants/2219621907_47bc7cc6b0.jpg  
  inflating: /content/hymenoptera_data/val/ants/2238242353_52c82441df.jpg  
  inflating: /content/hymenoptera_data/val/ants/2255445811_dabcdf7258.jpg  
  inflating: /content/hymenoptera_data/val/ants/239161491_86ac23b0a3.jpg  
  inflating: /content/hymenoptera_data/val/ants/263615709_cfb28f6b8e.jpg  
  inflating: /content/hymenoptera_data/val/ants/308196310_1db5ffa01b.jpg  
  inflating: /content/hymenoptera_data/val/ants/319494379_648fb5a1c6.jpg  
  inflating: /content/hymenoptera_data/val/ants/35558229_1fa4608a7a.jpg  
  inflating: /content/hymenoptera_data/val/ants/412436937_4c2378efc2.jpg  
  inflating: /content/hymenoptera_data/val/ants/436944325_d4925a38c7.jpg  
  inflating: /content/hymenoptera_data/val/ants/445356866_6cb3289067.jpg  
  inflating: /content/hymenoptera_data/val/ants/459442412_412fecf3fe.jpg  
  inflating: /content/hymenoptera_data/val/ants/470127071_8b8ee2bd74.jpg  
  inflating: /content/hymenoptera_data/val/ants/477437164_bc3e6e594a.jpg  
  inflating: /content/hymenoptera_data/val/ants/488272201_c5aa281348.jpg  
  inflating: /content/hymenoptera_data/val/ants/502717153_3e4865621a.jpg  
  inflating: /content/hymenoptera_data/val/ants/518746016_bcc28f8b5b.jpg  
  inflating: /content/hymenoptera_data/val/ants/540543309_ddbb193ee5.jpg  
  inflating: /content/hymenoptera_data/val/ants/562589509_7e55469b97.jpg  
  inflating: /content/hymenoptera_data/val/ants/57264437_a19006872f.jpg  
  inflating: /content/hymenoptera_data/val/ants/573151833_ebbc274b77.jpg  
  inflating: /content/hymenoptera_data/val/ants/649407494_9b6bc4949f.jpg  
  inflating: /content/hymenoptera_data/val/ants/751649788_78dd7d16ce.jpg  
  inflating: /content/hymenoptera_data/val/ants/768870506_8f115d3d37.jpg  
  inflating: /content/hymenoptera_data/val/ants/800px-Meat_eater_ant_qeen_excavating_hole.jpg  
  inflating: /content/hymenoptera_data/val/ants/8124241_36b290d372.jpg  
  inflating: /content/hymenoptera_data/val/ants/8398478_50ef10c47a.jpg  
  inflating: /content/hymenoptera_data/val/ants/854534770_31f6156383.jpg  
  inflating: /content/hymenoptera_data/val/ants/892676922_4ab37dce07.jpg  
  inflating: /content/hymenoptera_data/val/ants/94999827_36895faade.jpg  
  inflating: /content/hymenoptera_data/val/ants/Ant-1818.jpg  
  inflating: /content/hymenoptera_data/val/ants/ants-devouring-remains-of-large-dead-insect-on-red-tile-in-Stellenbosch-South-Africa-closeup-1-DHD.jpg  
  inflating: /content/hymenoptera_data/val/ants/desert_ant.jpg  
  inflating: /content/hymenoptera_data/val/ants/F.pergan.28(f).jpg  
  inflating: /content/hymenoptera_data/val/ants/Hormiga.jpg  
   creating: /content/hymenoptera_data/val/bees/
  inflating: /content/hymenoptera_data/val/bees/1032546534_06907fe3b3.jpg  
  inflating: /content/hymenoptera_data/val/bees/10870992_eebeeb3a12.jpg  
  inflating: /content/hymenoptera_data/val/bees/1181173278_23c36fac71.jpg  
  inflating: /content/hymenoptera_data/val/bees/1297972485_33266a18d9.jpg  
  inflating: /content/hymenoptera_data/val/bees/1328423762_f7a88a8451.jpg  
  inflating: /content/hymenoptera_data/val/bees/1355974687_1341c1face.jpg  
  inflating: /content/hymenoptera_data/val/bees/144098310_a4176fd54d.jpg  
  inflating: /content/hymenoptera_data/val/bees/1486120850_490388f84b.jpg  
  inflating: /content/hymenoptera_data/val/bees/149973093_da3c446268.jpg  
  inflating: /content/hymenoptera_data/val/bees/151594775_ee7dc17b60.jpg  
  inflating: /content/hymenoptera_data/val/bees/151603988_2c6f7d14c7.jpg  
  inflating: /content/hymenoptera_data/val/bees/1519368889_4270261ee3.jpg  
  inflating: /content/hymenoptera_data/val/bees/152789693_220b003452.jpg  
  inflating: /content/hymenoptera_data/val/bees/177677657_a38c97e572.jpg  
  inflating: /content/hymenoptera_data/val/bees/1799729694_0c40101071.jpg  
  inflating: /content/hymenoptera_data/val/bees/181171681_c5a1a82ded.jpg  
  inflating: /content/hymenoptera_data/val/bees/187130242_4593a4c610.jpg  
  inflating: /content/hymenoptera_data/val/bees/203868383_0fcbb48278.jpg  
  inflating: /content/hymenoptera_data/val/bees/2060668999_e11edb10d0.jpg  
  inflating: /content/hymenoptera_data/val/bees/2086294791_6f3789d8a6.jpg  
  inflating: /content/hymenoptera_data/val/bees/2103637821_8d26ee6b90.jpg  
  inflating: /content/hymenoptera_data/val/bees/2104135106_a65eede1de.jpg  
  inflating: /content/hymenoptera_data/val/bees/215512424_687e1e0821.jpg  
  inflating: /content/hymenoptera_data/val/bees/2173503984_9c6aaaa7e2.jpg  
  inflating: /content/hymenoptera_data/val/bees/220376539_20567395d8.jpg  
  inflating: /content/hymenoptera_data/val/bees/224841383_d050f5f510.jpg  
  inflating: /content/hymenoptera_data/val/bees/2321144482_f3785ba7b2.jpg  
  inflating: /content/hymenoptera_data/val/bees/238161922_55fa9a76ae.jpg  
  inflating: /content/hymenoptera_data/val/bees/2407809945_fb525ef54d.jpg  
  inflating: /content/hymenoptera_data/val/bees/2415414155_1916f03b42.jpg  
  inflating: /content/hymenoptera_data/val/bees/2438480600_40a1249879.jpg  
  inflating: /content/hymenoptera_data/val/bees/2444778727_4b781ac424.jpg  
  inflating: /content/hymenoptera_data/val/bees/2457841282_7867f16639.jpg  
  inflating: /content/hymenoptera_data/val/bees/2470492902_3572c90f75.jpg  
  inflating: /content/hymenoptera_data/val/bees/2478216347_535c8fe6d7.jpg  
  inflating: /content/hymenoptera_data/val/bees/2501530886_e20952b97d.jpg  
  inflating: /content/hymenoptera_data/val/bees/2506114833_90a41c5267.jpg  
  inflating: /content/hymenoptera_data/val/bees/2509402554_31821cb0b6.jpg  
  inflating: /content/hymenoptera_data/val/bees/2525379273_dcb26a516d.jpg  
  inflating: /content/hymenoptera_data/val/bees/26589803_5ba7000313.jpg  
  inflating: /content/hymenoptera_data/val/bees/2668391343_45e272cd07.jpg  
  inflating: /content/hymenoptera_data/val/bees/2670536155_c170f49cd0.jpg  
  inflating: /content/hymenoptera_data/val/bees/2685605303_9eed79d59d.jpg  
  inflating: /content/hymenoptera_data/val/bees/2702408468_d9ed795f4f.jpg  
  inflating: /content/hymenoptera_data/val/bees/2709775832_85b4b50a57.jpg  
  inflating: /content/hymenoptera_data/val/bees/2717418782_bd83307d9f.jpg  
  inflating: /content/hymenoptera_data/val/bees/272986700_d4d4bf8c4b.jpg  
  inflating: /content/hymenoptera_data/val/bees/2741763055_9a7bb00802.jpg  
  inflating: /content/hymenoptera_data/val/bees/2745389517_250a397f31.jpg  
  inflating: /content/hymenoptera_data/val/bees/2751836205_6f7b5eff30.jpg  
  inflating: /content/hymenoptera_data/val/bees/2782079948_8d4e94a826.jpg  
  inflating: /content/hymenoptera_data/val/bees/2809496124_5f25b5946a.jpg  
  inflating: /content/hymenoptera_data/val/bees/2815838190_0a9889d995.jpg  
  inflating: /content/hymenoptera_data/val/bees/2841437312_789699c740.jpg  
  inflating: /content/hymenoptera_data/val/bees/2883093452_7e3a1eb53f.jpg  
  inflating: /content/hymenoptera_data/val/bees/290082189_f66cb80bfc.jpg  
  inflating: /content/hymenoptera_data/val/bees/296565463_d07a7bed96.jpg  
  inflating: /content/hymenoptera_data/val/bees/3077452620_548c79fda0.jpg  
  inflating: /content/hymenoptera_data/val/bees/348291597_ee836fbb1a.jpg  
  inflating: /content/hymenoptera_data/val/bees/350436573_41f4ecb6c8.jpg  
  inflating: /content/hymenoptera_data/val/bees/353266603_d3eac7e9a0.jpg  
  inflating: /content/hymenoptera_data/val/bees/372228424_16da1f8884.jpg  
  inflating: /content/hymenoptera_data/val/bees/400262091_701c00031c.jpg  
  inflating: /content/hymenoptera_data/val/bees/416144384_961c326481.jpg  
  inflating: /content/hymenoptera_data/val/bees/44105569_16720a960c.jpg  
  inflating: /content/hymenoptera_data/val/bees/456097971_860949c4fc.jpg  
  inflating: /content/hymenoptera_data/val/bees/464594019_1b24a28bb1.jpg  
  inflating: /content/hymenoptera_data/val/bees/485743562_d8cc6b8f73.jpg  
  inflating: /content/hymenoptera_data/val/bees/540976476_844950623f.jpg  
  inflating: /content/hymenoptera_data/val/bees/54736755_c057723f64.jpg  
  inflating: /content/hymenoptera_data/val/bees/57459255_752774f1b2.jpg  
  inflating: /content/hymenoptera_data/val/bees/576452297_897023f002.jpg  
  inflating: /content/hymenoptera_data/val/bees/586474709_ae436da045.jpg  
  inflating: /content/hymenoptera_data/val/bees/590318879_68cf112861.jpg  
  inflating: /content/hymenoptera_data/val/bees/59798110_2b6a3c8031.jpg  
  inflating: /content/hymenoptera_data/val/bees/603709866_a97c7cfc72.jpg  
  inflating: /content/hymenoptera_data/val/bees/603711658_4c8cd2201e.jpg  
  inflating: /content/hymenoptera_data/val/bees/65038344_52a45d090d.jpg  
  inflating: /content/hymenoptera_data/val/bees/6a00d8341c630a53ef00e553d0beb18834-800wi.jpg  
  inflating: /content/hymenoptera_data/val/bees/72100438_73de9f17af.jpg  
  inflating: /content/hymenoptera_data/val/bees/759745145_e8bc776ec8.jpg  
  inflating: /content/hymenoptera_data/val/bees/936182217_c4caa5222d.jpg  
  inflating: /content/hymenoptera_data/val/bees/abeja.jpg
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Data augmentation and normalization for training</span>
<span class="c1"># Just normalization for validation</span>
<span class="n">data_transforms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]),</span>
    <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]),</span>
<span class="p">}</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;hymenoptera_data&#39;</span>
<span class="n">image_datasets</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>
                                          <span class="n">data_transforms</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
                  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dataloaders</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                             <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
              <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dataset_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="n">image_datasets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">classes</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">imshow</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Imshow for Tensor.&quot;&quot;&quot;</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">inp</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">transpose</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">mean</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">])</span>
    <span class="n">std</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">std</span> <span class="o">*</span> <span class="n">inp</span> <span class="o">+</span> <span class="n">mean</span>
    <span class="n">inp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">clip</span><span class="p">(</span><span class="n">inp</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">inp</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">title</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">pause</span><span class="p">(</span><span class="mf">0.001</span><span class="p">)</span>  <span class="c1"># pause a bit so that plots are updated</span>


<span class="c1"># Get a batch of training data</span>
<span class="n">inputs</span><span class="p">,</span> <span class="n">classes</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">dataloaders</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]))</span>

<span class="c1"># Make a grid from batch</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">make_grid</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>

<span class="n">imshow</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">title</span><span class="o">=</span><span class="p">[</span><span class="n">class_names</span><span class="p">[</span><span class="n">x</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">classes</span><span class="p">])</span>
</code></pre></div>
<p><img alt="png" src="../Deep_Learning_Notes_%28Important%29_files/Deep_Learning_Notes_%28Important%29_19_0.png" /></p>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">since</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

        <span class="c1"># Each epoch has a training and validation phase</span>
        <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set model to training mode</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>   <span class="c1"># Set model to evaluate mode</span>

            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">running_corrects</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Iterate over data.</span>
            <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># zero the parameter gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># forward</span>
                <span class="c1"># track history if only in train</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">):</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

                    <span class="c1"># backward + optimize only if in training phase</span>
                    <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># statistics</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">running_corrects</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>
            <span class="n">epoch_acc</span> <span class="o">=</span> <span class="n">running_corrects</span><span class="o">.</span><span class="n">double</span><span class="p">()</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>

            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> Loss: </span><span class="si">{:.4f}</span><span class="s1"> Acc: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">phase</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">))</span>

            <span class="c1"># deep copy the model</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;val&#39;</span> <span class="ow">and</span> <span class="n">epoch_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
                <span class="n">best_acc</span> <span class="o">=</span> <span class="n">epoch_acc</span>
                <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

        <span class="nb">print</span><span class="p">()</span>

    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">since</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training complete in </span><span class="si">{:.0f}</span><span class="s1">m </span><span class="si">{:.0f}</span><span class="s1">s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">time_elapsed</span> <span class="o">//</span> <span class="mi">60</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">%</span> <span class="mi">60</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best val Acc: </span><span class="si">{:4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_acc</span><span class="p">))</span>

    <span class="c1"># load best model weights</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_wts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">model_ft</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="c1"># Here the size of each output sample is set to 2.</span>
<span class="c1"># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">model_ft</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Observe that all parameters are being optimized</span>
<span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_ft</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">model_ft</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">exp_lr_scheduler</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Epoch 0/0
----------
train Loss: 0.4348 Acc: 0.7951
val Loss: 0.1981 Acc: 0.9085

Training complete in 0m 3s
Best val Acc: 0.908497
</code></pre></div>
<h2 id="hooks-the-amazing-trick-you-should-know">Hooks - The amazing trick you should know</h2>
<p><a href="https://towardsdatascience.com/the-one-pytorch-trick-which-you-should-know-2d5e9c1da2ca">the-one-pytorch-trick-which-you-should-know</a></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torchvision.models</span> <span class="kn">import</span> <span class="n">resnet34</span>


<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span><span class="p">)</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cpu&#39;</span><span class="p">)</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">resnet34</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">SaveOutput</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">module_in</span><span class="p">,</span> <span class="n">module_out</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">module_out</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">clear</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">outputs</span> <span class="o">=</span> <span class="p">[]</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Downloading: &quot;https://download.pytorch.org/models/resnet34-333f7ec4.pth&quot; to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth



HBox(children=(FloatProgress(value=0.0, max=87306240.0), HTML(value=&#39;&#39;)))
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">save_output</span> <span class="o">=</span> <span class="n">SaveOutput</span><span class="p">()</span>

<span class="n">hook_handles</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">layer</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">modules</span><span class="o">.</span><span class="n">conv</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
        <span class="n">handle</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">register_forward_hook</span><span class="p">(</span><span class="n">save_output</span><span class="p">)</span>
        <span class="n">hook_handles</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">handle</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">image</span> <span class="o">=</span> <span class="n">PIL</span><span class="o">.</span><span class="n">Image</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">paths</span><span class="p">[</span><span class="s1">&#39;image_path&#39;</span><span class="p">],</span> <span class="s1">&#39;cat.jpg&#39;</span><span class="p">))</span>
<span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">((</span><span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)),</span> <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
                                <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])])</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">out</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">len</span><span class="p">(</span><span class="n">save_output</span><span class="o">.</span><span class="n">outputs</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>36
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">save_output</span><span class="o">.</span><span class="n">outputs</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>[tensor([[[[-8.4063e-02, -3.1156e-01, -3.7922e-01,  ..., -3.1241e-01,
            -3.1991e-01, -7.8703e-02],
           [-6.6684e-01, -1.0324e+00, -1.1204e+00,  ..., -1.5653e+00,
            -1.5471e+00, -6.4014e-01],
           [-3.4449e-01, -6.4493e-01, -7.2495e-01,  ..., -1.2277e+00,
            -1.2087e+00, -4.5994e-01],
           ...,
           [ 2.1659e-02, -4.6106e-02, -2.1702e-01,  ..., -1.0963e-01,
            -1.2138e-01, -1.5617e-01],
           [-3.2920e-02, -1.3041e-01, -3.1823e-01,  ..., -2.6584e-02,
            -3.2380e-02, -1.1487e-01],
           [ 4.4561e-01, -2.9023e-01, -1.0615e+00,  ...,  4.9755e-01,
             4.4903e-01,  2.2949e-01]],

          [[-4.6110e-02, -3.0740e-02, -1.0826e-01,  ..., -7.0238e-02,
            -9.2460e-02, -2.0240e+00],
           [-3.5144e-02, -1.7679e-02, -4.9731e-02,  ..., -1.2231e-02,
            -9.3168e-03, -2.8310e+00],
           [-7.0530e-02, -3.8022e-02, -4.4606e-02,  ..., -4.5727e-03,
             2.5627e-02, -2.7854e+00],
           ...,
           [-7.3700e-01,  6.4940e-01, -5.2753e-01,  ...,  1.7030e-02,
            -3.7055e-02, -2.0967e-02],
           [-7.4464e-01,  6.5585e-01, -5.2193e-01,  ...,  4.4152e-02,
            -8.7973e-03,  4.6403e-02],
           [-6.1189e-01,  5.5873e-01, -4.2375e-01,  ...,  6.6532e-02,
             3.7737e-02,  6.0204e-02]],

          [[-2.3457e-01, -1.2645e-01, -1.7406e-01,  ..., -4.1817e-01,
            -4.3566e-01, -1.6011e+00],
           [-6.6614e-02, -2.3226e-02, -6.2236e-02,  ...,  2.1789e-02,
             3.5555e-02,  2.7135e-01],
           [-4.7556e-02, -7.3814e-02, -4.9432e-02,  ..., -5.7698e-02,
            -7.4298e-02, -6.5381e-02],
           ...,
           [ 3.9153e-03, -3.1434e-02, -2.9721e-02,  ..., -1.0715e-01,
            -6.9462e-02, -6.0394e-02],
           [ 1.6745e-02, -3.0932e-02, -2.6025e-02,  ..., -6.5645e-02,
            -1.0768e-01, -6.5954e-02],
           [ 1.7977e-01,  1.5711e-01, -9.2721e-02,  ..., -1.2713e-01,
            -1.2850e-01, -3.8657e-02]],

          ...,

          [[ 8.5574e-02,  1.1745e-01,  1.5548e-01,  ...,  4.0933e-01,
             4.1436e-01,  9.9362e-01],
           [-2.6615e-01,  4.7584e-02,  6.8852e-02,  ...,  1.1224e-01,
             1.0466e-01,  5.7341e-02],
           [-2.5215e-01,  2.7188e-02,  8.2145e-02,  ...,  1.0604e-01,
             1.0107e-01,  2.3964e-02],
           ...,
           [-1.5416e-01,  5.6333e-02, -1.2265e-01,  ...,  8.9357e-02,
             7.2297e-02,  4.5511e-02],
           [-1.6092e-01,  5.2559e-02, -1.2424e-01,  ...,  6.9515e-02,
             1.0962e-01,  5.3230e-02],
           [ 7.6358e-02,  5.4660e-02, -4.3079e-01,  ..., -4.0607e-03,
             1.3518e-02, -7.2620e-02]],

          [[ 3.1630e-01,  8.0494e-01,  1.0661e+00,  ...,  2.1891e+00,
             2.1899e+00,  1.3774e+00],
           [ 6.3669e-01,  1.2647e+00,  1.4631e+00,  ...,  3.0832e+00,
             3.0457e+00,  1.9488e+00],
           [ 2.7135e-01,  6.2898e-01,  6.9927e-01,  ...,  2.0648e+00,
             2.0256e+00,  1.1266e+00],
           ...,
           [-9.1054e-02, -3.8858e-02,  3.3645e-01,  ..., -1.9231e-01,
            -1.5554e-01, -1.0143e-01],
           [-8.0800e-02, -1.7947e-02,  3.7280e-01,  ..., -2.6777e-01,
            -2.3381e-01, -1.4636e-01],
           [-2.4702e-01, -5.7148e-02,  5.2341e-01,  ..., -1.4570e-01,
            -1.0016e-01, -4.2076e-02]],

          [[ 1.8776e-07,  2.7738e-07,  3.4406e-07,  ...,  5.4105e-07,
             5.3934e-07,  3.5630e-07],
           [ 2.7450e-07,  4.1102e-07,  5.1028e-07,  ...,  8.2784e-07,
             8.2309e-07,  5.3809e-07],
           [ 2.9428e-07,  4.4021e-07,  5.3925e-07,  ...,  8.8300e-07,
             8.7416e-07,  5.5885e-07],
           ...,
           [-2.8161e-08,  6.2136e-08,  1.4658e-07,  ...,  2.8521e-07,
             2.8608e-07,  1.9511e-07],
           [-3.0600e-08,  5.6445e-08,  1.3730e-07,  ...,  2.6854e-07,
             2.7299e-07,  1.8746e-07],
           [-1.4595e-08,  4.4339e-08,  9.0041e-08,  ...,  1.8611e-07,
             1.8967e-07,  1.3514e-07]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-7.1307e-01, -8.3134e-01, -8.4162e-01,  ..., -8.3447e-01,
            -8.8322e-01, -8.0581e-01],
           [-8.5292e-01, -7.7469e-01, -8.0102e-01,  ..., -7.7430e-01,
            -7.3565e-01, -5.8939e-01],
           [-8.3598e-01, -8.0091e-01, -9.0385e-01,  ..., -8.0386e-01,
            -8.3582e-01, -7.0583e-01],
           ...,
           [-1.0630e+00, -1.0327e+00, -9.0952e-01,  ..., -8.5371e-01,
            -9.6862e-01, -1.0368e+00],
           [-1.1039e+00, -1.0192e+00, -8.9569e-01,  ..., -8.6189e-01,
            -1.0371e+00, -1.1618e+00],
           [-8.5768e-01, -9.8439e-01, -8.9813e-01,  ..., -1.0932e+00,
            -1.2086e+00, -1.2490e+00]],

          [[-3.9721e-02,  1.8612e-02, -5.6467e-02,  ..., -7.6485e-01,
            -9.7524e-01, -3.5409e-01],
           [ 3.4262e-01,  3.3146e-01,  1.9839e-01,  ...,  1.2355e-01,
             9.3290e-02,  9.5830e-02],
           [ 1.3413e-01,  1.1606e-01,  2.6072e-02,  ..., -6.3812e-02,
            -5.7438e-02, -2.1188e-03],
           ...,
           [-1.8598e-02, -1.2766e-01, -2.4095e-02,  ...,  1.4271e-01,
             1.1860e-01, -4.7149e-02],
           [-9.9174e-03, -1.2616e-01,  4.7130e-03,  ...,  1.3165e-01,
            -4.2112e-02, -1.3193e-01],
           [-2.8945e-01, -5.4195e-02,  3.9133e-02,  ..., -2.2187e+00,
            -2.4321e+00, -1.8812e+00]],

          [[-6.8958e-01, -2.9590e-01, -3.4411e-01,  ..., -2.2276e-01,
            -3.4415e-01, -1.8591e+00],
           [-7.0155e-01, -4.5380e-01, -5.7219e-01,  ..., -4.8057e-01,
            -6.6103e-01, -1.7357e+00],
           [-4.6282e-01, -3.0516e-01, -4.1870e-01,  ..., -3.9162e-01,
            -6.0281e-01, -1.7183e+00],
           ...,
           [-1.5330e+00, -5.3029e-01, -3.5363e-01,  ..., -1.6527e-01,
            -5.8343e-01, -2.1110e+00],
           [-1.5865e+00, -5.5779e-01, -2.7971e-01,  ..., -4.0614e-01,
            -9.4208e-01, -2.4309e+00],
           [-1.5805e+00, -7.1949e-01, -3.7832e-01,  ..., -6.8876e-01,
            -1.1460e+00, -2.1012e+00]],

          ...,

          [[-9.6639e-01, -1.0328e+00, -1.0597e+00,  ..., -1.1950e+00,
            -1.2843e+00, -1.2610e+00],
           [-1.1809e+00, -1.1479e+00, -1.2401e+00,  ..., -1.3782e+00,
            -1.3827e+00, -1.0675e+00],
           [-1.1952e+00, -1.2641e+00, -1.3910e+00,  ..., -1.3886e+00,
            -1.3968e+00, -1.0293e+00],
           ...,
           [-2.8220e+00, -1.7530e+00, -1.6388e+00,  ..., -1.2392e+00,
            -1.2937e+00, -1.1474e+00],
           [-2.8713e+00, -1.6669e+00, -1.5304e+00,  ..., -1.2188e+00,
            -1.3438e+00, -1.1898e+00],
           [-2.7238e+00, -1.5046e+00, -1.3087e+00,  ..., -9.7235e-01,
            -1.0158e+00, -9.8973e-01]],

          [[-2.5968e+00, -1.6794e+00, -1.4204e+00,  ..., -1.1400e+00,
            -1.2257e+00, -1.2097e+00],
           [-2.6432e+00, -1.9258e+00, -1.7191e+00,  ..., -1.3148e+00,
            -1.1469e+00, -1.2445e+00],
           [-2.3157e+00, -2.0002e+00, -2.0134e+00,  ..., -1.4132e+00,
            -1.2471e+00, -1.5705e+00],
           ...,
           [-2.5916e+00, -3.0395e+00, -1.8192e+00,  ..., -1.3918e+00,
            -1.3557e+00, -2.4565e+00],
           [-2.6827e+00, -3.0189e+00, -1.6226e+00,  ..., -1.2810e+00,
            -1.2225e+00, -2.5779e+00],
           [-2.3964e+00, -2.7206e+00, -1.5952e+00,  ..., -1.3886e+00,
            -1.3188e+00, -2.3821e+00]],

          [[ 9.3492e-01,  2.9573e-01,  2.0938e-01,  ...,  1.5254e-01,
             9.0258e-03, -7.4639e-01],
           [ 6.4624e-01, -9.7434e-02, -1.3152e-01,  ...,  1.3951e-01,
            -1.5915e-01, -1.7132e+00],
           [ 5.5572e-01, -1.0975e-01, -1.4220e-01,  ..., -4.1307e-02,
            -3.4354e-01, -1.7407e+00],
           ...,
           [-9.0136e-01, -8.2252e-02, -6.0170e-02,  ...,  7.6841e-02,
             1.1324e-01, -1.2357e+00],
           [-7.7420e-01, -2.0381e-02, -8.0946e-02,  ...,  8.4156e-02,
             1.3501e-01, -1.3044e+00],
           [-3.3190e-01,  8.8170e-02, -1.7382e-02,  ..., -3.6395e-01,
            -4.6098e-01, -9.1564e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.0067,  0.0934,  0.2068,  ...,  0.2558,  0.2704,  0.1711],
           [-0.0525, -0.0926,  0.0183,  ...,  0.2465,  0.2182,  0.1562],
           [ 0.0718,  0.0516,  0.0838,  ...,  0.3026,  0.2200,  0.1786],
           ...,
           [ 0.0680,  0.0353,  0.0985,  ...,  0.0679, -0.0684, -0.0239],
           [ 0.1705,  0.0419,  0.0697,  ..., -0.0153, -0.0345,  0.0361],
           [ 0.1610, -0.1131, -0.0392,  ...,  0.0911,  0.0280,  0.0677]],

          [[ 0.1090,  0.0759,  0.1343,  ...,  0.0514,  0.0668,  0.0639],
           [ 0.1767,  0.1108,  0.1808,  ...,  0.0470,  0.0197,  0.0140],
           [ 0.2040,  0.1734,  0.2154,  ...,  0.0737,  0.0707,  0.0720],
           ...,
           [ 0.2990,  0.3060,  0.3207,  ...,  0.3023,  0.2745,  0.1356],
           [ 0.2607,  0.2654,  0.2734,  ...,  0.3501,  0.3430,  0.2238],
           [ 0.1456,  0.1358,  0.1019,  ...,  0.1606,  0.1911,  0.1065]],

          [[ 0.1066,  0.0436,  0.0515,  ...,  0.1293,  0.0921, -0.0538],
           [-0.2412, -0.3833, -0.2128,  ..., -0.2032, -0.2209, -0.0512],
           [-0.2085, -0.1475, -0.0593,  ..., -0.1508, -0.2108, -0.0181],
           ...,
           [-0.0955, -0.1585, -0.1726,  ..., -0.1232, -0.0873, -0.0838],
           [-0.2223, -0.3166, -0.2828,  ..., -0.2100, -0.1755, -0.1166],
           [-0.2328, -0.0936, -0.1716,  ..., -0.1858, -0.1902, -0.0887]],

          ...,

          [[ 0.0435, -0.0346, -0.0193,  ..., -0.0864, -0.0844, -0.0661],
           [-0.0094, -0.0602,  0.0022,  ..., -0.1411, -0.1402, -0.0684],
           [ 0.0354,  0.0333,  0.0703,  ..., -0.1200, -0.1259, -0.0280],
           ...,
           [ 0.0172,  0.0704,  0.0566,  ...,  0.1495,  0.1632,  0.0931],
           [-0.0317,  0.0102, -0.0065,  ...,  0.1540,  0.1796,  0.1241],
           [-0.0509, -0.0178, -0.0326,  ...,  0.0413,  0.0676,  0.0497]],

          [[-0.3162, -0.2310, -0.1908,  ..., -0.2563, -0.2508, -0.1339],
           [-0.2608, -0.2658, -0.3400,  ..., -0.3716, -0.3720, -0.0844],
           [-0.1699, -0.3054, -0.3627,  ..., -0.4232, -0.3379, -0.0883],
           ...,
           [-0.1122, -0.3011, -0.3755,  ..., -0.0965, -0.1681,  0.0880],
           [-0.2009, -0.3449, -0.3103,  ..., -0.1556, -0.2994,  0.1678],
           [-0.0541, -0.2684, -0.1538,  ..., -0.0941, -0.1122,  0.0796]],

          [[ 0.2191,  0.2895,  0.3184,  ...,  0.3778,  0.4290,  0.3253],
           [ 0.3126,  0.3261,  0.3293,  ...,  0.4939,  0.6433,  0.4783],
           [ 0.2731,  0.2239,  0.2208,  ...,  0.4430,  0.5743,  0.4407],
           ...,
           [ 0.1634,  0.1989,  0.3175,  ...,  0.1045,  0.0940,  0.1423],
           [ 0.1457,  0.1518,  0.2690,  ...,  0.1048,  0.0339,  0.0605],
           [ 0.0594,  0.0695,  0.1093,  ...,  0.0717,  0.0124,  0.0449]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.1288, -0.2503, -0.1333,  ...,  0.3151,  0.4780, -0.0678],
           [-0.0787, -0.1792,  0.0485,  ...,  0.4072,  0.4981,  0.3600],
           [-0.1732, -0.2616,  0.1061,  ...,  0.4136,  0.4425,  0.3536],
           ...,
           [ 0.3060,  0.4366,  0.2526,  ...,  0.0864,  0.3143,  0.0586],
           [ 0.3617,  0.2622,  0.2624,  ...,  0.1249,  0.4111, -0.2825],
           [-0.4700, -0.8507, -0.8230,  ..., -1.6068, -1.5898, -1.3000]],

          [[ 0.1018, -0.3544, -0.3491,  ..., -0.4679, -0.7683, -1.1598],
           [ 0.3575, -0.4819, -0.7272,  ..., -0.7274, -1.1150, -1.3365],
           [ 0.3272, -0.4256, -0.6880,  ..., -0.7192, -1.0137, -1.2675],
           ...,
           [ 0.1819, -1.3496, -1.1823,  ..., -0.5881, -0.5162, -0.5722],
           [ 0.1448, -1.2669, -0.9025,  ..., -0.6687, -0.3966, -0.2392],
           [ 0.2109, -0.8323, -0.4376,  ..., -0.2245,  0.0652, -0.1672]],

          [[-2.3957, -1.9007, -1.9473,  ..., -1.6839, -1.8994, -2.1858],
           [-1.2779, -1.4584, -1.7060,  ..., -1.2947, -1.5838, -2.1106],
           [-1.2658, -1.6701, -1.8100,  ..., -1.5734, -1.5880, -2.0974],
           ...,
           [-1.2345, -1.9685, -1.6607,  ..., -1.5137, -1.6177, -1.7467],
           [-1.2292, -1.9627, -1.5617,  ..., -1.7320, -1.6819, -1.7406],
           [-1.1952, -1.7024, -1.2822,  ..., -1.4485, -1.3326, -1.3642]],

          ...,

          [[-0.1999,  0.7422,  0.7286,  ...,  0.6396,  0.4921,  0.5735],
           [-1.8417, -0.0774,  0.0263,  ...,  0.1794,  0.2562,  0.3815],
           [-1.6356,  0.1033,  0.0197,  ...,  0.1362,  0.1361, -0.0085],
           ...,
           [-0.2457,  0.3278,  0.3608,  ...,  0.0249, -0.0697,  0.5960],
           [-0.1247,  0.2252,  0.2401,  ..., -0.4984, -0.5210,  0.4292],
           [-0.0336,  0.2188,  0.0487,  ...,  0.5139,  0.6008,  1.5812]],

          [[-0.8325, -0.2705, -0.1320,  ..., -0.0169,  0.0082,  0.7680],
           [-0.4834, -0.6586, -0.3605,  ..., -0.2657, -0.3053, -0.7996],
           [-0.5342, -0.6958, -0.3008,  ...,  0.2130,  0.0545, -0.5790],
           ...,
           [-0.4812, -0.5852, -0.1952,  ..., -0.3104, -0.3786, -0.7488],
           [-0.4629, -0.5718, -0.3029,  ..., -0.2068, -0.0184, -0.5921],
           [-0.5736, -0.6432, -0.3380,  ..., -0.2731, -0.3399, -0.5874]],

          [[ 0.6537,  0.2888,  0.3033,  ...,  1.1874,  1.1648,  1.3152],
           [ 0.9450,  0.6366,  0.6243,  ...,  1.1310,  1.0945,  1.3916],
           [ 1.1746,  0.9364,  0.9100,  ...,  1.3841,  1.2866,  1.4843],
           ...,
           [ 1.2870,  1.4445,  1.4908,  ...,  0.4462,  0.4064,  0.9422],
           [ 1.2159,  1.3198,  1.4482,  ...,  1.2616,  1.2065,  1.4373],
           [-0.4371, -0.9823, -0.9968,  ...,  0.9042,  0.7254,  1.2273]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.0690,  0.0205,  0.0238,  ...,  0.0504,  0.0489,  0.0620],
           [-0.0085, -0.2284, -0.2074,  ..., -0.0862, -0.2175, -0.0029],
           [ 0.1603,  0.0254, -0.0896,  ..., -0.1621, -0.2845,  0.0653],
           ...,
           [-0.0922, -0.0500, -0.0803,  ...,  0.1579, -0.0258,  0.1260],
           [ 0.1160, -0.0575, -0.1284,  ..., -0.1459,  0.0544,  0.1429],
           [ 0.1766, -0.3412, -0.2090,  ..., -0.2005, -0.1526, -0.0480]],

          [[ 0.0569, -0.0271,  0.0484,  ...,  0.0785,  0.0668,  0.0726],
           [ 0.1256, -0.0083,  0.1261,  ...,  0.1567,  0.1875,  0.0977],
           [ 0.0912, -0.0189,  0.1105,  ...,  0.1244,  0.1274,  0.0368],
           ...,
           [ 0.0576,  0.0070,  0.0357,  ..., -0.1868, -0.2296, -0.1509],
           [ 0.1553,  0.0701,  0.0321,  ..., -0.2530, -0.2889, -0.2127],
           [ 0.0855,  0.0397, -0.0359,  ..., -0.1913, -0.2375, -0.1456]],

          [[ 0.1201,  0.0909,  0.0267,  ...,  0.0299,  0.1325,  0.0393],
           [-0.0334,  0.0592,  0.0434,  ...,  0.0855,  0.1506,  0.1683],
           [-0.1773, -0.0331,  0.0200,  ...,  0.0043,  0.0764,  0.0877],
           ...,
           [-0.0717,  0.0951,  0.0525,  ..., -0.0263,  0.0365,  0.0329],
           [-0.0570,  0.0173, -0.0354,  ..., -0.0474, -0.0211,  0.0258],
           [-0.1326,  0.0810, -0.0064,  ..., -0.0219, -0.0343,  0.0497]],

          ...,

          [[ 0.0337,  0.0411,  0.0187,  ..., -0.0363, -0.0619, -0.0256],
           [-0.0246,  0.0176,  0.0450,  ..., -0.0725, -0.1047, -0.0112],
           [-0.0102,  0.0386,  0.0480,  ..., -0.0989, -0.1209,  0.0060],
           ...,
           [ 0.0540,  0.0942,  0.0474,  ...,  0.0919,  0.0928,  0.1310],
           [ 0.0908,  0.1295,  0.0543,  ...,  0.1005,  0.1049,  0.1038],
           [ 0.0257,  0.0705,  0.0354,  ...,  0.0861,  0.0639,  0.0800]],

          [[-0.0520, -0.1138, -0.1880,  ..., -0.2184, -0.2333, -0.2963],
           [-0.0347,  0.2291, -0.0918,  ...,  0.0682,  0.1796, -0.1232],
           [-0.0566,  0.0762, -0.2317,  ..., -0.1599,  0.0066, -0.0630],
           ...,
           [-0.1647,  0.0511, -0.1918,  ..., -0.0743, -0.0133, -0.0464],
           [-0.2029,  0.0046, -0.0944,  ...,  0.0204, -0.0767, -0.0127],
           [ 0.0343, -0.0258, -0.0422,  ..., -0.0718, -0.1464,  0.0529]],

          [[ 0.0959, -0.1765, -0.1379,  ..., -0.2142, -0.2033,  0.0204],
           [ 0.2175, -0.1815, -0.1862,  ..., -0.2911, -0.1999, -0.0215],
           [ 0.3199, -0.1060, -0.1423,  ..., -0.2524, -0.1460,  0.0433],
           ...,
           [ 0.2595, -0.0375, -0.0292,  ...,  0.1552,  0.2469,  0.2323],
           [ 0.2947,  0.0060, -0.0351,  ...,  0.3238,  0.4278,  0.3459],
           [ 0.2347,  0.1015,  0.0621,  ...,  0.3857,  0.4319,  0.3006]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.7312, -1.0573, -0.8696,  ..., -0.9803, -1.2274, -0.4400],
           [-0.4258, -1.6297, -1.3173,  ..., -1.3742, -1.6037, -0.2364],
           [-0.5914, -1.0902, -1.3082,  ..., -1.8181, -1.7968, -0.3723],
           ...,
           [-0.0704, -1.8710, -1.3881,  ..., -1.1977, -1.1060, -0.3352],
           [ 0.0396, -2.2010, -1.4669,  ..., -1.7222, -0.9263, -0.2770],
           [ 0.2731, -1.0796, -0.5575,  ..., -0.3376, -0.2581, -0.1647]],

          [[ 0.7737,  0.8047,  0.0747,  ...,  0.1028,  0.4023, -0.9467],
           [ 0.6843,  1.3533,  0.0049,  ...,  0.0604,  0.2824, -0.6501],
           [ 0.3333,  1.1694,  0.5182,  ..., -0.0359,  0.2724, -0.2666],
           ...,
           [ 1.1152,  1.0655, -0.3863,  ..., -0.1095,  0.0656,  0.4892],
           [ 1.3597,  1.0931, -0.1453,  ..., -0.5847, -0.5435,  0.5415],
           [ 1.5063,  0.8190, -0.0748,  ..., -0.2666,  0.0716,  0.4723]],

          [[-0.0421,  0.1598,  0.3452,  ...,  0.6064,  0.5386,  0.9047],
           [ 0.0706,  0.1349,  0.2835,  ...,  0.7040,  0.5819,  1.0330],
           [ 0.1681,  0.2871,  0.3497,  ...,  0.8788,  0.6498,  0.8639],
           ...,
           [ 0.9277,  1.1339,  0.8439,  ...,  0.2173, -0.0893,  0.3682],
           [ 1.2604,  1.4140,  1.0508,  ...,  0.1766, -0.1631,  0.3723],
           [ 0.8026,  0.9001,  0.7016,  ...,  0.1117, -0.3394,  0.0032]],

          ...,

          [[ 0.3208, -0.5787, -0.2745,  ..., -0.4792, -0.7870, -1.1380],
           [ 0.1350, -0.8132, -0.8228,  ..., -0.6536, -0.6146, -1.3862],
           [ 0.1851, -0.2499, -0.5231,  ..., -1.0034, -0.4775, -1.1100],
           ...,
           [ 0.3556, -1.2090, -1.0370,  ..., -0.5365,  0.0756, -0.8619],
           [ 0.4460, -0.9401, -0.7835,  ..., -0.5803,  0.0291, -0.5543],
           [-0.0055, -1.0113, -0.8210,  ..., -0.3147, -0.1591, -0.7711]],

          [[ 1.0562,  0.7463,  1.1578,  ...,  0.7318,  0.2068,  0.3523],
           [ 0.5896,  0.3341,  1.3005,  ...,  0.6428, -0.1286, -0.1280],
           [ 0.6546,  0.4339,  1.3679,  ...,  1.0451,  0.3791, -0.1241],
           ...,
           [ 0.3876,  1.0999,  1.5070,  ...,  0.8180,  0.7997, -0.3036],
           [ 0.5483,  1.5749,  1.3768,  ...,  1.0305,  0.9950, -0.3318],
           [-0.3145,  0.1694,  0.0642,  ...,  0.0511, -0.0087, -0.5342]],

          [[ 0.4556,  0.0650,  0.5178,  ...,  0.5446,  0.9076, -1.0967],
           [-0.2459, -0.5475, -0.1135,  ...,  0.3136,  0.9088, -1.6499],
           [-0.2022, -0.3190, -0.1806,  ...,  0.0904,  0.7406, -1.3833],
           ...,
           [-0.8970,  0.2649, -0.0789,  ..., -0.0769,  1.1681, -2.2012],
           [-1.2325,  0.4407, -0.1711,  ..., -0.0385,  1.1555, -2.5085],
           [-0.5395,  0.5949,  0.0827,  ...,  0.2193,  0.9333, -1.8239]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-3.7964e-01, -4.0134e-01, -1.7608e-01,  ..., -2.5551e-01,
            -2.3841e-01, -2.2295e-01],
           [ 3.9957e-02, -1.3263e-01,  8.1712e-02,  ...,  2.3840e-01,
             1.3429e-01,  7.8315e-02],
           [ 3.1333e-03, -1.0131e-02, -6.6429e-02,  ..., -2.0292e-01,
            -2.8177e-01, -5.3561e-02],
           ...,
           [-2.1268e-01,  1.5780e-01,  6.7509e-02,  ...,  1.0054e-01,
            -1.3563e-01, -2.1604e-01],
           [ 1.4755e-02,  8.2588e-02, -1.2901e-01,  ..., -3.6963e-01,
            -8.8912e-02, -3.1725e-02],
           [-1.5123e-02, -4.9199e-01, -3.9780e-01,  ..., -4.1590e-01,
            -4.3884e-01, -4.5005e-01]],

          [[-2.4282e-02, -8.2193e-02, -8.2178e-02,  ..., -1.3298e-01,
             5.8532e-02, -7.8329e-02],
           [-3.2592e-03, -1.6045e-01, -1.6002e-01,  ..., -1.8618e-01,
             2.2344e-03, -2.6714e-01],
           [ 1.4457e-02, -7.3774e-02, -1.1208e-01,  ..., -1.1209e-01,
             3.8288e-02, -2.6211e-01],
           ...,
           [ 2.3041e-01,  1.1639e-01,  2.1283e-02,  ...,  1.4279e-02,
             3.2593e-02, -1.5568e-01],
           [ 2.3745e-01,  7.5388e-02, -6.5470e-02,  ...,  1.2928e-01,
             1.2930e-01, -9.1972e-02],
           [ 7.6496e-02, -1.1406e-01, -2.1356e-01,  ..., -8.5138e-02,
            -8.2041e-02, -1.7543e-01]],

          [[ 3.8545e-02,  1.7309e-02, -1.7679e-01,  ..., -7.5756e-02,
            -6.3311e-02, -8.1885e-02],
           [ 2.0244e-01,  2.7231e-01,  3.9004e-02,  ...,  1.4688e-02,
            -4.5041e-02,  5.9030e-02],
           [ 4.0409e-02,  2.9233e-01,  1.1852e-01,  ..., -3.0633e-02,
             4.2346e-02,  1.1974e-01],
           ...,
           [ 1.0777e-01,  1.0976e-01,  5.1145e-02,  ...,  8.7173e-02,
             6.6064e-02,  1.9359e-01],
           [ 8.7519e-02, -1.2386e-02,  7.9483e-02,  ...,  3.3585e-02,
             1.0019e-01,  3.8054e-01],
           [ 1.6395e-01,  3.0325e-01,  8.2967e-02,  ...,  1.3820e-01,
             3.1377e-01,  4.5450e-01]],

          ...,

          [[ 1.3808e-01,  2.0525e-01,  1.7885e-01,  ...,  2.8482e-01,
             2.8515e-01,  1.2578e-01],
           [ 9.4201e-04,  1.4381e-01,  1.7652e-01,  ...,  2.2403e-01,
             2.0144e-01,  1.4126e-01],
           [-1.8357e-02,  7.3374e-02,  1.4470e-01,  ...,  1.3975e-01,
             1.9496e-01,  1.3552e-01],
           ...,
           [ 1.2864e-01,  1.7703e-02,  7.7141e-04,  ...,  1.4196e-01,
             1.6583e-01,  7.5212e-02],
           [ 8.7795e-02,  1.2203e-01,  4.5601e-02,  ...,  4.8339e-02,
             1.1783e-01,  3.1923e-02],
           [ 8.8624e-02,  2.0204e-01,  1.8055e-01,  ...,  9.0144e-02,
             1.2010e-01,  7.4829e-02]],

          [[-1.2925e-01, -2.7588e-02, -4.4342e-02,  ...,  8.2830e-02,
            -1.7703e-02, -6.3619e-02],
           [-1.4586e-01, -9.6416e-03,  5.4718e-02,  ..., -3.5866e-02,
            -1.2122e-01, -2.9893e-02],
           [-3.0947e-01, -8.5613e-02, -1.7647e-02,  ..., -2.0618e-01,
            -4.2163e-02, -4.4049e-04],
           ...,
           [-2.7113e-01, -1.3855e-01, -2.0130e-01,  ..., -2.0272e-01,
            -1.9512e-01, -1.2623e-01],
           [-2.4112e-01, -1.5066e-01, -1.6733e-01,  ..., -1.9722e-01,
            -3.0106e-01, -1.2402e-01],
           [-2.4192e-01, -1.7451e-01,  2.7594e-02,  ..., -1.0973e-02,
            -1.1463e-01, -6.7437e-02]],

          [[ 2.1856e-01,  1.2767e-01,  8.7509e-02,  ...,  1.7413e-01,
             1.3547e-01,  2.4634e-01],
           [ 3.9917e-01,  2.7012e-01,  1.7836e-01,  ...,  3.1700e-01,
             3.3307e-01,  3.6791e-01],
           [ 1.9946e-01,  9.8512e-02, -6.8485e-03,  ...,  1.6686e-01,
             2.0509e-01,  2.7482e-01],
           ...,
           [ 3.2994e-01,  2.2487e-01,  1.6483e-01,  ...,  1.2141e-01,
             1.8807e-01,  2.3022e-01],
           [ 3.5468e-01,  3.0923e-01,  1.8328e-01,  ...,  1.1140e-01,
             1.1644e-01,  1.4330e-01],
           [ 2.4101e-01,  2.4712e-01,  1.5476e-01,  ...,  1.7904e-01,
             1.7466e-01,  1.4160e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-9.0091e-01,  6.3870e-01, -3.0263e-01,  ..., -6.5964e-01,
             7.8636e-01, -1.0163e+00],
           [-1.1825e+00,  6.3744e-01, -3.5650e-01,  ..., -8.8556e-02,
             3.4580e-01, -1.0833e-01],
           [-1.1111e+00,  3.4459e-01, -7.5116e-01,  ..., -1.6278e-01,
            -2.8018e-01,  2.0702e-01],
           ...,
           [ 7.5050e-01, -9.8482e-01,  4.0760e-01,  ...,  6.2197e-01,
             1.2554e-01, -6.7755e-01],
           [-1.5456e+00,  1.3781e-01,  6.0317e-01,  ...,  1.3621e+00,
            -1.3546e-01,  1.2409e-01],
           [-1.1613e+00, -3.4615e-01,  1.3554e-01,  ...,  4.6713e-02,
            -1.0961e-01,  5.2183e-01]],

          [[ 6.4298e-01,  2.1897e-01,  1.5417e-01,  ...,  6.1239e-01,
             6.5252e-01,  1.9946e-01],
           [-2.1554e-01, -4.5524e-01,  3.1487e-01,  ...,  1.2128e+00,
             1.7485e+00,  1.2734e-02],
           [-4.8627e-02, -8.1735e-02, -1.5425e-01,  ..., -3.5698e-02,
             9.1563e-01,  1.5359e+00],
           ...,
           [-8.6189e-01, -1.1113e-01, -1.0548e-01,  ..., -2.2268e-01,
             2.1504e-02, -4.1924e-01],
           [-7.7746e-01, -6.7780e-01,  6.5219e-02,  ..., -2.7417e-01,
            -1.9657e-01,  3.0158e-02],
           [-4.2939e-01, -1.1187e-01,  8.3300e-01,  ..., -3.0947e-01,
             1.2986e-02, -7.6760e-02]],

          [[-2.2114e-01, -3.9811e-01, -4.3892e-01,  ..., -4.2268e-01,
            -6.8673e-01, -4.9937e-01],
           [-7.4385e-02,  1.0765e-01, -6.6805e-01,  ..., -2.9073e-01,
            -7.2485e-01,  3.2642e-01],
           [ 1.7151e-01, -9.0508e-02, -1.4112e-01,  ...,  2.7432e-01,
             3.4726e-02,  8.5700e-02],
           ...,
           [ 4.4768e-02,  7.3492e-01,  1.7399e-01,  ...,  1.5529e-01,
            -5.5666e-02, -1.0640e+00],
           [ 5.0144e-01,  4.9841e-01,  6.9592e-04,  ..., -2.5502e-01,
            -5.8249e-01, -4.9665e-03],
           [ 3.5961e-01, -6.5753e-01, -2.9218e-01,  ...,  7.3599e-03,
            -4.0838e-01,  2.6860e-02]],

          ...,

          [[ 7.9693e-01,  1.1981e+00, -2.6719e-02,  ..., -1.4044e-01,
             9.2718e-01, -5.7674e-01],
           [ 8.0784e-01, -1.5681e+00,  1.8397e-01,  ...,  8.7765e-01,
            -6.4868e-01,  6.9011e-01],
           [-2.4827e-02,  1.6731e-01, -1.2616e-01,  ..., -3.6915e-01,
             2.0152e-01, -3.9128e-01],
           ...,
           [-1.1125e+00,  4.7629e-01,  8.7911e-01,  ..., -9.4275e-04,
            -9.2995e-01,  2.9742e-01],
           [ 5.7873e-01,  6.8500e-01, -5.4961e-01,  ..., -3.0391e-01,
             5.8966e-01, -1.5808e-01],
           [-5.0518e-01,  5.9546e-01, -4.2340e-01,  ..., -7.0296e-02,
             1.5118e-01,  5.6469e-01]],

          [[-1.1372e-01,  1.9317e-01, -2.0616e-01,  ..., -4.5876e-02,
             2.9818e-02, -1.4028e-01],
           [ 2.7155e-02,  4.5951e-01,  1.8610e-01,  ...,  4.6667e-01,
            -3.9038e-01,  1.1254e+00],
           [ 2.1434e-01,  5.7286e-02, -2.0534e-01,  ..., -2.1218e-01,
             3.6298e-02,  5.4128e-01],
           ...,
           [-1.6878e+00, -1.5219e+00,  8.6590e-02,  ...,  5.5942e-01,
             3.5859e-01,  1.3370e+00],
           [-1.2910e+00,  2.3102e-01,  6.7816e-01,  ..., -2.6203e-01,
            -2.4199e-01, -1.0794e-01],
           [-4.2782e-02,  7.7749e-01,  9.3433e-01,  ...,  9.2322e-01,
             1.2178e+00,  1.8176e+00]],

          [[-7.9935e-01, -1.2774e+00, -4.3572e-01,  ..., -7.2118e-02,
            -2.2340e-01, -4.4651e-01],
           [-1.7296e+00, -2.1770e+00, -8.5848e-01,  ..., -6.6132e-01,
            -3.8605e-01, -7.1216e-01],
           [-1.2839e+00, -2.0997e+00, -1.4358e+00,  ..., -1.1509e+00,
            -7.3437e-01, -1.2747e+00],
           ...,
           [-1.7467e+00, -2.7322e+00, -1.0077e+00,  ..., -9.5499e-01,
            -6.3091e-01, -1.0631e+00],
           [-2.0026e+00, -1.7775e+00, -9.2295e-01,  ..., -6.0964e-01,
            -4.7979e-01, -5.8898e-01],
           [-1.4926e+00, -1.1507e+00, -3.1636e-01,  ..., -1.2428e-01,
            -4.7847e-01, -4.4640e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 9.5913e-02, -1.6541e-01, -5.6267e-02,  ..., -1.8978e-01,
            -1.0216e-02, -2.0282e-02],
           [-7.9051e-02, -1.5625e-01, -9.1682e-02,  ..., -1.2345e-01,
            -5.0356e-02,  6.8900e-02],
           [-1.3790e-01, -1.4030e-01, -7.8608e-02,  ..., -1.1149e-01,
            -3.1122e-01, -2.4360e-01],
           ...,
           [-2.0402e-01, -2.7970e-01, -5.8880e-02,  ..., -1.2766e-01,
            -1.5945e-01, -1.4166e-04],
           [ 1.0777e-01, -5.8746e-02, -3.4232e-01,  ..., -6.7850e-02,
            -1.2919e-01,  2.3733e-02],
           [-1.5006e-01,  1.8371e-01, -2.5554e-01,  ..., -2.5197e-01,
            -8.3513e-03,  7.0744e-02]],

          [[-1.1158e-02, -2.5456e-02, -3.6755e-02,  ...,  6.3668e-02,
            -1.7311e-01,  1.1011e-01],
           [-6.5492e-02,  9.1241e-02, -5.5219e-02,  ...,  3.3896e-02,
            -8.6943e-02,  2.9966e-02],
           [-2.4388e-02, -2.0955e-02, -1.2032e-02,  ..., -4.6190e-03,
             1.3383e-02,  5.6576e-02],
           ...,
           [ 6.9491e-03,  1.1501e-01, -1.6926e-04,  ...,  3.8924e-02,
            -1.5815e-02,  3.5392e-02],
           [-7.1771e-02, -1.1710e-01,  1.3267e-02,  ..., -1.1833e-01,
             4.6548e-02,  3.4670e-02],
           [-2.0510e-02,  4.5852e-02, -9.4286e-03,  ...,  7.4114e-02,
             2.8800e-02, -4.0978e-02]],

          [[ 2.8442e-01,  1.8822e-01,  2.3620e-01,  ...,  1.2417e-01,
             2.6348e-01,  3.2023e-01],
           [ 3.0938e-02,  7.4200e-02,  2.4235e-01,  ...,  1.3457e-01,
             1.1945e-01,  9.4352e-02],
           [ 1.0847e-01,  1.3481e-01, -2.0223e-02,  ...,  1.2688e-01,
             1.3234e-01,  2.9863e-02],
           ...,
           [-9.2610e-02,  2.1935e-02, -1.5643e-01,  ..., -4.6844e-02,
            -1.0332e-01,  8.3054e-02],
           [ 3.7796e-02,  2.5773e-01,  1.3152e-02,  ..., -6.5266e-02,
            -2.9678e-02, -1.7658e-01],
           [ 3.2729e-01,  2.8362e-01,  1.0696e-01,  ...,  2.2743e-01,
             1.2019e-02,  1.5634e-01]],

          ...,

          [[-3.0847e-01, -2.5876e-01, -3.6083e-01,  ..., -2.5877e-01,
            -3.1287e-01, -3.7233e-01],
           [-1.3438e-01, -1.4756e-01, -2.5999e-01,  ..., -2.9874e-01,
            -2.4534e-01, -1.3022e-01],
           [ 7.5756e-02, -9.8625e-02, -1.1781e-01,  ..., -6.3175e-02,
            -1.2338e-01,  8.6862e-02],
           ...,
           [-1.4622e-01, -3.0403e-01, -1.7429e-01,  ..., -1.5258e-01,
            -1.9483e-01, -1.2083e-04],
           [ 5.3101e-02, -1.3620e-01, -1.3141e-01,  ...,  2.1619e-01,
            -8.5160e-02, -4.4242e-02],
           [-7.8481e-02,  8.2884e-02,  1.2997e-02,  ...,  7.7851e-02,
             1.4876e-01,  5.9686e-02]],

          [[-4.4822e-01, -4.4531e-01, -5.4460e-01,  ..., -4.2265e-01,
            -5.7580e-01, -3.2392e-01],
           [-4.1808e-01, -4.3049e-01, -5.1591e-01,  ..., -4.7325e-01,
            -4.2901e-01, -3.3930e-01],
           [-3.9814e-01, -3.4293e-01, -4.2360e-01,  ..., -5.9320e-01,
            -4.5428e-01, -3.0691e-01],
           ...,
           [-5.2022e-01, -4.3604e-01, -2.8243e-01,  ..., -3.7317e-01,
            -3.8210e-01, -5.0886e-01],
           [-7.2720e-01, -4.8945e-01, -1.4572e-01,  ..., -4.5263e-01,
            -4.7482e-01, -6.6300e-01],
           [-5.8000e-01, -3.1295e-01, -3.2944e-01,  ..., -4.0389e-01,
            -4.3888e-01, -3.2057e-01]],

          [[ 9.7382e-02,  9.4367e-02,  7.4948e-03,  ...,  2.4979e-01,
             3.8360e-01,  2.1761e-01],
           [-2.4950e-01, -8.9020e-02, -1.3273e-01,  ...,  8.9120e-02,
             2.7409e-01, -1.7473e-01],
           [-5.4640e-02,  1.3543e-01, -3.0125e-02,  ...,  1.0683e-01,
             1.2142e-01,  2.9367e-01],
           ...,
           [ 6.0568e-01, -6.5119e-02, -8.1571e-02,  ...,  6.2436e-02,
            -4.4642e-02,  8.2873e-02],
           [ 5.8876e-02, -8.7217e-02,  7.7449e-02,  ..., -1.0470e-01,
            -2.2360e-02, -7.8556e-03],
           [ 7.5289e-03,  1.0554e-01,  5.1145e-02,  ...,  1.0968e-01,
             1.1641e-01, -6.0809e-02]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-4.2273e-01, -2.0987e-01, -1.8386e-01,  ..., -1.6742e-01,
            -1.4549e-01, -2.3816e-01],
           [ 5.2229e-02, -2.1747e-01,  1.6554e-03,  ...,  9.4766e-02,
             2.8188e-03,  2.2632e-02],
           [-2.1932e-01, -4.8531e-02,  1.7961e-02,  ..., -1.8766e-01,
            -1.5018e-01, -2.3167e-01],
           ...,
           [-2.6574e-01, -2.2816e-01, -1.6534e-02,  ..., -1.1980e-01,
            -9.9002e-02, -1.0444e-01],
           [-1.4383e-01, -4.1912e-02,  1.2204e-01,  ...,  1.0591e-02,
            -7.6314e-03, -3.2738e-01],
           [-1.8492e-01, -6.7604e-02, -2.1401e-02,  ..., -2.0158e-01,
            -1.5867e-01, -5.3975e-02]],

          [[ 1.3357e+00,  1.1842e+00,  1.3085e+00,  ...,  8.3036e-01,
             8.1247e-01,  1.1123e+00],
           [ 9.6221e-01,  9.3270e-01,  1.3355e+00,  ...,  6.1226e-01,
             2.3988e-01,  4.3982e-01],
           [ 8.8059e-01,  7.4175e-01,  8.8665e-01,  ...,  8.1106e-01,
             4.9318e-01,  7.6294e-01],
           ...,
           [ 1.9570e-01, -8.9729e-02, -1.5378e-01,  ...,  1.0819e+00,
             9.9820e-01,  1.2328e+00],
           [-1.6463e-01, -1.0758e-01, -1.3862e-01,  ...,  1.1708e+00,
             9.6169e-01,  1.4559e+00],
           [-2.3193e-01, -2.6281e-01, -1.7272e-01,  ...,  1.1984e+00,
             1.3402e+00,  1.5838e+00]],

          [[-2.9064e-01, -3.3235e-01, -3.0300e-01,  ..., -1.4648e-01,
            -1.0491e-01, -8.5999e-02],
           [ 3.0795e-01, -3.6245e-01,  1.7980e-01,  ...,  2.4748e-01,
             8.4595e-02,  8.1217e-02],
           [-3.0408e-02, -2.1951e-02, -1.8527e-02,  ..., -2.8260e-03,
            -4.4726e-02, -4.8306e-02],
           ...,
           [ 3.6590e-02, -2.2649e-01, -5.1185e-02,  ..., -3.1439e-02,
            -4.5245e-01, -2.1810e-02],
           [ 1.1245e-01, -3.2933e-01,  8.5335e-03,  ...,  4.0620e-02,
             1.7344e-01, -3.1027e-01],
           [ 2.3234e-01,  2.2664e-01, -7.7205e-02,  ..., -2.2093e-01,
            -4.8593e-02,  2.4661e-02]],

          ...,

          [[-9.3261e-01, -7.6260e-01, -7.3332e-01,  ..., -7.7190e-01,
            -6.0499e-01, -5.9985e-01],
           [-8.5653e-01, -2.1887e-01, -5.4355e-01,  ..., -3.8094e-01,
            -5.8377e-01, -5.0749e-01],
           [-4.9705e-01, -1.9928e-01, -4.5073e-01,  ...,  1.2020e-03,
            -1.8645e-01, -1.2595e-01],
           ...,
           [-6.3847e-01, -3.3980e-01, -5.2701e-01,  ..., -3.0330e-01,
            -2.8109e-01, -1.6475e-01],
           [-6.8109e-01, -5.0743e-01, -5.2533e-01,  ..., -5.2017e-01,
            -6.2944e-01, -6.2879e-01],
           [-2.7850e-01, -6.1580e-01, -5.2393e-01,  ..., -5.9199e-01,
            -6.9086e-01, -6.9969e-01]],

          [[ 2.5167e-01,  4.3919e-02,  1.0668e-02,  ..., -7.8221e-02,
             2.1594e-01,  1.3642e-01],
           [ 2.4208e-01,  2.5012e-01,  2.5683e-01,  ...,  2.6633e-01,
            -5.7677e-02,  3.9456e-01],
           [ 3.7880e-01,  1.2930e-01, -3.5076e-02,  ...,  2.1143e-01,
             1.0497e-01,  4.1619e-01],
           ...,
           [ 3.1514e-01,  2.0994e-01,  1.2845e-01,  ...,  2.5211e-01,
             9.9327e-02,  1.8318e-01],
           [ 3.1479e-01,  1.2375e-01,  1.1239e-01,  ...,  2.0128e-01,
             1.0337e-01,  3.0883e-01],
           [ 3.8773e-01,  1.0302e-01,  2.2351e-01,  ..., -7.8994e-02,
             6.5807e-03, -1.0335e-01]],

          [[ 1.2423e-03, -1.0223e-01,  9.5612e-02,  ..., -9.4084e-02,
            -4.2660e-02,  7.5494e-02],
           [-5.1509e-01, -5.2124e-02, -2.5991e-01,  ..., -3.1778e-01,
            -2.3171e-02, -2.8931e-01],
           [-2.6891e-01, -7.5821e-02, -2.3992e-01,  ...,  1.3733e-01,
             2.6749e-02, -9.0869e-02],
           ...,
           [-1.9027e-01, -1.9019e-01, -1.7996e-01,  ..., -1.0913e-01,
             1.2905e-01, -9.7400e-02],
           [-4.8791e-01, -2.2153e-01, -1.8444e-01,  ..., -1.9465e-01,
            -2.4405e-01,  5.0802e-02],
           [-4.1235e-01, -4.6859e-01, -3.2017e-01,  ..., -2.3232e-01,
            -1.8305e-01, -4.1211e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.0551, -0.5440, -0.6146,  ...,  0.1801, -0.3121,  0.2243],
           [ 0.2878, -0.2937,  0.0180,  ..., -0.3412, -0.9847,  0.3291],
           [-0.2521, -0.2032,  0.6301,  ..., -0.9992, -1.3043,  0.1372],
           ...,
           [-0.4388, -2.0501, -0.9857,  ..., -1.4562, -1.1338, -0.2438],
           [-0.6619, -1.0800, -0.6420,  ..., -0.9531, -0.9155, -0.5830],
           [-0.9757, -0.4903, -0.7896,  ..., -0.0207,  0.0709, -0.3874]],

          [[-0.5626, -0.8982, -0.6051,  ..., -0.4369, -0.3069, -0.0818],
           [-0.8539, -1.2124, -1.1421,  ..., -1.0073, -1.0924, -0.4628],
           [-0.6097, -0.7027, -0.6621,  ..., -1.2089, -1.3066, -0.7056],
           ...,
           [-0.5803, -0.5633, -0.2863,  ..., -0.4478, -0.9250, -0.5883],
           [-0.6545, -0.8446, -0.5428,  ..., -0.3727, -0.2968,  0.0574],
           [-0.6146, -0.6378, -0.3994,  ..., -0.5582, -0.4681, -0.0292]],

          [[ 0.5193,  0.6878,  0.3467,  ...,  0.2677,  0.1245,  0.1870],
           [ 0.1295, -0.1289, -0.1073,  ...,  0.2351, -0.0065,  0.0047],
           [-0.1027, -0.4202, -0.5724,  ..., -0.3395, -0.0770,  0.0321],
           ...,
           [-0.0276,  0.5198,  0.3101,  ..., -0.0947, -0.1507, -0.2880],
           [-0.3556, -0.0265, -0.3138,  ...,  0.0869,  0.0704,  0.0083],
           [ 0.1238,  0.6825,  0.2532,  ..., -1.6974, -1.8882, -1.3618]],

          ...,

          [[ 0.8641,  0.6122,  0.5621,  ...,  0.4198,  0.8420,  0.1588],
           [ 0.6023,  0.1794,  0.3502,  ..., -0.0430,  0.5074, -0.0994],
           [ 0.1859,  0.1100,  0.5256,  ...,  0.5270,  1.0384, -0.0507],
           ...,
           [ 0.1272,  0.4405,  0.4913,  ...,  0.1201, -0.0852, -0.2832],
           [-0.0867,  0.4949,  0.4213,  ...,  0.3035,  0.3179, -0.0499],
           [ 0.1581,  0.7226,  0.5054,  ...,  0.4537,  0.4473,  0.4062]],

          [[-0.8049, -1.0994, -1.1123,  ..., -0.5673, -0.4921, -0.0453],
           [-0.5760, -0.7352, -0.4998,  ..., -0.4954, -0.2212,  0.0798],
           [-0.2649,  0.0948, -0.3051,  ..., -0.3232, -0.4791, -0.2479],
           ...,
           [-0.2960, -1.0196, -0.1207,  ..., -0.2136, -0.4638,  0.2480],
           [ 0.3223, -0.2110, -0.0877,  ..., -0.2047, -0.7102,  0.3825],
           [-0.4926, -0.8470, -0.7704,  ...,  0.5240,  0.2731,  0.9488]],

          [[ 0.7633,  0.5597,  0.6460,  ...,  0.8756,  0.7951,  0.4977],
           [ 1.0543,  0.6982,  1.0793,  ...,  1.1163,  1.2171,  0.3768],
           [ 0.6776,  0.4172,  0.4710,  ...,  1.1850,  1.4658,  0.7831],
           ...,
           [ 0.8799,  0.0338,  0.0235,  ...,  1.1350,  1.4108,  0.9740],
           [ 0.4392, -0.0140,  0.3868,  ...,  0.5046,  0.7000,  0.4616],
           [ 0.2597,  0.1772,  0.4445,  ...,  0.7297,  0.6433,  0.2840]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 5.0589e-02,  3.0239e-02, -6.5652e-02,  ...,  2.9136e-02,
             2.0472e-02,  3.3116e-02],
           [-4.3490e-02, -9.9013e-02, -1.4477e-01,  ..., -1.2799e-01,
            -1.2968e-01, -1.1374e-01],
           [-1.7633e-02,  8.8080e-02,  9.0812e-02,  ...,  8.1622e-02,
             4.6130e-02,  9.6210e-03],
           ...,
           [-3.2275e-02, -1.1952e-01, -8.8798e-02,  ..., -7.3871e-02,
             7.0270e-02,  9.4732e-02],
           [-3.6789e-04, -1.6536e-01, -1.2563e-01,  ..., -3.9373e-03,
            -1.1487e-04,  9.4181e-02],
           [-3.9141e-02, -6.5069e-02, -7.1126e-03,  ..., -1.3528e-03,
             2.9227e-02,  7.1437e-02]],

          [[ 4.9216e-01,  3.2340e-01,  3.7978e-01,  ...,  8.5515e-02,
             2.5145e-01,  2.8095e-01],
           [ 1.8159e-01, -1.3266e-01,  1.4115e-01,  ...,  1.5686e-02,
            -9.7150e-03, -4.6657e-02],
           [ 9.7674e-02, -1.9594e-01, -9.3590e-02,  ...,  1.4430e-01,
             3.0088e-01,  1.6222e-01],
           ...,
           [ 2.1367e-01,  1.3881e-01,  1.8991e-02,  ..., -3.0949e-02,
             3.1051e-01,  1.7396e-01],
           [ 1.1380e-01, -7.6312e-02, -1.8014e-02,  ...,  2.8777e-02,
             2.3656e-01,  7.9741e-02],
           [ 2.0087e-01,  1.1959e-01,  1.2988e-01,  ..., -1.5768e-01,
            -9.1760e-02, -1.4441e-01]],

          [[-1.3740e-01, -1.9611e-01, -2.0091e-01,  ..., -1.5659e-01,
            -1.2471e-01, -1.8021e-01],
           [-1.7893e-01, -2.0166e-01, -1.0795e-01,  ...,  5.2685e-02,
            -6.0237e-02, -8.4450e-02],
           [-1.2058e-01, -6.8945e-04, -3.3964e-03,  ...,  9.2430e-02,
            -1.5144e-02,  1.0227e-02],
           ...,
           [ 1.2023e-01,  9.7808e-02,  6.1309e-02,  ..., -1.4919e-01,
            -8.5181e-02,  1.0121e-01],
           [ 1.0048e-01, -7.8018e-03, -9.2056e-02,  ..., -1.8924e-01,
            -2.1661e-01, -7.0055e-02],
           [ 8.6329e-02, -5.4492e-02, -1.6985e-01,  ..., -2.0948e-01,
            -1.6376e-01, -2.4448e-02]],

          ...,

          [[-2.8329e-01, -3.6258e-01, -3.0192e-01,  ..., -9.3842e-02,
            -1.5187e-01, -2.5100e-02],
           [-1.6744e-01, -1.9852e-01, -2.5101e-01,  ...,  1.1434e-01,
             2.3056e-03,  9.7841e-03],
           [-2.3171e-02, -5.7884e-02, -1.3461e-01,  ..., -2.6371e-02,
            -1.9229e-01, -2.0811e-01],
           ...,
           [-6.9217e-02, -2.0768e-01, -2.8877e-02,  ..., -5.8385e-02,
             2.6056e-02,  4.0350e-02],
           [-8.4423e-02, -2.5802e-01, -2.9243e-02,  ..., -1.7626e-01,
            -2.2544e-01, -1.3741e-01],
           [-1.7964e-02, -1.3211e-02,  1.2998e-01,  ...,  4.6026e-02,
             4.3756e-02,  2.3945e-02]],

          [[-3.3565e-01, -5.4160e-01, -6.0805e-01,  ..., -3.8045e-01,
            -4.3757e-01, -3.0454e-01],
           [-1.4515e-01, -3.4559e-01, -4.1628e-01,  ..., -3.6153e-01,
            -3.3174e-01, -9.0514e-02],
           [-1.2495e-01, -3.9581e-01, -3.5128e-01,  ..., -2.6482e-01,
            -2.4520e-01, -1.8402e-01],
           ...,
           [-2.2884e-01, -6.1938e-01, -5.5678e-01,  ..., -6.8449e-01,
            -5.8617e-01, -2.8077e-01],
           [-3.3351e-01, -5.2314e-01, -4.2504e-01,  ..., -5.2789e-01,
            -6.0944e-01, -3.6275e-01],
           [-1.5605e-01, -3.6710e-01, -3.8210e-01,  ..., -4.0686e-01,
            -4.1307e-01, -1.7890e-01]],

          [[-2.1081e-01, -2.9553e-01, -3.2521e-01,  ..., -2.0666e-01,
            -1.2164e-01, -1.2524e-01],
           [-2.4101e-01, -2.0451e-01, -1.5815e-01,  ..., -3.4341e-02,
             4.8311e-02,  2.4075e-02],
           [-2.1997e-01, -2.2960e-01, -2.4427e-01,  ...,  2.7745e-02,
             6.6867e-02,  4.3925e-02],
           ...,
           [-7.6800e-03, -9.8346e-02, -2.0452e-01,  ..., -1.2589e-01,
             1.1875e-01,  7.0566e-02],
           [-8.1622e-02, -1.5807e-01, -2.0304e-01,  ..., -1.0088e-01,
             1.0701e-02, -1.2372e-02],
           [-9.3799e-02, -1.8981e-01, -2.0816e-01,  ..., -2.0537e-01,
            -1.6077e-01, -1.8046e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.1642,  0.6111,  0.6719,  ...,  0.3935,  0.4093,  0.1318],
           [-0.2679,  0.4372,  0.4897,  ...,  0.5854,  0.5598,  0.4889],
           [-0.0614,  0.0641, -0.0846,  ...,  0.9225,  0.8031,  0.8296],
           ...,
           [-0.0864, -0.0523, -0.1517,  ..., -0.3154, -0.4248,  0.7720],
           [-0.0210, -0.0107, -0.4515,  ..., -0.3691, -0.4755, -0.3588],
           [ 0.2661,  0.2514,  0.4845,  ...,  0.4435,  0.6367, -0.1002]],

          [[-0.2612, -0.2832, -0.6690,  ..., -0.6152, -0.5100, -0.5664],
           [-0.5795, -0.6801, -1.0398,  ..., -1.1175, -1.3070, -0.9341],
           [-0.4090, -0.7280, -0.6889,  ..., -0.6297, -1.0082, -0.7394],
           ...,
           [ 0.2380, -0.9826, -0.7688,  ..., -0.3479, -0.6661, -0.5269],
           [-0.8029, -1.2784, -1.1533,  ..., -0.5312, -1.0361, -0.8832],
           [-0.6589, -0.5647, -0.3576,  ..., -0.0677, -0.3550, -0.3389]],

          [[ 0.0297, -0.4572, -0.3457,  ...,  0.0052,  0.3190,  0.2809],
           [-0.2332, -0.5157, -0.3640,  ..., -0.4438, -0.3500, -0.5304],
           [-0.4940, -0.6755, -0.6056,  ..., -0.2920, -0.5922, -0.1759],
           ...,
           [ 0.5285,  0.7424, -0.5153,  ..., -0.4805, -0.3844,  0.4224],
           [ 0.3556, -0.6536, -0.6248,  ...,  0.0121,  0.2211,  0.0086],
           [ 0.4613, -0.0046, -0.2656,  ..., -0.1414, -0.0830, -0.6322]],

          ...,

          [[ 0.1395, -0.0938, -0.0249,  ..., -0.2357, -0.2905, -0.4863],
           [-0.0598,  0.2485,  0.3585,  ..., -0.4103, -0.3441, -0.6461],
           [-0.1429,  0.5415,  0.5160,  ..., -0.2196, -0.0928, -0.3425],
           ...,
           [ 1.1019, -0.0367, -0.5643,  ...,  0.0514,  0.1681,  0.1267],
           [ 0.9417, -0.0935, -0.6389,  ..., -0.0209,  0.0145,  0.0313],
           [ 0.5574,  0.2148, -0.5317,  ..., -0.3683, -0.4497, -0.1123]],

          [[ 0.0148,  0.0874, -0.7874,  ...,  0.4710,  0.6335, -0.4608],
           [ 0.2926,  0.2670, -0.9552,  ...,  0.2511,  0.6559, -0.3782],
           [ 0.5292, -0.1217, -0.6817,  ..., -0.1196,  0.1346, -0.6021],
           ...,
           [ 0.2037, -0.5333, -0.2021,  ...,  0.2152,  0.5675, -1.0983],
           [ 0.4190, -0.6143,  0.7062,  ...,  0.4490,  0.7827, -0.9449],
           [ 0.1773, -0.5181,  1.0329,  ...,  0.5269,  0.5063, -0.6873]],

          [[ 0.0336, -0.1246, -0.1963,  ..., -0.3679,  0.0404, -0.4178],
           [-0.3616, -0.3861, -0.0552,  ..., -0.0681, -0.0149, -0.3101],
           [-0.2323, -0.6257, -0.3293,  ...,  0.0823, -0.1018, -0.2396],
           ...,
           [ 0.2612, -0.2018, -0.5177,  ..., -0.7051, -0.2484, -0.2144],
           [ 0.2345, -0.1775, -0.4967,  ..., -0.4719, -0.0954, -0.0237],
           [-1.0177, -0.5352, -0.4000,  ..., -0.2615, -0.4057, -0.2122]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 1.3626e-03, -2.4663e-02,  4.6051e-02,  ..., -9.1565e-03,
             2.6631e-03, -2.3246e-02],
           [-1.3125e-01, -5.8948e-02,  7.5310e-02,  ..., -4.9859e-02,
            -2.3506e-02, -4.2598e-02],
           [ 6.0517e-03,  7.9837e-02,  1.3708e-01,  ..., -6.7412e-02,
            -1.6596e-01, -1.9063e-01],
           ...,
           [-1.0412e-01,  1.0787e-01,  1.9226e-02,  ..., -1.7789e-01,
            -1.4185e-01, -1.1365e-01],
           [ 1.9537e-01, -8.7989e-02, -1.1354e-01,  ..., -8.3751e-02,
            -8.7740e-02, -7.4591e-02],
           [ 1.0447e-01, -5.5854e-02, -5.7268e-02,  ..., -5.2313e-02,
             8.7574e-02,  4.5343e-02]],

          [[-4.4239e-02, -2.1504e-02,  4.3372e-03,  ..., -1.2835e-02,
            -7.4009e-02, -4.2044e-02],
           [-5.3044e-02, -8.7785e-02, -1.2914e-01,  ..., -4.7358e-02,
            -1.3473e-01, -6.2772e-02],
           [-9.3551e-02, -1.3260e-01, -1.3236e-01,  ...,  1.3536e-01,
             1.0653e-01,  1.2801e-01],
           ...,
           [-1.8869e-03, -6.6526e-02, -1.0954e-02,  ...,  5.1577e-02,
             2.0316e-01,  1.2561e-01],
           [-2.7441e-02, -9.5117e-02,  1.7368e-02,  ...,  1.2589e-01,
             2.3397e-01,  1.5138e-01],
           [-5.1650e-02, -5.0134e-02,  5.3820e-02,  ...,  1.3207e-02,
            -7.1995e-04, -9.8985e-02]],

          [[-1.3365e-02, -4.0225e-02,  1.1895e-02,  ..., -4.4649e-02,
            -2.2931e-02, -4.4239e-02],
           [ 8.7024e-03, -7.6718e-03,  5.0184e-02,  ...,  7.8267e-03,
            -2.9017e-02, -1.0779e-02],
           [ 6.0618e-02,  1.2400e-02,  1.8309e-02,  ..., -2.1703e-02,
            -4.2587e-02, -8.2061e-03],
           ...,
           [-4.6708e-03, -4.0856e-02, -1.2657e-01,  ..., -7.2252e-02,
             1.7713e-02,  5.6455e-02],
           [ 1.2032e-01,  8.5076e-03, -4.6789e-02,  ...,  7.3983e-03,
            -6.1203e-02,  9.5531e-04],
           [ 9.6192e-02,  3.0080e-02, -2.5663e-02,  ..., -2.1131e-02,
            -2.0930e-02,  5.3250e-03]],

          ...,

          [[ 8.0602e-02,  2.0411e-02,  6.5288e-02,  ...,  6.6563e-02,
             1.1606e-02,  2.7365e-02],
           [ 7.2081e-02,  8.9982e-02,  1.4145e-01,  ...,  4.2192e-02,
             5.2420e-02,  1.0945e-01],
           [ 5.4702e-02,  8.3627e-02,  3.0349e-02,  ...,  9.6957e-02,
             1.3886e-01,  1.6291e-01],
           ...,
           [ 1.2677e-01, -7.0860e-02,  4.2757e-02,  ...,  5.4127e-02,
             1.3381e-01,  1.5856e-01],
           [-6.8892e-02, -1.3785e-01,  6.4451e-02,  ...,  9.7933e-02,
             9.6460e-02,  1.6184e-01],
           [ 8.2498e-03, -7.8099e-04,  5.8352e-02,  ...,  4.5872e-03,
             3.9126e-02,  1.2256e-01]],

          [[-1.6818e-01, -1.2923e-01, -1.6857e-01,  ..., -5.4568e-02,
            -1.2155e-01, -1.6396e-01],
           [-4.4197e-01, -3.9939e-01, -3.0251e-01,  ..., -2.8055e-01,
            -3.1912e-01, -2.5067e-01],
           [-3.9235e-01, -3.4749e-01, -2.4425e-01,  ..., -3.1263e-01,
            -3.2038e-01, -2.7487e-01],
           ...,
           [-5.7203e-01, -3.7472e-01, -2.5183e-01,  ..., -3.1058e-01,
            -3.8692e-01, -3.0409e-01],
           [-7.4071e-01, -4.7059e-01, -2.6943e-01,  ..., -2.5183e-01,
            -3.5373e-01, -2.9527e-01],
           [-5.1734e-01, -3.9472e-01, -2.5330e-01,  ..., -4.2560e-01,
            -3.7086e-01, -3.3770e-01]],

          [[-6.9101e-03, -5.5174e-02, -5.2258e-02,  ..., -5.5020e-02,
            -3.8445e-02, -1.0077e-01],
           [-5.0044e-02, -3.1171e-02, -2.5651e-02,  ..., -5.5442e-02,
            -3.2126e-02, -1.1928e-01],
           [ 7.3592e-02,  8.5570e-02,  4.4706e-02,  ..., -2.2834e-02,
             5.2341e-02, -3.3763e-03],
           ...,
           [ 1.5344e-01, -1.2464e-01, -7.3227e-02,  ..., -9.2346e-02,
             1.2123e-01,  8.5718e-02],
           [ 6.0997e-02, -1.2332e-01, -1.0832e-02,  ..., -7.4599e-02,
            -7.8659e-02, -1.0594e-01],
           [-4.7824e-02, -7.0945e-02, -1.7477e-02,  ..., -8.5501e-02,
            -1.0939e-01, -1.5686e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-4.2873e-01, -4.6934e-01, -4.1325e-02,  ..., -3.2636e-02,
             7.4030e-02,  5.8232e-03],
           [-5.5538e-01, -1.0775e+00, -5.9274e-01,  ..., -9.1038e-01,
            -3.8420e-01, -3.6700e-01],
           [-4.9508e-01, -1.0233e+00, -2.1957e-01,  ..., -5.9944e-01,
            -3.6409e-01, -1.1305e-01],
           ...,
           [-6.3640e-01, -2.6598e-01, -2.8498e-01,  ..., -3.0316e-01,
            -3.0609e-01, -9.3499e-01],
           [ 1.0858e-01,  9.1596e-02, -3.1969e-01,  ..., -4.5866e-01,
            -2.9367e-01, -9.2299e-01],
           [ 6.3381e-01,  1.1834e-01, -1.6743e-01,  ..., -1.6575e-01,
            -1.6571e-01, -2.6300e-01]],

          [[ 4.0905e-03, -4.3001e-01, -5.7072e-01,  ...,  8.1292e-04,
            -6.4482e-01, -3.6637e-01],
           [-3.0681e-01,  1.5747e-02, -2.6038e-01,  ...,  3.0524e-01,
            -2.2313e-01,  4.0327e-02],
           [-5.6381e-01,  1.9786e-03, -1.3212e-01,  ...,  6.2308e-02,
            -5.2619e-01, -1.3217e-01],
           ...,
           [-7.0862e-01, -9.1414e-01, -2.5121e-01,  ..., -4.9914e-01,
            -7.5175e-01, -1.7616e-01],
           [-2.1418e-01, -4.5349e-01, -3.8520e-01,  ..., -3.2243e-01,
            -4.9149e-01, -3.4339e-01],
           [ 9.3637e-02, -8.7578e-02, -2.4526e-01,  ..., -1.3802e-01,
            -3.6111e-01, -5.0108e-01]],

          [[ 7.3805e-01,  1.4611e-01, -2.7105e-01,  ..., -1.2570e-01,
            -2.0609e-01, -7.4954e-02],
           [ 8.2128e-01,  3.0414e-01, -2.0269e-01,  ...,  1.8832e-01,
             3.5639e-01,  8.4530e-01],
           [ 5.3060e-01, -1.9782e-01, -3.9589e-01,  ..., -3.7223e-01,
            -3.4382e-01, -8.0846e-02],
           ...,
           [-5.9906e-01, -6.1805e-01, -3.0498e-01,  ..., -8.5905e-01,
            -1.4049e+00, -7.6847e-01],
           [-3.7451e-01, -3.8290e-01, -7.8562e-02,  ..., -2.9276e-02,
            -6.0355e-01, -3.1064e-01],
           [ 8.4362e-01,  5.4807e-01,  2.0263e-01,  ...,  3.1692e-01,
             1.3642e-01,  6.8857e-01]],

          ...,

          [[ 5.1337e-01,  3.9596e-01,  2.2522e-01,  ...,  4.1894e-01,
             1.0254e-01, -4.0375e-01],
           [-5.3977e-03, -3.4549e-01, -5.9793e-01,  ..., -1.7841e-01,
            -3.0228e-01, -8.4002e-01],
           [-2.3763e-01, -6.0266e-01, -3.2253e-01,  ..., -1.2647e-01,
            -2.9172e-01, -1.0146e+00],
           ...,
           [-8.1082e-02, -4.2886e-01,  3.3912e-01,  ..., -7.1773e-01,
            -3.2211e-01, -4.3716e-01],
           [ 3.6547e-02,  6.8812e-01, -3.2904e-01,  ..., -1.8101e-01,
            -4.1893e-01, -7.3784e-01],
           [-3.4927e-01,  1.3177e+00,  2.0435e-01,  ..., -1.9723e-02,
            -6.6064e-02, -2.3001e-01]],

          [[ 6.9231e-01, -1.0600e-01, -2.5855e-01,  ..., -4.6072e-01,
             9.7681e-01, -7.9610e-01],
           [-5.8889e-01, -1.1106e+00, -3.1060e-02,  ..., -3.3787e-01,
             5.3565e-01, -5.3625e-01],
           [-5.6028e-01, -7.4135e-01, -1.4226e-01,  ...,  4.8697e-02,
             1.7423e-01, -7.5924e-01],
           ...,
           [-5.8227e-01, -3.0304e-01, -1.0266e+00,  ..., -9.6372e-01,
            -5.2071e-01, -5.8520e-01],
           [-3.2737e-01, -5.4993e-01, -1.3333e+00,  ..., -5.4997e-01,
            -2.9026e-01, -8.1955e-01],
           [ 5.2538e-02,  5.0382e-01, -6.4723e-01,  ..., -3.1758e-01,
            -2.8657e-01, -6.7551e-01]],

          [[-9.3298e-01, -8.5845e-01, -1.0554e+00,  ..., -8.7959e-01,
            -7.9436e-01, -1.1912e+00],
           [-1.0732e+00, -9.6579e-01, -8.0460e-01,  ..., -1.0780e+00,
            -5.7669e-01, -1.0331e+00],
           [-1.1648e+00, -9.7872e-01, -5.6461e-01,  ..., -9.1402e-01,
            -4.6951e-01, -8.8273e-01],
           ...,
           [-1.5256e+00, -1.6750e-01,  2.1887e-01,  ..., -9.9437e-01,
            -7.7857e-01, -1.0885e+00],
           [-1.3656e+00,  2.4792e-01, -5.4816e-01,  ..., -1.2917e+00,
            -1.4464e+00, -1.6200e+00],
           [-7.4554e-01,  7.8284e-01, -6.8172e-02,  ..., -4.8101e-01,
            -8.3025e-01, -8.2073e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.0988,  0.1280,  0.0348,  ...,  0.0244,  0.0435,  0.0492],
           [-0.0232,  0.0532,  0.0509,  ..., -0.1039, -0.0123,  0.0517],
           [-0.0195, -0.0130,  0.0014,  ...,  0.0052,  0.1269,  0.0927],
           ...,
           [ 0.0612, -0.0726, -0.0816,  ..., -0.0858,  0.0101,  0.0488],
           [ 0.0246, -0.0265, -0.0734,  ..., -0.0315,  0.0121,  0.0841],
           [-0.0066, -0.0592, -0.0653,  ...,  0.0848,  0.0086,  0.0533]],

          [[ 0.0054,  0.0172,  0.0109,  ...,  0.0438, -0.0023,  0.0667],
           [ 0.0028,  0.0551, -0.0138,  ...,  0.0370, -0.0277,  0.0705],
           [-0.0194,  0.0452, -0.0279,  ...,  0.0167, -0.0203,  0.0328],
           ...,
           [ 0.0789, -0.0072, -0.0014,  ...,  0.0319, -0.0005,  0.0071],
           [ 0.0310, -0.0774,  0.0336,  ..., -0.0352, -0.0523,  0.0280],
           [ 0.0317, -0.0733,  0.0212,  ..., -0.0258, -0.0484,  0.0304]],

          [[ 0.0447,  0.0728,  0.0419,  ...,  0.0372,  0.0194,  0.0387],
           [ 0.0556,  0.0240,  0.0387,  ...,  0.0497,  0.0876,  0.0938],
           [-0.0082,  0.0247,  0.0094,  ..., -0.0385,  0.0543,  0.0157],
           ...,
           [-0.0077, -0.0965, -0.0529,  ...,  0.0185,  0.0220,  0.0010],
           [ 0.0037, -0.1304, -0.0403,  ...,  0.0028, -0.0538,  0.0186],
           [ 0.0494,  0.0494, -0.0566,  ..., -0.0360,  0.0525,  0.0500]],

          ...,

          [[ 0.1733,  0.1157,  0.0382,  ...,  0.0869,  0.1794,  0.1358],
           [-0.0386, -0.0362,  0.0066,  ...,  0.0206, -0.0064, -0.0312],
           [ 0.0028, -0.0682, -0.0012,  ..., -0.0308, -0.0326,  0.0439],
           ...,
           [ 0.1916,  0.0499, -0.0054,  ...,  0.0241,  0.0702,  0.0216],
           [ 0.1830,  0.0439,  0.0128,  ...,  0.0936,  0.0854,  0.0686],
           [ 0.1746,  0.0807, -0.0055,  ..., -0.0044,  0.0453,  0.0411]],

          [[-0.0622, -0.0869, -0.0834,  ..., -0.0582, -0.0993, -0.1090],
           [-0.0826, -0.2253, -0.1340,  ..., -0.1373, -0.1944, -0.1553],
           [-0.1094, -0.1520, -0.1378,  ..., -0.1157, -0.2341, -0.2295],
           ...,
           [-0.2469, -0.1926,  0.0333,  ..., -0.1980, -0.3922, -0.2547],
           [-0.0622, -0.0641,  0.0081,  ..., -0.1415, -0.1819, -0.0514],
           [-0.1384, -0.0867, -0.0205,  ..., -0.1600, -0.1566, -0.0787]],

          [[ 0.1696,  0.0830,  0.0843,  ...,  0.0816,  0.1086,  0.0569],
           [ 0.0366,  0.1129,  0.0805,  ...,  0.0165,  0.0319, -0.0460],
           [-0.0262,  0.0282,  0.0309,  ...,  0.0037,  0.0894,  0.0436],
           ...,
           [ 0.1452,  0.0994,  0.0504,  ...,  0.0656,  0.2144,  0.1010],
           [ 0.1647,  0.0498,  0.0299,  ..., -0.0269,  0.1108,  0.0720],
           [ 0.1522,  0.0643, -0.0155,  ...,  0.0290,  0.0490,  0.0259]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 4.1243e-01,  3.6304e-01,  8.8107e-01,  ...,  6.0127e-01,
             6.5288e-01,  9.4326e-01],
           [ 6.0697e-01,  6.4844e-01,  8.7361e-01,  ...,  6.2816e-01,
             6.8928e-01,  5.3948e-01],
           [-1.1460e-03,  4.0684e-01,  6.6968e-01,  ...,  2.4982e-01,
             3.0477e-01,  4.4353e-01],
           ...,
           [ 1.0008e+00,  3.6334e-01,  3.7838e-01,  ...,  6.2974e-02,
             1.3335e-01,  7.1240e-01],
           [ 9.4002e-01,  4.6166e-01,  3.9414e-01,  ...,  1.1289e-01,
             2.4865e-01,  1.6548e+00],
           [ 4.5392e-01,  3.8610e-01,  2.1027e-01,  ...,  3.0638e-01,
             4.6619e-01,  7.9911e-01]],

          [[-4.5250e-01, -2.0844e-01, -2.4178e-01,  ..., -2.8272e-01,
            -3.9787e-01, -8.4349e-01],
           [-8.0248e-01, -2.7057e-01, -4.7645e-01,  ..., -3.7947e-01,
            -1.8241e-01,  6.5178e-02],
           [-5.1991e-01, -6.0929e-01, -3.5325e-01,  ..., -5.2016e-01,
            -2.4186e-01, -6.5532e-01],
           ...,
           [-5.9643e-01,  5.7050e-01, -8.3123e-01,  ..., -4.4619e-01,
            -2.6789e-01, -5.2685e-01],
           [ 1.7776e-01,  1.0316e-01, -6.1159e-01,  ..., -8.4718e-01,
            -9.2070e-02, -6.6023e-01],
           [-4.6888e-01, -3.4122e-02, -8.5488e-02,  ..., -1.0417e+00,
            -1.8465e-02, -4.5028e-01]],

          [[ 1.3665e+00,  6.7283e-01,  8.2696e-01,  ...,  1.1734e+00,
             5.8562e-01,  1.1521e+00],
           [-3.5310e-01, -3.1397e-01,  1.0160e-01,  ...,  2.0190e-01,
            -1.2062e-01,  1.1574e-02],
           [ 1.8670e-01, -7.1362e-01, -2.7392e-01,  ..., -4.8404e-01,
            -5.5818e-01, -1.8868e-01],
           ...,
           [ 5.7915e-01,  4.0021e-01,  1.3172e-01,  ..., -2.4053e-01,
             3.9218e-02,  4.3768e-01],
           [ 4.3819e-01, -4.0679e-01, -2.1769e-03,  ..., -8.8953e-02,
             8.1186e-02,  3.6979e-01],
           [ 1.4249e+00, -2.3837e-02, -1.5262e-01,  ...,  5.2375e-01,
             2.9434e-01,  2.4603e-01]],

          ...,

          [[ 3.8155e-02, -1.6977e-01, -2.0032e-01,  ..., -5.6964e-01,
            -2.9177e-01, -9.4349e-02],
           [ 2.4736e-01,  1.3977e-01, -1.2234e-01,  ..., -4.4522e-01,
             6.4455e-02,  3.9772e-01],
           [-6.1862e-01, -2.3263e-01,  2.2372e-01,  ..., -1.3316e-01,
             1.3979e-01,  4.3874e-01],
           ...,
           [-4.4341e-02,  1.2667e-01, -1.4757e-01,  ..., -4.7259e-02,
            -8.4698e-02, -3.8401e-01],
           [ 5.8723e-02, -4.6699e-01,  2.9764e-01,  ...,  1.5851e-02,
             2.0578e-01, -2.7948e-01],
           [ 3.0847e-01, -7.3721e-01, -8.6126e-01,  ..., -1.1998e+00,
            -4.6212e-01,  1.3137e+00]],

          [[ 8.6156e-02, -2.0926e-01, -7.1230e-01,  ..., -1.3362e-01,
             3.1789e-01,  3.6001e-01],
           [-1.2724e-01, -1.2035e-01, -6.0503e-01,  ..., -1.7572e-01,
            -2.1856e-01, -1.0504e-01],
           [ 6.0878e-02,  2.0468e-01,  6.8006e-02,  ...,  7.5139e-01,
             2.5093e-02, -1.5781e-01],
           ...,
           [ 8.0393e-01,  6.9006e-02,  1.1580e+00,  ..., -6.4039e-01,
            -7.3785e-02,  6.7414e-01],
           [ 8.7700e-01, -4.3417e-01, -2.9335e-01,  ..., -1.4228e-01,
             2.3888e-01,  7.7920e-01],
           [ 5.2887e-01, -3.4151e-01, -3.1082e-01,  ...,  2.4944e-01,
            -8.7037e-02,  7.1645e-01]],

          [[ 1.2785e-01, -2.4757e-01,  4.0018e-01,  ..., -7.1277e-01,
            -4.4163e-01, -3.2978e-01],
           [-3.8121e-01, -4.8290e-01, -4.8577e-01,  ..., -1.7976e+00,
            -1.0235e+00, -8.7740e-01],
           [-4.0046e-01, -3.5255e-01,  2.1916e-02,  ..., -1.6129e+00,
            -1.1431e+00, -9.3650e-01],
           ...,
           [-1.4788e+00, -6.9077e-01, -4.5148e-01,  ..., -8.8217e-01,
            -9.8117e-01, -1.0065e+00],
           [-1.0895e+00, -9.9224e-01, -6.8925e-01,  ..., -5.7167e-01,
            -6.9166e-01, -1.7308e+00],
           [-1.4956e+00, -9.4706e-01, -8.6554e-01,  ..., -1.4528e+00,
            -7.2765e-01, -1.3770e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.1236, -0.0602, -0.1390,  ..., -0.4963, -0.4020, -0.1198],
           [-0.0350, -0.0439, -0.2125,  ..., -0.0424,  0.0160,  0.1509],
           [-0.2220, -0.1353, -0.3867,  ..., -0.1576, -0.0601, -0.0723],
           ...,
           [-0.1874, -0.1648, -0.3391,  ...,  0.0121, -0.2412, -0.3454],
           [-0.1325, -0.4435, -0.3661,  ..., -0.3154, -0.1932, -0.2613],
           [-0.3495, -0.1867, -0.0766,  ..., -0.2538, -0.1465, -0.1136]],

          [[-0.3884, -0.2835, -0.3478,  ..., -0.3397, -0.6106, -0.5631],
           [-0.2955, -0.1269,  0.0024,  ..., -0.0864, -0.4283, -0.4903],
           [-0.0700, -0.0156, -0.0923,  ...,  0.1401, -0.0755, -0.4042],
           ...,
           [ 0.1401, -0.3010, -0.3625,  ..., -0.2610, -0.4198, -0.2596],
           [-0.1279, -0.3806, -0.5162,  ..., -0.3461, -0.4323, -0.2634],
           [-0.2910, -0.3711, -0.3404,  ..., -0.1880, -0.1061, -0.1619]],

          [[-0.2050, -0.5653, -0.7059,  ..., -0.5888, -0.4452, -0.2084],
           [-0.3620, -0.8297, -0.5641,  ..., -0.7035, -0.6533, -0.4250],
           [-0.2378, -0.5462,  0.0864,  ..., -0.2322, -0.3490, -0.2139],
           ...,
           [-0.6504, -0.7616,  0.0459,  ...,  0.2952,  0.3382,  0.0308],
           [-0.6238, -0.5782,  0.0213,  ...,  0.0991, -0.1207,  0.2721],
           [-0.2482, -0.3077,  0.1315,  ..., -0.0717, -0.3099,  0.0063]],

          ...,

          [[ 0.0926, -0.0044, -0.0968,  ...,  0.0761, -0.0428,  0.1569],
           [ 0.1673,  0.0863, -0.1966,  ...,  0.2720,  0.1123,  0.2954],
           [ 0.1487,  0.1765,  0.2782,  ...,  0.0290, -0.0423,  0.4044],
           ...,
           [ 0.1914, -0.1436, -0.2107,  ..., -0.1952,  0.0748, -0.0246],
           [-0.2369,  0.0786, -0.0242,  ..., -0.1436, -0.2877,  0.1694],
           [-0.0514,  0.2114,  0.3048,  ...,  0.1482, -0.3507,  0.4003]],

          [[-0.1723,  0.0760,  0.0721,  ...,  0.0341,  0.1266, -0.2085],
           [-0.2347, -0.3643,  0.0663,  ..., -0.3313, -0.1482, -0.2671],
           [-0.3051, -0.3792,  0.2800,  ..., -0.1511, -0.1272, -0.2918],
           ...,
           [ 0.0721,  0.0340,  0.2539,  ...,  0.4027,  0.0683, -0.3045],
           [ 0.0758, -0.1852, -0.1356,  ...,  0.1785,  0.0511, -0.0705],
           [-0.2175, -0.0551, -0.2782,  ...,  0.0408, -0.0052, -0.0972]],

          [[ 0.2038,  0.0062,  0.1736,  ...,  0.1367,  0.2460,  0.1823],
           [ 0.1573, -0.2326,  0.0208,  ..., -0.3015,  0.0737,  0.1335],
           [ 0.1387,  0.0569,  0.3607,  ..., -0.0596,  0.1768,  0.2967],
           ...,
           [ 0.7866,  0.5105,  0.4362,  ...,  0.0980,  0.3943,  0.5658],
           [ 0.5503,  0.0597,  0.1589,  ..., -0.0902,  0.3756,  0.5093],
           [ 0.1137, -0.0809, -0.0159,  ...,  0.1156,  0.3735,  0.4709]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-3.2580e-02,  4.6716e-03, -6.6709e-02,  ..., -4.7522e-03,
            -2.2099e-03,  9.0466e-02],
           [-1.6302e-01, -2.9018e-02, -2.1720e-01,  ..., -4.3875e-02,
             1.0886e-02,  2.8372e-02],
           [-2.5479e-01, -1.4047e-01, -1.7275e-01,  ...,  8.0531e-02,
             1.9334e-01,  1.5276e-02],
           ...,
           [-2.1139e-01, -1.4825e-01, -4.9402e-03,  ...,  9.2946e-02,
            -1.0612e-01, -1.7040e-01],
           [-2.0970e-01, -1.6195e-01, -1.7520e-01,  ..., -6.7448e-02,
             4.9452e-02, -1.1551e-01],
           [-2.7232e-01, -9.8204e-02, -8.8646e-02,  ...,  8.4115e-03,
             1.1206e-01, -1.0140e-02]],

          [[ 4.8812e-02, -6.0470e-02, -5.8316e-02,  ..., -8.2867e-02,
            -9.3440e-02, -7.1303e-02],
           [-1.4589e-01, -1.4611e-01, -1.8509e-01,  ...,  7.8155e-02,
            -5.8147e-03, -1.0605e-01],
           [-7.0111e-02, -2.2644e-01, -8.3414e-02,  ...,  2.0901e-01,
             8.1771e-02, -1.6470e-02],
           ...,
           [ 1.8304e-01, -8.1817e-03,  6.9792e-02,  ..., -1.0695e-01,
            -1.7610e-01, -1.3897e-01],
           [ 2.4655e-01, -1.4628e-01, -2.1027e-01,  ..., -2.4190e-01,
             8.1670e-03,  2.2009e-01],
           [ 1.0761e-02, -2.2890e-01, -2.6206e-01,  ..., -1.8678e-01,
             5.0541e-02,  1.7424e-01]],

          [[-6.4699e-01, -6.5046e-01, -6.4946e-01,  ..., -6.3103e-01,
            -5.8418e-01, -6.0015e-01],
           [-3.5077e-01, -2.5295e-01, -3.1632e-01,  ..., -2.6033e-01,
            -3.3463e-01, -4.6449e-01],
           [-3.1468e-01, -3.2959e-01, -2.4537e-01,  ..., -3.4004e-01,
            -2.1492e-01, -1.9570e-01],
           ...,
           [-5.4013e-01, -2.5121e-01, -1.6403e-01,  ..., -1.5129e-02,
            -2.1977e-01, -2.5057e-01],
           [-3.8462e-01, -2.4791e-01, -2.3765e-01,  ..., -2.2953e-01,
            -4.0156e-01, -2.9487e-01],
           [-8.4561e-01, -1.3793e-01, -1.1995e-01,  ..., -3.2368e-01,
            -1.9963e-01, -2.4796e-01]],

          ...,

          [[ 5.7024e-01,  6.6056e-01,  9.5901e-02,  ..., -2.4350e-02,
             2.7821e-01,  1.2417e-01],
           [-7.0457e-02,  3.7125e-02, -8.5546e-02,  ..., -7.4320e-02,
            -1.3726e-01,  6.1165e-03],
           [-9.4908e-02, -4.6271e-02,  2.8854e-02,  ..., -4.7003e-02,
             1.2840e-01, -2.9733e-02],
           ...,
           [-1.0554e-01, -6.0221e-02, -1.7736e-01,  ...,  7.9574e-03,
            -2.8799e-01, -2.2224e-01],
           [-5.7899e-02, -1.0701e-01, -1.7920e-01,  ..., -1.4876e-01,
            -2.7093e-01, -7.9749e-02],
           [-4.4996e-02, -2.9580e-01,  2.2398e-01,  ..., -2.4354e-01,
            -2.1907e-01, -8.4004e-02]],

          [[ 3.4024e-01, -1.5116e-01, -7.1770e-02,  ..., -1.6114e-01,
             9.6471e-02,  3.4851e-01],
           [-3.5924e-01, -1.8450e-01,  9.4673e-02,  ..., -3.2239e-01,
            -3.4507e-01, -7.4684e-02],
           [-2.6030e-01, -2.0770e-01, -3.4150e-01,  ..., -2.8970e-01,
             2.1401e-01, -9.7496e-02],
           ...,
           [ 1.9954e-01, -2.0608e-01, -1.2124e-01,  ...,  1.2212e-01,
             9.7532e-02, -3.5990e-01],
           [ 4.1975e-01, -2.3223e-01, -2.0307e-01,  ..., -3.8297e-01,
            -3.5574e-01, -6.8504e-02],
           [ 1.8114e-04, -2.0356e-01,  1.0351e-01,  ..., -2.3819e-01,
            -1.4674e-01, -1.1833e-01]],

          [[ 3.0758e-01,  2.7873e-01,  5.4953e-02,  ...,  1.4411e-01,
             1.1629e-01,  1.0042e-01],
           [ 1.7667e-01, -1.8428e-01,  5.3541e-02,  ...,  1.0744e-01,
             3.9272e-02,  1.7413e-01],
           [ 2.0926e-03,  1.1734e-01,  4.6211e-02,  ..., -2.7263e-01,
             5.6385e-03, -6.9367e-02],
           ...,
           [ 2.7898e-01,  9.0060e-02,  1.0426e-01,  ..., -5.5958e-02,
            -9.9089e-02,  1.5218e-01],
           [ 7.2136e-02, -2.8248e-02,  5.7768e-02,  ..., -1.7842e-01,
            -4.6636e-02,  3.7414e-01],
           [ 3.3351e-01, -1.6085e-01,  6.2398e-02,  ..., -2.3159e-02,
             2.2459e-01,  1.4017e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.8268,  0.4441,  0.3694,  ...,  0.4115,  0.7633,  0.8978],
           [-0.0194, -0.7248, -0.6000,  ..., -0.7206, -0.5846, -0.1153],
           [ 0.1886, -0.4891, -0.5042,  ..., -0.5467, -0.4565, -0.1056],
           ...,
           [ 1.0802,  0.5223,  0.2821,  ..., -0.1917, -0.3600, -0.3545],
           [ 1.0232,  0.4767,  0.1597,  ..., -0.3930, -0.4350, -0.0377],
           [ 1.0075,  0.7341,  0.2484,  ...,  0.2522, -0.0150,  0.2700]],

          [[-0.5701, -0.7030, -0.7707,  ..., -0.6556, -0.8253, -0.5767],
           [-0.5188, -0.8589, -0.7814,  ..., -0.9747, -1.1042, -0.6838],
           [-0.5817, -0.6517, -0.4354,  ..., -0.3231, -0.6983, -0.5580],
           ...,
           [-0.5730, -0.7506, -0.6265,  ..., -0.5238, -0.5434, -0.4181],
           [-0.3847, -0.6073, -0.8639,  ..., -0.4829, -0.4861,  0.0185],
           [-0.4507, -0.4574, -0.5627,  ..., -0.2748, -0.5572, -0.3460]],

          [[ 0.1596,  0.0046, -0.2229,  ...,  0.2172,  0.4685,  0.4965],
           [ 0.2181,  0.2517,  0.3000,  ..., -0.0341, -0.2611, -0.2299],
           [ 0.4062,  0.3518,  0.4570,  ...,  0.0234, -0.1292, -0.0786],
           ...,
           [-0.3141, -0.1117,  0.1558,  ...,  0.0288, -0.2321, -0.1655],
           [ 0.0597, -0.0387,  0.2186,  ...,  0.3252,  0.3253,  0.2932],
           [ 0.0218, -0.1647, -0.0439,  ...,  0.1506,  0.2616,  0.2033]],

          ...,

          [[-0.3023, -0.5082, -0.4832,  ..., -0.8931, -0.7944, -0.5214],
           [-0.4516, -0.2861, -0.5033,  ..., -0.8971, -1.2599, -0.8366],
           [-0.5091, -0.2623, -0.6127,  ..., -0.9415, -1.1568, -0.9192],
           ...,
           [-0.8310, -1.0234, -1.1779,  ..., -0.3845, -0.4947, -0.1517],
           [-0.9886, -0.7029, -0.4522,  ..., -0.5521, -0.8839, -0.6843],
           [-0.3870, -0.2183, -0.0513,  ..., -0.3436, -0.6146, -0.6278]],

          [[ 0.0665,  0.0452, -0.1549,  ...,  0.1974, -0.2540, -0.0679],
           [-0.3426,  0.0577, -0.8722,  ..., -0.5749, -0.8167, -0.1882],
           [-0.7388,  0.0540, -0.1547,  ..., -0.7001, -1.1010, -0.0070],
           ...,
           [-0.4458, -0.0720, -0.0663,  ..., -0.1730, -0.5392, -0.0321],
           [ 0.0398,  0.3934, -0.1953,  ..., -0.4248, -0.6574, -0.3950],
           [-0.1572,  0.5568,  0.0729,  ..., -0.4862, -0.5172, -0.2908]],

          [[-0.9220, -1.2343, -0.1687,  ..., -0.2934, -0.1706, -0.1749],
           [-0.9835, -1.1848, -0.7574,  ..., -0.2448, -0.1289,  0.0472],
           [-1.0677, -1.1468, -0.6967,  ..., -0.5125, -0.0795,  0.3138],
           ...,
           [-0.1524, -0.4937, -0.6800,  ...,  0.0790, -0.0247, -0.2594],
           [-0.4430, -0.3362, -0.4801,  ..., -0.0096, -0.7177, -0.2634],
           [-0.3126, -0.4949, -0.1230,  ..., -0.0975, -0.8262, -0.2739]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.0891, -0.0343, -0.0670,  ...,  0.0482,  0.0205,  0.0690],
           [ 0.0079, -0.0992, -0.1780,  ..., -0.0172,  0.0695,  0.0783],
           [-0.1336, -0.1911, -0.1928,  ..., -0.0254, -0.0152, -0.0049],
           ...,
           [-0.0549, -0.0683, -0.1709,  ..., -0.0291, -0.0146, -0.0118],
           [-0.0996, -0.1211, -0.2715,  ...,  0.0197, -0.0492, -0.0516],
           [-0.0667, -0.0486, -0.1591,  ..., -0.0957, -0.0715, -0.1130]],

          [[-0.0414, -0.0187, -0.0580,  ..., -0.0443, -0.0396, -0.0592],
           [-0.0774, -0.0847, -0.1103,  ..., -0.0007,  0.0389,  0.0294],
           [-0.0698, -0.0738, -0.0786,  ..., -0.0846, -0.1175, -0.1000],
           ...,
           [-0.0121, -0.1405, -0.0540,  ..., -0.1062, -0.1952, -0.1241],
           [-0.0941, -0.1619, -0.0185,  ..., -0.2264, -0.1543, -0.0991],
           [-0.0718, -0.0770,  0.0399,  ..., -0.1147,  0.0332,  0.0185]],

          [[-0.0967, -0.1833, -0.1092,  ..., -0.2087, -0.1302, -0.0594],
           [-0.1555, -0.2623, -0.1557,  ..., -0.2220, -0.2110, -0.1157],
           [-0.1416, -0.1988, -0.1886,  ..., -0.1003, -0.1234, -0.0743],
           ...,
           [-0.1254, -0.2000, -0.1661,  ..., -0.0280, -0.0018, -0.0108],
           [-0.1081, -0.1427, -0.1374,  ..., -0.1261, -0.1929, -0.0767],
           [-0.0184, -0.0225, -0.0251,  ..., -0.0505, -0.0375,  0.0290]],

          ...,

          [[-0.2503, -0.2906, -0.2482,  ..., -0.0599, -0.1782, -0.1961],
           [-0.2494, -0.3674, -0.2781,  ..., -0.1314, -0.1071, -0.1463],
           [-0.0903, -0.1135, -0.0733,  ..., -0.0469,  0.0529, -0.0597],
           ...,
           [-0.1460, -0.1257, -0.0230,  ...,  0.0024,  0.0556, -0.0626],
           [-0.1900, -0.0814, -0.0467,  ..., -0.0095, -0.0219, -0.0222],
           [-0.1668, -0.0776, -0.0633,  ..., -0.0105, -0.1150, -0.0501]],

          [[-0.0462, -0.0058, -0.0168,  ..., -0.0012, -0.0573,  0.0469],
           [-0.1890, -0.1472, -0.0599,  ..., -0.1150, -0.0626,  0.0218],
           [-0.0405, -0.0680,  0.0672,  ..., -0.0256,  0.0763,  0.0875],
           ...,
           [ 0.0059, -0.0371, -0.0750,  ...,  0.0666,  0.0448, -0.0269],
           [ 0.0553, -0.0393, -0.1183,  ...,  0.0850,  0.0264, -0.0066],
           [ 0.0347, -0.0798, -0.1994,  ...,  0.0171, -0.0586, -0.0245]],

          [[-0.0178, -0.0318, -0.0838,  ...,  0.0773,  0.0054, -0.0698],
           [-0.0545, -0.0315, -0.0842,  ...,  0.0640, -0.0761, -0.1300],
           [-0.0559, -0.0413, -0.0776,  ..., -0.1542, -0.1934, -0.1077],
           ...,
           [ 0.0022,  0.1460,  0.1342,  ..., -0.1196, -0.1491, -0.1003],
           [ 0.0401,  0.1450,  0.1216,  ..., -0.0765, -0.1312, -0.1566],
           [ 0.0010,  0.0654,  0.0558,  ..., -0.0464, -0.0703, -0.1186]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.2521, -0.8738, -0.6532,  ...,  0.0576, -0.2081, -0.3561],
           [-0.3011, -0.5276, -0.6430,  ..., -0.1986, -0.4507, -0.3705],
           [-0.4933, -0.8762, -1.2042,  ...,  0.0192, -0.5263, -0.4188],
           ...,
           [-0.4822, -0.5530, -1.0430,  ..., -0.2959, -0.1074, -0.3416],
           [-0.5835, -0.6165, -0.9733,  ..., -1.1879, -0.3531, -0.4250],
           [-0.6776, -0.6156, -0.5577,  ..., -0.5834, -0.3649, -0.2203]],

          [[ 0.0177, -0.1427, -0.3212,  ..., -0.2198, -0.2059,  0.0977],
           [-0.2004, -0.5116, -0.3690,  ..., -0.4446, -0.8544, -0.5728],
           [-0.2213, -0.3730, -0.3643,  ..., -0.2383, -0.4089, -0.3251],
           ...,
           [-0.1507, -1.1372, -0.9870,  ..., -0.6122, -0.4332, -0.1330],
           [-0.3038, -0.9152, -0.8302,  ..., -0.3705, -0.4816, -0.3446],
           [-0.4832, -0.5504, -0.2201,  ..., -0.2456, -0.3247, -0.3117]],

          [[-0.0672, -0.1554,  0.0552,  ..., -0.2345, -0.7497, -0.6175],
           [ 0.2831,  0.0600, -0.0768,  ..., -0.3010, -0.7343, -0.7601],
           [-0.1145, -0.3830, -0.6809,  ..., -0.5276, -0.5555, -0.6247],
           ...,
           [-0.2057, -0.7569, -0.5689,  ..., -0.6663, -0.5145,  0.0535],
           [-0.6855, -0.7507, -0.1757,  ..., -0.1187, -0.5039,  0.0934],
           [-0.4590, -0.5180, -0.2126,  ..., -0.4002, -0.3137, -0.5877]],

          ...,

          [[-0.5173, -0.7319, -0.5628,  ..., -0.7071, -0.6873, -0.4385],
           [-0.7093, -1.0123, -0.5945,  ..., -0.5060, -0.6159, -0.7295],
           [-0.5527, -0.6056, -0.2464,  ..., -0.7749, -0.8456, -0.8498],
           ...,
           [-0.9676, -1.5211, -1.0507,  ..., -0.5427, -0.3854, -0.7520],
           [-0.9118, -1.0320, -0.8958,  ..., -0.7115, -0.5381, -0.4616],
           [-0.5716, -0.8103, -0.7555,  ..., -0.4182, -0.5253, -0.5415]],

          [[-0.5313, -0.3614, -0.5246,  ..., -0.6295, -0.5290, -0.4729],
           [-0.2976, -0.3723, -0.5166,  ..., -0.8591, -0.6088, -0.5045],
           [-0.7066, -0.2102, -0.0457,  ..., -0.8686, -0.8044, -0.7096],
           ...,
           [-0.9559, -0.4253, -0.2284,  ..., -0.5182, -0.3698, -0.6497],
           [-1.1067, -0.8729, -0.9031,  ..., -0.4912, -0.2269, -0.6201],
           [-0.8432, -0.5654, -0.6099,  ..., -0.4652, -0.3318, -0.4693]],

          [[ 0.1028,  0.1567,  0.1607,  ...,  0.8193,  0.1068,  0.1878],
           [ 0.0629,  0.0170,  0.6012,  ...,  0.4266,  0.1424,  0.2063],
           [ 0.1214,  0.1671,  1.2869,  ...,  0.3030,  0.1830,  0.3461],
           ...,
           [-0.1943,  0.3957, -0.0051,  ...,  0.3658,  0.8822,  0.6292],
           [ 0.2586,  0.7748, -0.0087,  ...,  0.5417,  0.2212, -0.0846],
           [ 0.5294,  0.7278,  0.1215,  ...,  0.1824, -0.2166, -0.2289]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 5.9690e-02,  8.1791e-02,  8.8460e-02,  ...,  1.2052e-02,
            -2.9440e-02,  4.1868e-02],
           [ 2.0751e-01,  1.9978e-01,  3.1553e-01,  ...,  5.5059e-02,
             7.1169e-02,  7.4423e-02],
           [ 9.4788e-02,  9.9758e-02,  5.5432e-02,  ..., -2.8651e-02,
            -9.6179e-02, -2.8936e-02],
           ...,
           [-5.7275e-02, -6.1507e-02, -2.1981e-02,  ...,  5.6889e-02,
             4.3233e-02,  8.5275e-02],
           [-7.9141e-02, -2.5249e-02, -6.8972e-02,  ...,  3.9908e-02,
            -6.9416e-02,  2.6843e-03],
           [ 2.1747e-02,  1.2513e-01,  7.1213e-02,  ..., -2.8586e-02,
            -1.3100e-02, -2.4738e-02]],

          [[-2.7763e-02, -1.1040e-01, -5.0566e-02,  ..., -7.8674e-02,
            -3.8930e-02,  2.7603e-02],
           [-4.1623e-02, -9.8588e-02, -4.6023e-02,  ..., -5.2057e-02,
            -9.7615e-02, -7.2089e-02],
           [-5.5634e-02, -9.4488e-02, -5.6073e-02,  ..., -2.9765e-02,
            -1.4687e-01, -1.0436e-01],
           ...,
           [ 3.8538e-02, -3.3256e-02, -2.8461e-02,  ..., -8.6775e-03,
            -6.4014e-02, -6.6953e-02],
           [-1.2763e-02, -9.8569e-02, -8.2613e-02,  ..., -2.2940e-02,
            -7.3775e-02, -8.6286e-02],
           [-8.1326e-02, -1.1877e-01, -8.2915e-02,  ..., -2.1756e-02,
            -5.5721e-02, -5.7234e-02]],

          [[ 5.3683e-02, -7.5098e-02, -1.4165e-01,  ..., -1.2710e-01,
            -3.9675e-02, -2.3752e-03],
           [-9.5284e-02, -1.8529e-01, -1.0618e-01,  ..., -9.2752e-02,
            -9.2028e-03, -2.8579e-02],
           [ 1.0723e-02, -2.3845e-02,  5.8893e-02,  ..., -8.4111e-02,
            -1.0929e-02, -3.8908e-02],
           ...,
           [-1.2620e-01, -1.2239e-01, -6.0111e-02,  ...,  1.9814e-02,
            -7.4255e-02, -1.9455e-02],
           [-1.8121e-01, -1.2122e-01,  3.9839e-02,  ..., -8.2767e-02,
            -1.8340e-01, -1.2343e-01],
           [-9.4623e-02, -2.1298e-02,  9.8767e-02,  ..., -1.3415e-01,
            -1.4433e-01, -9.5447e-02]],

          ...,

          [[-1.4666e-01, -2.1602e-01, -9.7738e-02,  ..., -6.1896e-02,
            -5.6454e-02, -5.9906e-02],
           [ 1.9899e-02,  5.1323e-03,  1.3906e-02,  ...,  1.5137e-02,
             8.3006e-02,  3.2444e-02],
           [-3.5191e-02, -5.4830e-02, -2.9264e-04,  ..., -5.2180e-02,
            -3.4717e-02, -2.7403e-02],
           ...,
           [ 2.9712e-02,  1.5094e-02, -1.5655e-02,  ...,  1.8559e-02,
            -1.6583e-02, -1.3607e-02],
           [ 1.0858e-02, -7.2396e-02, -3.3979e-02,  ..., -1.7926e-02,
            -4.6190e-02, -5.3141e-02],
           [-3.7275e-02, -9.7014e-02,  1.0602e-02,  ..., -5.7990e-02,
            -2.2373e-02, -1.8351e-02]],

          [[ 2.2787e-03,  7.1163e-02,  1.6819e-02,  ...,  9.2681e-02,
             1.1505e-01,  2.3904e-02],
           [ 4.7862e-02,  1.1637e-01,  9.4310e-02,  ...,  1.1634e-01,
             1.8279e-01,  5.3646e-02],
           [-1.1675e-01, -7.2314e-02,  3.4619e-02,  ..., -6.8577e-03,
             2.9380e-02, -2.8520e-02],
           ...,
           [ 2.4590e-02,  4.2514e-02,  6.2918e-02,  ..., -2.6829e-02,
            -1.1360e-02, -9.5783e-02],
           [-3.6852e-02, -6.3597e-02, -6.8385e-02,  ..., -7.8031e-02,
            -2.6182e-02, -3.7326e-02],
           [-2.0531e-02, -4.0638e-02, -1.0545e-01,  ..., -3.3283e-02,
            -1.7214e-02, -8.7905e-03]],

          [[ 1.4262e-01,  1.8939e-01,  4.6325e-02,  ...,  5.6332e-03,
            -1.7036e-02,  8.5665e-02],
           [ 8.7077e-02,  1.5266e-01,  1.1495e-02,  ...,  2.6765e-02,
            -7.1896e-02,  1.6017e-02],
           [ 2.0477e-02,  3.8997e-02, -5.1062e-02,  ..., -3.8573e-02,
            -1.3501e-01, -4.8769e-02],
           ...,
           [ 6.8783e-02,  8.6703e-02,  3.7755e-02,  ..., -1.4440e-02,
            -4.4981e-02,  4.6754e-02],
           [ 1.5211e-01,  1.4666e-01,  1.0651e-01,  ...,  6.6362e-03,
            -2.3379e-02,  2.2118e-02],
           [ 1.5475e-01,  1.1244e-01,  5.5967e-02,  ...,  2.7780e-02,
             5.5084e-02,  3.2660e-02]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.4845,  0.0795, -0.2955,  ..., -0.7637, -0.7079, -0.2085],
           [ 0.0782, -0.6192, -0.6169,  ..., -0.5698, -0.6532, -0.1965],
           [-0.1840, -0.7758, -0.5835,  ...,  0.4777, -0.3596, -0.5760],
           ...,
           [-0.4258, -0.6596, -0.4395,  ..., -1.2278, -1.2216, -0.2326],
           [-0.7650, -0.4104, -0.0632,  ..., -1.1424, -1.1432, -0.1594],
           [-0.4026,  0.0630,  0.2351,  ..., -0.2858, -0.3669,  0.2083]],

          [[ 0.6445,  0.0482,  0.4370,  ..., -0.4058,  0.3200,  0.3312],
           [-0.1693, -0.6156, -0.5838,  ..., -0.3975,  0.0058,  0.0147],
           [ 0.0864, -0.4110, -0.5953,  ..., -0.2295, -0.2403, -0.0342],
           ...,
           [ 0.1388, -0.2530,  0.2279,  ..., -0.3627, -0.2018,  0.1189],
           [ 0.4692, -0.2895,  0.3101,  ..., -0.4736, -0.0019,  0.2250],
           [ 0.3214, -0.2667,  0.1720,  ...,  0.0590,  0.4691,  0.3283]],

          [[-0.1366, -0.6080, -0.5196,  ...,  0.2603, -0.2752, -0.2446],
           [-0.2837, -1.1259, -0.9564,  ...,  0.0706, -0.4083, -0.1435],
           [-0.0544, -0.5661, -0.5452,  ..., -0.0945, -0.1330, -0.0922],
           ...,
           [-0.0720, -0.4958, -0.2366,  ...,  0.2443, -0.0310,  0.0820],
           [-0.0304, -0.4755, -0.2775,  ...,  0.1328, -0.2953, -0.1548],
           [ 0.0987, -0.4032, -0.2415,  ..., -0.2818, -0.3963, -0.1066]],

          ...,

          [[ 0.3596,  0.2900,  0.1245,  ...,  0.1821,  0.4045,  0.2309],
           [ 0.0965, -0.0323, -0.2414,  ...,  0.0500,  0.1201,  0.0346],
           [-0.0176,  0.1297, -0.1019,  ..., -0.3010, -0.2776, -0.0885],
           ...,
           [-0.0956, -0.2160,  0.2131,  ...,  0.3172,  0.2728,  0.4095],
           [-0.0683,  0.0664,  0.2848,  ...,  0.4504,  0.4178,  0.0137],
           [ 0.1541,  0.3728,  0.4992,  ...,  0.1085,  0.6247,  0.3332]],

          [[-0.1562, -0.6261, -0.3393,  ..., -0.0509,  0.1059, -0.1578],
           [-0.3468, -0.7332, -0.9827,  ...,  0.0946, -0.1183, -0.4941],
           [-0.3986, -0.8786, -1.0388,  ..., -0.1285,  0.0028, -0.2330],
           ...,
           [-0.5062, -0.3236,  0.2055,  ..., -0.7337, -0.4309,  0.0667],
           [-0.6180, -0.3479, -0.0436,  ..., -0.7868, -0.4855,  0.0638],
           [-0.3072, -0.2761, -0.2037,  ...,  0.3174,  0.1394,  0.1267]],

          [[-0.2980, -0.6261, -0.3754,  ..., -0.8803, -0.5116, -0.2325],
           [-0.2628, -0.9277, -0.9636,  ..., -0.4362, -0.4065, -0.3207],
           [-0.2065, -0.8519, -1.0033,  ..., -0.6636, -0.4973, -0.1509],
           ...,
           [-0.4886, -1.0695, -0.6502,  ..., -0.6194, -0.6536,  0.0325],
           [-0.5144, -0.6333, -0.1508,  ..., -0.9391, -1.1019, -0.7397],
           [-0.0694, -0.0629,  0.0898,  ..., -0.4796, -0.1971, -0.3615]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-1.6082e-01, -8.7399e-02, -1.3319e-03,  ..., -1.1923e-01,
            -1.4567e-01, -1.0296e-01],
           [-3.6143e-01, -5.2402e-01, -3.1734e-01,  ..., -3.7360e-02,
            -1.4727e-01, -2.1146e-01],
           [-1.2748e-01, -2.0289e-01, -1.7263e-01,  ...,  3.2821e-02,
             2.3899e-02, -1.7116e-02],
           ...,
           [-5.4805e-02, -8.7460e-02, -7.2353e-02,  ..., -8.5676e-02,
            -4.8657e-02,  4.4028e-02],
           [-7.9688e-02, -1.0489e-01, -9.2847e-02,  ..., -2.2595e-02,
            -1.0795e-01, -7.0397e-02],
           [-9.7414e-02, -1.1942e-01, -9.3385e-02,  ..., -6.3040e-02,
            -1.0286e-02, -2.8162e-02]],

          [[-8.3590e-02, -1.1097e-01, -7.6247e-02,  ..., -8.4737e-03,
             5.6614e-05, -2.6328e-02],
           [-3.3130e-02, -2.6316e-02, -6.1830e-02,  ..., -3.6645e-02,
             1.5747e-02,  1.4232e-02],
           [-4.1686e-02, -7.8000e-02, -7.1547e-02,  ..., -3.7017e-02,
            -2.4838e-03, -2.6782e-02],
           ...,
           [-1.2196e-02, -2.3432e-02, -2.0606e-03,  ..., -8.6377e-02,
            -1.2465e-01, -9.6318e-02],
           [ 7.4525e-03, -1.4041e-02, -4.3532e-02,  ..., -6.8818e-02,
            -6.5830e-02, -7.8353e-02],
           [ 1.1506e-02,  9.2946e-03, -2.4731e-02,  ..., -3.2439e-02,
             2.1590e-03,  3.9627e-02]],

          [[-3.9879e-01, -3.8665e-01, -1.3869e-01,  ..., -1.1499e-01,
            -1.2475e-01, -1.3711e-01],
           [-6.7526e-01, -7.6506e-01, -2.8433e-01,  ..., -1.8596e-01,
            -2.0662e-01, -2.4935e-01],
           [-2.1169e-01, -1.6909e-01,  5.4648e-02,  ..., -1.5494e-02,
             1.9123e-02, -2.2116e-02],
           ...,
           [-3.6328e-02, -1.6013e-03, -3.8489e-02,  ..., -1.0460e-01,
            -1.5847e-01, -1.7731e-01],
           [-6.4490e-02, -7.4539e-02, -1.0174e-01,  ..., -1.0484e-01,
            -1.5456e-01, -1.5496e-01],
           [-7.7448e-02, -1.5199e-01, -2.2827e-01,  ..., -9.5927e-02,
            -1.1893e-01, -9.5688e-02]],

          ...,

          [[-6.4548e-02, -8.8192e-02, -4.6773e-02,  ..., -6.9743e-03,
             2.2594e-03, -3.4030e-02],
           [ 1.3396e-01,  1.1073e-01,  3.6814e-02,  ...,  4.9052e-03,
             4.7609e-02,  2.7674e-02],
           [ 1.5980e-02,  5.0351e-03,  9.3483e-03,  ...,  1.8490e-02,
             4.5325e-02, -4.3205e-04],
           ...,
           [-5.8525e-03,  4.7031e-02,  4.5665e-02,  ...,  4.1247e-02,
             4.7514e-02, -2.1914e-02],
           [ 2.8747e-04,  4.0925e-02,  7.1120e-02,  ...,  1.4343e-02,
             3.0187e-02, -1.0466e-03],
           [-1.6504e-02, -8.5669e-03,  3.8790e-02,  ..., -3.4095e-02,
            -1.7662e-02, -1.4444e-02]],

          [[-3.3402e-01, -2.9618e-01, -9.9874e-02,  ..., -8.1035e-02,
            -1.4801e-01, -1.0487e-01],
           [-3.1593e-01, -2.6937e-01, -7.6912e-02,  ..., -5.0427e-02,
            -9.1080e-02, -7.3436e-02],
           [-1.6077e-01, -6.5540e-02,  4.2919e-02,  ..., -4.2545e-02,
            -3.7607e-02, -1.2003e-02],
           ...,
           [-3.7154e-03,  3.9980e-02,  1.2839e-02,  ..., -1.6639e-02,
            -3.1090e-02, -6.4658e-02],
           [-2.3084e-02,  2.3174e-02, -1.3319e-02,  ..., -1.1787e-02,
             9.9478e-03,  2.9969e-02],
           [-1.9074e-02, -1.7670e-02, -7.8655e-02,  ..., -2.6532e-03,
            -2.2898e-02,  1.5542e-02]],

          [[ 1.7509e-01, -2.9027e-05, -3.3672e-02,  ...,  3.0066e-02,
             2.1173e-02, -7.9550e-03],
           [-1.0897e-01, -3.1960e-01, -1.1253e-01,  ..., -2.4740e-02,
            -9.3286e-02, -1.2415e-01],
           [-5.8501e-03, -1.0101e-01,  1.9465e-02,  ..., -3.2247e-02,
            -2.0805e-02, -4.5185e-03],
           ...,
           [ 7.1553e-03,  3.4583e-02,  6.0450e-02,  ..., -1.8143e-02,
            -8.8677e-03, -5.4216e-02],
           [ 3.3659e-02,  6.5209e-02,  9.3663e-02,  ...,  4.1290e-02,
            -5.5905e-03, -5.6606e-02],
           [ 2.9368e-02,  3.4554e-02,  1.7176e-02,  ...,  2.8348e-02,
            -2.7019e-02, -6.9664e-02]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.5098,  0.1736,  0.3925,  ...,  0.3039,  0.4451,  0.3184],
           [-0.0598, -0.2861, -0.2505,  ...,  0.1970,  0.1205, -0.0464],
           [ 0.4337, -0.0479, -0.1914,  ...,  0.3584,  0.1753, -0.0405],
           ...,
           [-0.2482, -0.4840, -0.1365,  ..., -0.3502, -0.2638, -0.1277],
           [ 0.0931, -0.1315, -0.0144,  ..., -0.0708, -0.1416,  0.2576],
           [ 0.5693,  0.0493, -0.1726,  ..., -0.0663, -0.1311,  0.2075]],

          [[ 0.0800,  0.3527,  0.2951,  ..., -0.2240,  0.0408,  0.1746],
           [ 0.1391,  0.1942,  0.1127,  ...,  0.1342,  0.2865,  0.1706],
           [ 0.1639, -0.0116, -0.0705,  ..., -0.1466, -0.0055,  0.0638],
           ...,
           [ 0.1223, -0.3129, -0.2357,  ...,  0.6392,  0.5878,  0.5443],
           [-0.0431, -0.3688, -0.2213,  ..., -0.0247, -0.2139,  0.1065],
           [ 0.3570,  0.1945,  0.1925,  ..., -0.0640,  0.1018,  0.0997]],

          [[ 0.6032,  0.0028, -0.0716,  ..., -0.1254,  0.0954,  0.3884],
           [-0.1856, -0.4956, -0.4756,  ..., -0.5205, -0.6469, -0.2358],
           [-0.1939, -0.6479, -0.3986,  ..., -0.5717, -0.6354, -0.2821],
           ...,
           [-0.2615, -0.3921,  0.1904,  ..., -0.4963, -0.5437, -0.2692],
           [-0.1927, -0.5685, -0.1972,  ..., -0.2620, -0.4574,  0.1973],
           [ 0.1334, -0.2671, -0.1990,  ..., -0.0171, -0.2605,  0.1129]],

          ...,

          [[-0.5754, -0.4448, -0.3716,  ..., -0.5752, -0.8019, -0.6547],
           [-0.5028, -0.7751, -0.7857,  ..., -0.4929, -0.5696, -0.3475],
           [-0.2166, -0.4623, -0.5127,  ..., -0.5050, -0.4840, -0.1737],
           ...,
           [-0.9109, -1.7282, -1.1727,  ..., -0.5710, -0.4864, -0.2089],
           [-0.9949, -1.4755, -1.4009,  ..., -0.8807, -1.0772, -0.4198],
           [-0.5473, -0.7397, -0.7279,  ..., -0.9085, -1.1764, -0.5110]],

          [[ 0.4664, -0.5403, -0.2714,  ...,  0.2430,  0.3114, -0.2147],
           [ 0.0738, -0.6117, -0.7808,  ...,  0.1921, -0.3795, -0.4145],
           [-0.0733, -0.6342, -0.9034,  ...,  0.4000, -0.7577, -0.3841],
           ...,
           [-0.4114, -1.1774, -0.6825,  ..., -0.4739, -0.1066, -0.1945],
           [-0.1428, -0.7037, -0.5981,  ..., -0.6284, -0.3815, -0.3180],
           [ 0.0949, -0.1319, -0.2956,  ..., -0.1477, -0.3470, -0.5407]],

          [[-0.4962, -0.0778, -0.5292,  ..., -0.0404,  0.0530, -0.1162],
           [-0.0377, -0.0302, -0.4661,  ..., -0.5547, -0.2383,  0.1106],
           [-0.1918,  0.2446,  0.0900,  ..., -0.6465, -0.5852,  0.0785],
           ...,
           [ 0.1349, -0.1471, -0.2929,  ..., -0.5733, -0.7522,  0.1922],
           [-0.2976, -0.0762, -0.4357,  ..., -0.1059, -0.0564,  0.0568],
           [-0.2566, -0.1907, -0.3015,  ..., -0.0227, -0.2228, -0.0242]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.0510, -0.0698,  0.0040,  ..., -0.0179,  0.0021, -0.0078],
           [-0.1222, -0.0798, -0.0631,  ...,  0.0161, -0.0895, -0.1311],
           [-0.0843, -0.1224, -0.1109,  ..., -0.0426, -0.2030, -0.1647],
           ...,
           [-0.0870, -0.0207, -0.0474,  ..., -0.1326, -0.0437, -0.0309],
           [-0.1607, -0.1051, -0.0448,  ...,  0.0469,  0.0465, -0.0133],
           [-0.1061, -0.1567, -0.0659,  ..., -0.0701, -0.0325,  0.0012]],

          [[-0.1245, -0.1477, -0.0338,  ..., -0.0827, -0.0504, -0.1058],
           [ 0.1969,  0.0248,  0.0013,  ..., -0.0502,  0.0326, -0.0411],
           [ 0.0264, -0.0859, -0.0659,  ..., -0.1118, -0.0909, -0.1030],
           ...,
           [-0.1272, -0.0633,  0.0459,  ..., -0.0523, -0.0801, -0.0876],
           [-0.1067, -0.0668,  0.0022,  ..., -0.1192, -0.1293, -0.1347],
           [-0.0381, -0.0477, -0.0597,  ..., -0.0926, -0.1077, -0.0823]],

          [[-0.0635, -0.1400, -0.1012,  ..., -0.0068,  0.0314,  0.0102],
           [-0.0933, -0.1811, -0.1031,  ..., -0.0319,  0.0461,  0.0047],
           [-0.0964, -0.1068,  0.0097,  ..., -0.0365, -0.0181, -0.0691],
           ...,
           [-0.0430, -0.0466, -0.0025,  ...,  0.0205, -0.0102, -0.0511],
           [-0.0682, -0.0683, -0.0129,  ..., -0.0089, -0.0188, -0.0494],
           [-0.0579, -0.0713, -0.0010,  ..., -0.0311, -0.0175, -0.0290]],

          ...,

          [[-0.0800, -0.0812, -0.0242,  ..., -0.0869, -0.0772, -0.0011],
           [-0.0381, -0.0167, -0.0238,  ..., -0.0680, -0.0347, -0.0412],
           [-0.0834, -0.0793, -0.1422,  ..., -0.0534, -0.0114, -0.0406],
           ...,
           [-0.0159,  0.0017, -0.0306,  ..., -0.0497, -0.0632, -0.0877],
           [-0.0268,  0.0149, -0.0126,  ..., -0.0441,  0.0213,  0.0090],
           [ 0.0006, -0.0310, -0.0287,  ..., -0.0085, -0.0128, -0.0178]],

          [[-0.0556, -0.0731, -0.0343,  ..., -0.0642, -0.0661, -0.0520],
           [ 0.0388,  0.0129,  0.0487,  ...,  0.0453,  0.0838,  0.0257],
           [-0.0910, -0.0915, -0.0123,  ...,  0.0324, -0.0015, -0.0794],
           ...,
           [ 0.0483, -0.0290, -0.0291,  ..., -0.0449, -0.0434, -0.0987],
           [ 0.0601, -0.0490, -0.0457,  ...,  0.0019,  0.0606,  0.0470],
           [ 0.0335, -0.0144, -0.0024,  ...,  0.0107,  0.0047,  0.0004]],

          [[-0.0654, -0.1429, -0.0705,  ..., -0.0970, -0.0802, -0.1169],
           [ 0.0387, -0.0708, -0.0757,  ..., -0.0317, -0.0100, -0.0739],
           [-0.0517, -0.1478, -0.1113,  ..., -0.0170, -0.0384, -0.0802],
           ...,
           [-0.0656, -0.1084, -0.0880,  ..., -0.0044, -0.0288, -0.0500],
           [-0.0497, -0.0753, -0.0420,  ..., -0.0368, -0.0288, -0.0468],
           [-0.0154, -0.0363, -0.0092,  ..., -0.0728, -0.0481, -0.0592]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.9101,  1.0766,  0.8197,  ...,  0.3239,  0.6147,  0.6619],
           [ 0.3469, -0.0430,  0.0586,  ...,  0.0741, -0.0061,  0.2298],
           [ 0.4233,  0.2378, -0.1834,  ..., -0.3338, -0.4337, -0.0405],
           ...,
           [-0.2806, -0.7089, -0.6877,  ..., -0.2932, -0.1125,  0.2156],
           [-0.1780, -0.5839, -0.3999,  ..., -0.3161, -0.3349, -0.1509],
           [ 0.0418, -0.2564, -0.0946,  ..., -0.1442, -0.0363, -0.1216]],

          [[ 0.8149,  0.4860,  0.3185,  ...,  0.1834,  0.6390,  0.6432],
           [ 0.7706,  0.3752,  0.3433,  ...,  0.0663,  0.5357,  0.4820],
           [ 0.1882, -0.2527, -0.2498,  ..., -0.0375, -0.0892, -0.1041],
           ...,
           [ 0.2684, -0.4433, -0.2683,  ..., -0.0835, -0.0633, -0.0604],
           [ 0.2136, -0.3107, -0.3213,  ..., -0.1884, -0.2071, -0.0392],
           [ 0.2493, -0.0326, -0.0568,  ..., -0.1346, -0.4392, -0.2407]],

          [[-0.7696, -0.7801, -0.3502,  ..., -0.4878, -0.4838, -0.3692],
           [-0.8561, -0.7158, -0.3122,  ..., -0.6538, -0.7723, -0.5182],
           [-0.4039, -0.3073, -0.2708,  ..., -0.7497, -0.6898, -0.4187],
           ...,
           [-0.1388, -0.7416, -0.4934,  ..., -0.4124, -0.5719, -0.9950],
           [ 0.0069, -0.7505, -0.6551,  ..., -0.8837, -0.7356, -0.9177],
           [-0.1235, -0.8004, -0.8288,  ..., -0.6875, -0.8000, -0.8135]],

          ...,

          [[ 0.5193,  0.0885, -0.1648,  ..., -0.2513, -0.0280,  0.2250],
           [-0.1095, -0.4824, -0.6343,  ..., -0.4968, -0.4093, -0.1937],
           [-0.1244, -0.5217, -0.5575,  ..., -0.3860, -0.2766, -0.0532],
           ...,
           [-0.0555, -0.4405, -0.6392,  ..., -0.7580, -0.7131, -0.6700],
           [ 0.0155, -0.8437, -0.9014,  ..., -1.1372, -0.8675, -0.2615],
           [ 0.1376, -0.5330, -0.7336,  ..., -0.1720, -0.0350,  0.0740]],

          [[-0.4117, -0.6053, -0.9020,  ..., -0.6382, -0.6521, -0.1293],
           [-0.9844, -1.0386, -0.9518,  ..., -1.1631, -1.2422, -0.5029],
           [-0.4233, -0.5345, -0.6717,  ..., -0.6881, -1.0350, -0.4479],
           ...,
           [-0.0976, -0.1517, -0.1754,  ...,  0.2021, -0.5755, -0.2413],
           [ 0.0702, -0.4755, -0.4894,  ...,  0.3783, -0.3654,  0.0330],
           [-0.0632, -0.3983, -0.3590,  ..., -0.3914, -0.5590,  0.2499]],

          [[-0.3513, -0.2525, -0.2272,  ..., -0.4691, -0.4100, -0.0667],
           [-0.0315, -0.2985, -0.1417,  ..., -0.8414, -0.7026, -0.2416],
           [ 0.0771, -0.1426,  0.0438,  ..., -0.4894, -0.7221, -0.3022],
           ...,
           [-0.5155, -0.8266, -0.2681,  ..., -0.1801, -0.8270, -0.3935],
           [-0.4917, -0.6305,  0.0745,  ..., -0.6882, -1.1467, -0.6796],
           [-0.0945, -0.0862,  0.2665,  ..., -0.4855, -0.6020, -0.2635]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 6.4430e-02, -1.6318e-01, -2.3215e-01,  ..., -1.9166e-01,
            -1.6584e-01, -1.0940e-01],
           [-1.5872e-01, -3.8746e-01, -3.0614e-01,  ..., -3.7735e-01,
            -3.5435e-01, -2.8609e-01],
           [-2.0114e-02, -1.1159e-01, -3.7295e-02,  ..., -6.2077e-02,
            -1.4846e-01, -1.0356e-01],
           ...,
           [-1.1273e-01, -1.3277e-01, -9.7977e-02,  ..., -7.3987e-02,
            -5.9154e-02, -3.6332e-02],
           [-1.3821e-01, -2.3602e-01, -1.7948e-01,  ..., -5.4057e-02,
            -8.1132e-02, -8.4313e-02],
           [-8.6350e-02, -1.5658e-01, -9.1837e-02,  ..., -1.3030e-01,
            -1.0429e-01, -6.4923e-02]],

          [[ 8.9676e-02, -6.1121e-02, -1.4292e-01,  ..., -1.2495e-01,
             4.0534e-02,  6.2829e-02],
           [-4.9366e-02, -2.0399e-01, -2.4697e-01,  ..., -2.5667e-01,
            -1.6171e-01, -1.1283e-01],
           [ 2.2497e-02, -3.9560e-02, -8.7142e-02,  ..., -1.9836e-01,
            -1.4036e-01, -1.1564e-01],
           ...,
           [-1.5411e-01, -1.2683e-01, -2.1520e-02,  ..., -1.2022e-01,
            -1.8644e-01, -1.1395e-01],
           [-1.1874e-01, -1.5701e-01, -6.2235e-02,  ..., -7.0218e-02,
            -1.0617e-01, -8.0756e-02],
           [-7.2681e-02, -1.4645e-01, -9.7536e-02,  ..., -6.5988e-02,
             2.5555e-03, -6.0063e-03]],

          [[ 1.8542e-01,  1.7175e-01,  1.1776e-01,  ...,  4.2249e-02,
             1.5117e-01,  1.2253e-01],
           [ 7.3441e-01,  8.1271e-01,  5.0550e-01,  ...,  2.7646e-01,
             5.0381e-01,  4.1670e-01],
           [ 1.3243e-01,  7.8072e-02,  4.7040e-02,  ...,  8.7921e-02,
             3.5772e-02, -1.3040e-03],
           ...,
           [-3.9274e-02,  1.2257e-02,  1.1344e-02,  ...,  4.4609e-02,
             2.8281e-02,  6.8394e-03],
           [-5.1679e-02, -1.6965e-02, -4.5877e-02,  ..., -5.1035e-02,
            -5.9237e-04,  3.0533e-02],
           [ 6.0087e-02,  3.7373e-02, -1.3914e-02,  ...,  7.0179e-03,
             8.6234e-02,  1.1765e-01]],

          ...,

          [[ 6.0558e-03,  1.5564e-01,  5.5820e-02,  ..., -4.4163e-02,
            -3.2737e-03,  8.2676e-02],
           [-2.2683e-01, -1.2114e-01, -9.8398e-02,  ..., -1.3539e-01,
            -1.0991e-01, -1.1122e-01],
           [-1.3119e-01, -4.0930e-03, -4.1464e-02,  ..., -1.4224e-02,
            -8.3651e-02, -1.7913e-01],
           ...,
           [-4.0930e-02,  1.0420e-02, -3.7359e-02,  ..., -5.6199e-02,
            -6.6513e-02, -8.7126e-02],
           [-9.0039e-02,  3.0807e-02, -1.4512e-04,  ..., -1.1594e-01,
            -3.8810e-02, -4.3311e-02],
           [-8.2347e-02, -1.1363e-02, -3.4658e-03,  ..., -5.7998e-02,
            -4.6701e-03, -7.7030e-03]],

          [[ 5.5289e-02, -1.5680e-03, -1.1800e-01,  ..., -2.2549e-01,
            -4.5773e-02, -2.2674e-02],
           [-2.0767e-01, -1.3274e-01, -1.2607e-01,  ..., -1.9728e-01,
            -1.5975e-01, -1.3349e-01],
           [-1.4214e-01, -3.7481e-02, -3.9965e-02,  ..., -4.2012e-02,
            -6.0136e-02, -1.1219e-01],
           ...,
           [-1.4361e-02, -8.7165e-02, -4.7337e-02,  ..., -1.0478e-01,
            -6.8615e-02, -9.3372e-02],
           [-8.2169e-02, -1.5698e-01, -1.4019e-01,  ..., -1.2017e-01,
            -3.3156e-03, -1.3669e-02],
           [-9.5183e-02, -1.0866e-01, -8.0570e-02,  ..., -5.5362e-02,
            -3.9940e-02, -2.6436e-02]],

          [[ 5.6359e-02,  1.1743e-01,  3.2198e-02,  ..., -3.8483e-03,
             8.7708e-02,  6.4603e-02],
           [-1.1675e-01, -6.1985e-02, -5.4091e-02,  ..., -4.9418e-02,
            -1.4927e-02, -4.6136e-02],
           [-3.6973e-02,  4.3101e-02,  5.4578e-03,  ...,  2.4467e-02,
             2.7021e-02, -4.8823e-03],
           ...,
           [ 5.6195e-03, -2.5033e-03, -1.4855e-02,  ...,  2.3181e-02,
            -2.8707e-03, -1.0791e-02],
           [-1.2482e-02,  5.2544e-04, -1.2498e-02,  ...,  1.4234e-02,
             4.9095e-02,  4.3880e-03],
           [-1.7698e-02,  2.2928e-03, -7.0659e-03,  ..., -3.8163e-03,
             3.9203e-02, -2.6743e-03]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 1.7339e-01, -9.4808e-02, -6.1271e-01,  ...,  1.4380e-01,
            -2.0960e-01, -3.2730e-01],
           [-6.3560e-02, -2.1000e-01, -6.8458e-01,  ..., -9.9222e-01,
             2.9317e-01, -5.5872e-02],
           [-1.5248e-01, -4.8554e-01, -4.8676e-01,  ...,  6.1018e-02,
             6.5937e-01, -1.3268e-01],
           ...,
           [-4.8350e-01, -8.6408e-01, -6.1364e-01,  ..., -9.9484e-01,
            -7.1179e-01, -1.4440e-01],
           [-1.7778e-01, -1.4797e-01, -4.1957e-01,  ..., -8.4083e-01,
            -6.0669e-01, -5.0201e-02],
           [-5.5214e-01, -4.5085e-01, -2.3836e-01,  ..., -5.5610e-01,
            -8.8097e-01, -4.0863e-01]],

          [[-4.3246e-03,  7.2340e-02, -4.0673e-01,  ...,  4.4244e-02,
            -1.3516e-01, -2.7559e-02],
           [-6.7222e-02, -1.0078e-01, -1.2998e-01,  ..., -2.3212e-01,
            -4.1464e-01, -4.0327e-01],
           [-1.5512e-01,  7.9317e-02,  1.5356e-01,  ..., -5.7165e-01,
            -4.5463e-01, -5.9033e-01],
           ...,
           [-1.8650e-01, -1.3346e-01, -2.2597e-02,  ..., -9.4229e-02,
            -3.2536e-01, -3.4481e-01],
           [-6.8029e-01, -1.1684e-03,  9.0839e-02,  ...,  2.6727e-01,
             3.1889e-01, -2.6609e-02],
           [-7.7352e-01, -3.5479e-01, -5.5215e-01,  ..., -4.0914e-01,
             1.0151e-01, -4.4220e-01]],

          [[ 1.3809e+00,  7.1808e-02, -4.7408e-02,  ..., -3.0978e-01,
             2.6252e-01,  5.1537e-01],
           [ 2.0916e-01,  5.9198e-02,  3.5689e-01,  ...,  2.4617e-01,
            -4.3292e-01, -3.2945e-01],
           [-9.1277e-03,  1.2988e-01, -3.6940e-01,  ..., -1.1850e-01,
             1.5383e-01, -1.4952e-02],
           ...,
           [-2.0953e-01, -1.1567e-01, -1.5326e-01,  ..., -4.2803e-01,
            -4.6014e-01, -1.9415e-01],
           [-1.4530e-01, -1.3514e-01, -2.9253e-01,  ..., -1.2311e-01,
            -1.1232e-01, -2.9425e-01],
           [ 1.9769e-01,  2.3179e-01, -2.5285e-01,  ..., -3.0741e-01,
            -2.1593e-01,  2.9725e-02]],

          ...,

          [[ 2.5535e-01,  7.2656e-03, -1.2095e-01,  ...,  3.7620e-02,
             1.8716e-03,  2.3830e-01],
           [ 1.2931e-01, -1.1446e-01, -6.7117e-01,  ..., -3.7731e-01,
            -1.8579e-01,  2.5818e-01],
           [ 1.0917e-02, -2.3147e-01, -6.8273e-01,  ..., -1.5688e+00,
            -3.1911e-01,  1.9214e-01],
           ...,
           [ 4.9276e-01,  2.3696e-01, -1.7069e-01,  ..., -2.3560e-02,
            -4.2982e-01,  4.3347e-02],
           [-1.5764e-01,  1.2234e-01, -2.6147e-01,  ...,  4.9637e-02,
            -3.0250e-01, -9.2175e-02],
           [-4.0238e-01, -2.6120e-01, -4.6877e-01,  ..., -8.3150e-01,
            -2.5967e-01, -6.1447e-01]],

          [[ 5.0277e-01, -2.5111e-01, -2.9781e-02,  ...,  1.2346e-01,
             1.2271e-01, -5.3489e-02],
           [ 5.4571e-01, -2.0467e-01, -5.6036e-01,  ..., -6.4822e-01,
            -2.9836e-01, -3.3093e-01],
           [ 1.5907e-01, -3.0992e-01, -7.3655e-01,  ...,  1.6752e-01,
            -2.4167e-01, -5.0056e-02],
           ...,
           [ 6.1304e-01,  1.5488e-01, -1.9809e-01,  ...,  1.3724e-01,
            -1.7476e-01, -2.0033e-01],
           [ 1.4995e-01,  3.0548e-01, -1.9005e-01,  ...,  1.7044e-01,
            -6.0262e-01,  1.1476e-02],
           [-1.3003e-01, -7.5153e-01, -2.9897e-01,  ..., -4.0668e-01,
            -7.2825e-01,  6.4905e-02]],

          [[ 1.1347e-01,  4.4911e-02, -7.4415e-02,  ..., -3.1216e-01,
            -2.3538e-01,  1.1548e-01],
           [-2.2218e-02, -2.2825e-01, -6.4981e-02,  ...,  5.8519e-02,
             1.0134e-01, -1.1251e-01],
           [-1.0316e-02,  4.1192e-01, -4.0713e-01,  ..., -2.2387e-02,
            -8.5106e-02, -2.5153e-01],
           ...,
           [-3.3986e-01, -4.1138e-01,  3.5781e-01,  ...,  2.1808e-01,
            -2.5594e-01,  1.1899e-01],
           [ 5.5571e-02, -1.4490e-01, -2.9625e-01,  ...,  8.0132e-02,
             1.0265e-01,  2.1682e-01],
           [ 6.5714e-02, -1.2890e-01,  1.6180e-01,  ...,  1.4383e-01,
             3.4399e-01,  6.4371e-01]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[ 0.0960,  0.0307, -0.0699,  ...,  0.0172,  0.0034, -0.0184],
           [-0.1651, -0.2210, -0.1714,  ..., -0.2050, -0.0549, -0.1189],
           [ 0.0070,  0.0068,  0.1551,  ...,  0.0701,  0.0633,  0.0086],
           ...,
           [-0.0674, -0.0241,  0.0063,  ...,  0.0346,  0.0357,  0.0131],
           [-0.1675, -0.0529,  0.1768,  ...,  0.1033,  0.0940,  0.0378],
           [-0.1387, -0.1719, -0.0859,  ...,  0.0721,  0.1203,  0.1045]],

          [[-0.0699,  0.0097,  0.0019,  ..., -0.1541, -0.2316, -0.1260],
           [-0.0322, -0.0661,  0.1079,  ..., -0.0795, -0.3717, -0.2026],
           [ 0.0063,  0.0893,  0.2031,  ...,  0.1351, -0.1136, -0.0444],
           ...,
           [ 0.1117,  0.0801,  0.0366,  ..., -0.0718,  0.0056, -0.0384],
           [ 0.0280,  0.0044, -0.0808,  ..., -0.1459, -0.0720, -0.0570],
           [ 0.0297,  0.0227,  0.0394,  ...,  0.1448,  0.1450, -0.0226]],

          [[-0.0899, -0.0195, -0.0080,  ..., -0.0544, -0.1548, -0.0921],
           [-0.0682,  0.0799,  0.0049,  ..., -0.1934, -0.2153, -0.0923],
           [-0.1031, -0.0454, -0.0174,  ..., -0.0893, -0.1499, -0.0551],
           ...,
           [-0.0286, -0.0889, -0.1280,  ..., -0.1297, -0.0631, -0.0738],
           [-0.1076, -0.1124, -0.1168,  ..., -0.2121, -0.0860, -0.1526],
           [-0.1690, -0.0428, -0.0780,  ..., -0.1965, -0.1253, -0.1400]],

          ...,

          [[-0.1522, -0.1636, -0.1202,  ..., -0.0121, -0.0746, -0.1115],
           [-0.0114, -0.1939, -0.1007,  ..., -0.0196,  0.0041, -0.0400],
           [-0.0623, -0.1104, -0.0841,  ..., -0.0666,  0.0758,  0.0979],
           ...,
           [-0.0540, -0.1088, -0.0957,  ..., -0.1641, -0.0596, -0.0542],
           [-0.1630, -0.1650, -0.1441,  ..., -0.1307, -0.1170, -0.0429],
           [-0.0806, -0.1046, -0.0604,  ..., -0.0512,  0.1480,  0.0605]],

          [[-0.0534, -0.0888, -0.1538,  ..., -0.1150, -0.0616, -0.1154],
           [-0.0053, -0.2251, -0.1865,  ..., -0.2248, -0.1754, -0.0764],
           [ 0.0032, -0.1462, -0.0746,  ...,  0.0086, -0.0652,  0.0277],
           ...,
           [-0.0308,  0.0306,  0.0580,  ..., -0.0542, -0.0445, -0.0155],
           [-0.0855, -0.0960, -0.0220,  ..., -0.1566, -0.1331,  0.0572],
           [-0.1060, -0.0912,  0.0406,  ..., -0.0249, -0.0581,  0.0064]],

          [[ 0.1796,  0.2143,  0.0647,  ..., -0.0623, -0.0173,  0.0643],
           [-0.0477, -0.0548, -0.0255,  ..., -0.2377, -0.2283, -0.0758],
           [ 0.0988,  0.1510,  0.1109,  ...,  0.0127, -0.0725, -0.0160],
           ...,
           [-0.0108, -0.0191, -0.0287,  ..., -0.0878, -0.1053, -0.0423],
           [-0.0221,  0.0222,  0.0112,  ..., -0.0241, -0.0022,  0.0472],
           [ 0.0500,  0.1050,  0.0466,  ...,  0.0299,  0.0499,  0.1599]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.4231, -0.0231, -0.0056,  ..., -0.0265, -0.1730, -0.1304],
           [-0.1795,  0.0069, -0.0698,  ..., -0.0588,  0.1447,  0.0358],
           [-0.0325,  0.0794,  0.0769,  ...,  0.1704,  0.1836, -0.0286],
           ...,
           [-0.0966, -0.0066,  0.0286,  ..., -0.0133,  0.0371, -0.1012],
           [ 0.0106,  0.0447,  0.0192,  ...,  0.0716,  0.0035, -0.0776],
           [-0.0816,  0.0074,  0.0128,  ..., -0.0761, -0.0472,  0.1071]],

          [[-0.1681, -0.0969,  0.0657,  ..., -0.0468, -0.1331, -0.3370],
           [-0.1509, -0.0407,  0.2268,  ...,  0.1119, -0.0907, -0.1011],
           [-0.0282,  0.0365,  0.0505,  ...,  0.1827,  0.0482, -0.1284],
           ...,
           [-0.0058,  0.0085, -0.0955,  ..., -0.1342, -0.1231,  0.0110],
           [ 0.1221, -0.1235, -0.1002,  ..., -0.0979, -0.1216, -0.1265],
           [-0.0721, -0.1120,  0.0545,  ...,  0.3044, -0.0122, -0.0502]],

          [[ 0.0532, -0.1504, -0.0791,  ..., -0.0050,  0.0386, -0.0034],
           [-0.0949,  0.0850, -0.1386,  ..., -0.1174, -0.0495, -0.0722],
           [-0.0897, -0.0400, -0.1848,  ..., -0.0402, -0.0539,  0.0251],
           ...,
           [-0.0268, -0.1440, -0.1328,  ..., -0.1762, -0.1322, -0.0544],
           [-0.2909, -0.1445, -0.0061,  ..., -0.2415, -0.0795, -0.0177],
           [-0.3183, -0.1925, -0.2452,  ..., -0.4863, -0.0652, -0.0086]],

          ...,

          [[-0.2409, -0.1967, -0.0914,  ..., -0.1281, -0.2115, -0.2216],
           [-0.1904, -0.0376, -0.1786,  ...,  0.0372,  0.1565,  0.0133],
           [-0.1434, -0.0010, -0.0514,  ..., -0.3211,  0.0617, -0.1025],
           ...,
           [-0.1048,  0.0027, -0.0717,  ..., -0.2067, -0.0891, -0.1054],
           [-0.2565, -0.0988, -0.1175,  ..., -0.1354, -0.0973, -0.1034],
           [-0.2623, -0.0985, -0.0262,  ..., -0.1220, -0.0202,  0.0135]],

          [[-0.2197, -0.0848,  0.0301,  ..., -0.2480, -0.1971,  0.0863],
           [ 0.0555,  0.0098, -0.1250,  ...,  0.0984, -0.0698,  0.0870],
           [-0.0286, -0.0368,  0.1240,  ..., -0.1178, -0.1522, -0.0569],
           ...,
           [-0.0732, -0.0158, -0.0738,  ...,  0.0430, -0.0608, -0.0357],
           [-0.2239, -0.0886, -0.0522,  ...,  0.0225, -0.2635, -0.1263],
           [ 0.0212, -0.1778, -0.0208,  ..., -0.1523, -0.1107, -0.1440]],

          [[ 0.0253,  0.0283,  0.0140,  ...,  0.0084, -0.0078,  0.1810],
           [ 0.0963,  0.0438, -0.1671,  ..., -0.1635, -0.2097, -0.0558],
           [ 0.0865,  0.0705, -0.1457,  ..., -0.1799, -0.1054, -0.0024],
           ...,
           [ 0.1376,  0.0282,  0.0467,  ...,  0.0566,  0.0660, -0.0354],
           [-0.1233,  0.0141,  0.0358,  ..., -0.0034, -0.0085, -0.0285],
           [ 0.0108,  0.0045,  0.1608,  ..., -0.0417, -0.0297,  0.0972]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.4958, -1.6956, -0.6618,  ..., -0.9556, -1.6244, -0.7040],
           [-1.6635, -2.5068, -1.4933,  ..., -1.6722, -2.4164, -1.5556],
           [-0.7953, -0.8299, -0.3875,  ..., -0.9296, -1.3441, -0.9987],
           ...,
           [-1.8495, -2.9274, -1.7244,  ..., -0.8433, -0.9403, -0.4768],
           [-1.1743, -2.8202, -2.3558,  ..., -2.1676, -2.2784, -1.2847],
           [-0.6261, -1.4864, -0.9453,  ..., -1.0875, -1.3397, -0.8367]],

          [[ 0.2355, -0.8715, -1.2119,  ..., -1.2575, -0.6488,  0.0329],
           [-0.3182, -1.5435, -1.9886,  ..., -2.0758, -1.5624, -0.3341],
           [-0.3772, -1.9734, -2.4813,  ..., -2.1128, -1.6591, -0.9725],
           ...,
           [-0.7824, -1.4839, -1.3397,  ..., -1.5276, -2.2641, -1.6701],
           [-1.3119, -2.0934, -1.6868,  ..., -1.9044, -2.1447, -1.2452],
           [-0.6846, -1.6288, -1.7022,  ..., -0.8273, -0.4320,  0.1732]],

          [[ 0.0166, -1.7161, -2.3600,  ..., -3.1715, -2.6389, -1.7020],
           [-1.2275, -2.8275, -3.6183,  ..., -4.1244, -3.2650, -1.9257],
           [-0.1512, -0.1212, -0.3152,  ..., -1.9853, -2.1037, -1.3129],
           ...,
           [-0.4808, -0.8547, -0.7786,  ..., -0.8631, -1.9802, -1.4388],
           [-0.3164, -1.0302, -0.7526,  ..., -1.7501, -2.7765, -1.1548],
           [-0.8256, -1.4198, -1.1582,  ..., -1.0846, -0.4300,  0.4089]],

          ...,

          [[-1.2897, -1.8389, -0.8400,  ..., -0.6759, -0.5749, -0.1012],
           [-1.9064, -3.2975, -2.6617,  ..., -2.9298, -2.4174, -1.3648],
           [-1.6253, -2.6109, -2.5476,  ..., -3.3257, -3.4099, -2.1412],
           ...,
           [-1.2108, -2.3047, -1.9960,  ..., -1.4551, -1.7386, -0.9149],
           [-1.3869, -2.4565, -2.1475,  ..., -1.0893, -1.9669, -1.2323],
           [-0.6772, -1.1768, -1.0358,  ..., -0.3274, -1.3807, -0.8585]],

          [[-1.8343, -0.8251, -1.0899,  ..., -1.2018, -1.3029, -0.1550],
           [-0.5182,  0.0390,  0.0699,  ..., -1.9062, -1.7981,  0.4875],
           [-0.8099, -0.7638, -1.8919,  ..., -1.0373, -2.1952, -0.7600],
           ...,
           [-1.0898, -1.5434, -1.1102,  ..., -2.0837, -2.9177, -0.6845],
           [-0.8162, -1.4854, -1.4141,  ..., -2.6396, -3.5088, -0.8067],
           [-1.2074, -1.2848, -0.3816,  ..., -0.5490, -2.6263, -0.3691]],

          [[-1.4092, -0.9987, -0.0146,  ..., -0.7766, -2.0979, -1.7557],
           [-2.2071, -2.9781, -1.7933,  ..., -2.5191, -2.7386, -1.6995],
           [-1.3005, -1.7724, -1.4228,  ..., -1.1738, -1.2907, -1.2182],
           ...,
           [-0.3932, -1.2425, -2.0961,  ..., -2.0225, -1.9730, -1.6157],
           [-1.0402, -1.3846, -1.5287,  ..., -1.3333, -2.1565, -2.2994],
           [-1.1169, -1.1005, -0.9754,  ..., -0.4825, -1.5659, -1.9117]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-0.0620, -0.0237, -0.0037,  ...,  0.0130, -0.0199, -0.0416],
           [-0.1411, -0.1366, -0.0297,  ..., -0.0025, -0.0703, -0.0618],
           [-0.0425,  0.0070,  0.0373,  ...,  0.0118, -0.0123, -0.0235],
           ...,
           [-0.0277, -0.0095, -0.0008,  ...,  0.0151,  0.0450,  0.0469],
           [-0.0916, -0.0925, -0.0732,  ..., -0.1455, -0.1627, -0.0588],
           [-0.0897, -0.0521, -0.0247,  ..., -0.0691, -0.1293, -0.0736]],

          [[-0.0568, -0.0628, -0.0028,  ...,  0.0254,  0.0397,  0.0392],
           [-0.0439, -0.0591,  0.0522,  ...,  0.0254,  0.0312,  0.0318],
           [-0.0353, -0.0663, -0.0202,  ...,  0.0170,  0.0434,  0.0318],
           ...,
           [ 0.0143,  0.0021,  0.0039,  ...,  0.0114, -0.0168, -0.0155],
           [ 0.0041, -0.0421, -0.0107,  ...,  0.0293,  0.0091,  0.0105],
           [ 0.0061, -0.0431,  0.0033,  ...,  0.0891,  0.1117,  0.0562]],

          [[-0.0850, -0.0327, -0.0011,  ...,  0.0552,  0.0250, -0.0236],
           [-0.0567, -0.0512,  0.0741,  ...,  0.1015,  0.0453, -0.0065],
           [-0.0738, -0.0334,  0.0383,  ...,  0.0974,  0.0570, -0.0097],
           ...,
           [-0.0352, -0.0065, -0.0038,  ..., -0.0257,  0.0273, -0.0275],
           [ 0.0552,  0.0570,  0.0491,  ..., -0.0533, -0.0732, -0.0627],
           [-0.0079,  0.0119,  0.0202,  ..., -0.0413, -0.0490, -0.0928]],

          ...,

          [[-0.0974, -0.0357, -0.0637,  ..., -0.0637, -0.0228,  0.0032],
           [-0.0352,  0.0125, -0.0438,  ..., -0.0205,  0.0805,  0.1438],
           [-0.0076,  0.0452,  0.0310,  ..., -0.0428, -0.0087,  0.0439],
           ...,
           [-0.0556, -0.0168,  0.0125,  ..., -0.0336, -0.0604, -0.0738],
           [-0.1158, -0.0726, -0.0050,  ...,  0.0109, -0.0004, -0.0633],
           [-0.1226, -0.0931, -0.0844,  ..., -0.0718, -0.0282, -0.0443]],

          [[-0.0787, -0.0310, -0.0008,  ...,  0.0244,  0.0272,  0.0122],
           [ 0.0031,  0.0096,  0.0468,  ...,  0.1062,  0.1036,  0.0854],
           [ 0.0196,  0.0422,  0.1191,  ...,  0.0817,  0.0749,  0.0545],
           ...,
           [ 0.0364,  0.0224,  0.0021,  ..., -0.0197,  0.0239, -0.0109],
           [ 0.0244,  0.0559,  0.0411,  ..., -0.0529, -0.0173, -0.0235],
           [-0.0286,  0.0330,  0.0321,  ...,  0.0262,  0.0654,  0.0311]],

          [[-0.0086,  0.0656,  0.0510,  ..., -0.0015, -0.0074, -0.0071],
           [ 0.0841,  0.0682,  0.0510,  ..., -0.0253, -0.0443, -0.0139],
           [ 0.0517,  0.0391,  0.0168,  ..., -0.0678, -0.0927, -0.0420],
           ...,
           [-0.0126, -0.0465, -0.0627,  ..., -0.0418, -0.0515, -0.0328],
           [ 0.0267,  0.0123,  0.0104,  ...,  0.0231, -0.0101,  0.0244],
           [ 0.0172,  0.0445,  0.0412,  ...,  0.0129, -0.0327, -0.0167]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-3.4750, -3.4560, -2.8273,  ..., -3.2508, -3.8729, -2.8269],
           [-4.2592, -4.8648, -2.5765,  ..., -1.2634, -1.9938, -2.1092],
           [-2.7763, -3.2505, -1.8529,  ..., -2.0219, -1.5580, -1.5422],
           ...,
           [-1.7902, -2.4408, -1.2079,  ..., -2.0084, -2.4411, -1.9580],
           [-1.6889, -2.7830, -2.4005,  ..., -1.9301, -2.0826, -1.7352],
           [-1.4279, -2.3741, -2.9092,  ..., -3.9762, -3.4731, -2.4181]],

          [[-1.9909, -2.7051, -2.3577,  ..., -3.0502, -3.1455, -1.9688],
           [-2.5792, -3.3235, -2.4701,  ..., -4.1309, -4.7480, -3.0812],
           [-2.1466, -2.2925, -1.1225,  ..., -2.5902, -3.6139, -2.3158],
           ...,
           [-2.0956, -3.0973, -2.2434,  ..., -1.5169, -2.2583, -1.6122],
           [-2.3290, -3.7623, -3.1273,  ..., -2.5104, -3.6841, -2.5078],
           [-1.8428, -2.6170, -1.8207,  ..., -1.3055, -2.4725, -1.5867]],

          [[-3.4129, -2.4648, -1.0742,  ..., -1.1919, -1.9342, -1.6739],
           [-2.6977, -2.0980, -1.4507,  ..., -0.8640, -1.0576, -0.5588],
           [-2.2977, -2.6378, -2.5816,  ..., -2.1669, -1.5316, -0.7172],
           ...,
           [-3.3527, -3.5814, -2.9848,  ..., -2.0961, -2.6056, -1.8142],
           [-4.3135, -4.9184, -4.3180,  ..., -3.8032, -4.8414, -3.6772],
           [-2.7174, -3.1033, -3.0057,  ..., -3.0211, -4.7558, -4.2106]],

          ...,

          [[-4.4429, -3.3553, -1.4595,  ..., -1.8802, -2.5783, -1.9087],
           [-4.6435, -4.3449, -3.1467,  ..., -2.3504, -2.0158, -1.1910],
           [-3.3648, -3.1884, -2.2892,  ..., -2.9678, -2.6551, -1.7214],
           ...,
           [-2.8477, -2.9236, -2.2211,  ..., -4.0577, -4.8453, -3.4708],
           [-3.9063, -4.3842, -3.3218,  ..., -4.5455, -5.6346, -4.1392],
           [-2.8678, -3.3069, -2.2644,  ..., -1.6910, -2.7187, -2.1092]],

          [[-2.5947, -2.0769, -1.6998,  ..., -2.1328, -3.2101, -2.5518],
           [-2.1753, -1.3601, -0.5612,  ..., -1.5786, -2.3167, -1.4304],
           [-1.8868, -1.4609, -1.4939,  ..., -2.2960, -1.9507, -0.9916],
           ...,
           [-4.1552, -4.0864, -2.9043,  ..., -2.2917, -2.6341, -1.9900],
           [-5.4539, -5.7471, -4.4933,  ..., -4.1449, -4.8205, -3.3648],
           [-3.5695, -4.2426, -4.0575,  ..., -3.9390, -4.0871, -2.6593]],

          [[-1.7293, -1.3352, -0.6515,  ..., -2.7331, -3.6395, -2.9957],
           [-2.3236, -2.4487, -2.4042,  ..., -4.6181, -4.5513, -3.0388],
           [-1.9516, -1.9545, -1.9636,  ..., -5.1817, -4.5127, -2.4386],
           ...,
           [-2.8701, -2.9135, -1.2747,  ..., -0.9129, -1.7076, -1.5889],
           [-3.5865, -4.6488, -3.6247,  ..., -4.0014, -4.4134, -3.0185],
           [-3.1188, -3.7854, -2.9042,  ..., -3.5254, -4.1202, -2.7234]]]],
        device=&#39;cuda:0&#39;, grad_fn=&lt;CudnnConvolutionBackward&gt;),
 tensor([[[[-4.0248e-02, -2.1918e-02,  1.6857e-02,  ..., -3.5696e-03,
            -2.6573e-02, -4.6227e-02],
           [-2.7004e-02, -1.1469e-02,  4.3785e-02,  ...,  3.2996e-02,
             1.1239e-02, -1.7459e-02],
           [ 5.9849e-03, -1.3250e-03,  1.6657e-02,  ...,  5.3861e-02,
             5.6166e-02,  1.7476e-02],
           ...,
           [ 8.3230e-03,  4.1532e-02,  5.7824e-02,  ...,  6.9979e-02,
             2.0746e-02, -6.8109e-03],
           [-2.6846e-02,  4.4148e-03,  1.4690e-02,  ..., -3.6798e-03,
            -7.0932e-02, -5.3330e-02],
           [-2.1289e-02, -1.7336e-02, -4.2136e-02,  ..., -5.3113e-02,
            -7.2978e-02, -2.9946e-02]],

          [[-3.7065e-02,  1.3638e-02,  5.1883e-02,  ..., -1.5602e-02,
            -4.2106e-02, -3.2605e-02],
           [-5.9112e-02,  8.4406e-03,  7.6438e-02,  ...,  1.9861e-02,
             3.6813e-02,  4.7601e-02],
           [-1.3119e-02,  2.3961e-02,  2.7430e-02,  ..., -8.6907e-02,
            -3.4433e-03,  4.5861e-02],
           ...,
           [-1.3509e-02,  2.4247e-03,  2.8476e-02,  ...,  5.4252e-02,
             1.1840e-01,  9.6187e-02],
           [-2.8346e-02, -1.9278e-02,  3.3225e-02,  ...,  7.3646e-02,
             9.0414e-02,  6.1256e-02],
           [-2.8322e-02, -5.2114e-02, -3.8483e-02,  ..., -1.2129e-04,
             3.6583e-02,  1.6103e-02]],

          [[-7.1677e-03,  1.0149e-01,  1.6720e-01,  ...,  9.0421e-02,
             3.4992e-02, -1.8386e-03],
           [ 4.6779e-02,  1.7365e-01,  2.3382e-01,  ...,  1.2050e-01,
             2.4064e-02, -6.9508e-03],
           [ 1.8438e-02,  9.5620e-02,  1.1244e-01,  ...,  6.1100e-02,
            -2.5235e-05, -1.9582e-02],
           ...,
           [-4.6476e-02, -8.5548e-02, -8.1671e-02,  ..., -1.2316e-02,
             2.3720e-02,  2.5891e-03],
           [-7.9118e-03, -4.0907e-02, -9.0682e-02,  ..., -3.6402e-02,
             1.4012e-03, -1.1529e-02],
           [-4.0327e-02, -4.7497e-02, -5.6817e-02,  ..., -1.1304e-02,
             1.4103e-02, -1.6755e-02]],

          ...,

          [[-7.1824e-02, -8.3558e-02, -6.0969e-02,  ..., -3.1534e-02,
             5.8441e-02,  4.9902e-02],
           [-5.4394e-02, -9.7608e-02, -1.1188e-01,  ..., -5.6412e-02,
             1.3519e-01,  1.1633e-01],
           [-2.6096e-02, -2.2610e-02, -1.3835e-02,  ...,  3.4550e-02,
             2.0898e-01,  1.6247e-01],
           ...,
           [-2.9306e-03,  2.2745e-02,  4.1931e-02,  ...,  5.7627e-02,
             1.1362e-01,  6.5168e-02],
           [ 3.3599e-03,  1.8140e-02,  3.4065e-02,  ...,  1.5860e-02,
             4.4836e-02,  2.5481e-02],
           [-1.0852e-02, -1.6917e-02, -8.4206e-03,  ..., -2.0341e-02,
            -7.6384e-03, -1.5975e-02]],

          [[-9.4794e-02, -9.0133e-02, -2.8065e-02,  ..., -2.7000e-02,
            -6.5505e-02, -7.7891e-02],
           [-2.9906e-02,  2.4624e-03,  6.2037e-02,  ...,  2.1808e-02,
            -3.5462e-02, -6.9783e-02],
           [-5.9355e-03,  1.2592e-02,  2.6404e-02,  ...,  6.4637e-02,
             6.1290e-02, -1.7846e-02],
           ...,
           [-5.3652e-02, -4.5677e-02, -4.0731e-02,  ..., -1.8724e-02,
            -2.1224e-03, -2.1797e-02],
           [-6.4489e-02, -6.2902e-02, -2.7807e-02,  ..., -4.3309e-03,
            -6.6434e-02, -7.2191e-02],
           [-5.5928e-02, -7.3513e-02, -6.4857e-02,  ..., -4.5293e-02,
            -8.1454e-02, -7.0142e-02]],

          [[ 1.5675e-02,  9.0438e-02,  8.0371e-02,  ...,  2.1300e-02,
            -2.8058e-02, -7.7982e-02],
           [ 5.9975e-02,  9.8272e-02,  6.5212e-02,  ...,  5.1632e-02,
            -3.6335e-02, -9.9438e-02],
           [ 4.6650e-02,  3.0553e-02, -5.7419e-03,  ...,  2.3345e-02,
            -5.8012e-02, -1.1471e-01],
           ...,
           [ 1.1716e-02, -2.0707e-02, -2.9558e-02,  ...,  2.8098e-02,
            -3.2145e-03, -7.5852e-02],
           [-3.7559e-02, -3.7850e-02, -9.6232e-03,  ...,  3.5433e-02,
            -1.7212e-02, -7.3634e-02],
           [-4.4100e-02, -2.9511e-02, -2.4186e-03,  ..., -1.3369e-02,
            -6.6702e-02, -9.5514e-02]]]], device=&#39;cuda:0&#39;,
        grad_fn=&lt;CudnnConvolutionBackward&gt;)]
</code></pre></div>
<h1 id="transfer-learning">Transfer Learning</h1>
<h2 id="input-shapes-importance-in-transfer-learning">Input Shape's importance in Transfer Learning</h2>
<p><a href="https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py">1. torchvision.models.vgg.py</a></p>
<p><a href="https://stackoverflow.com/questions/55810665/changing-input-dimension-for-alexnet">2. changing-input-dimension-for-alexnet</a></p>
<p><a href="https://stats.stackexchange.com/questions/388859/is-it-possible-to-give-variable-sized-images-as-input-to-a-convolutional-neural">3. is-it-possible-to-give-variable-sized-images-as-input-to-a-convolutional-neural</a></p>
<h3 id="vgg16">VGG16</h3>
<p>We use an extremely simple tranfer learning model from <code>torchvision.models</code> and use this as a vanilla example to understand our problem statement. One should understand one of the fundamental reason why we use transfer learning is because the model is already pre-trained on millions of images; this is often the case as we usually benchmark our performance on model that are trained on <code>imagenet</code>. However, problem arises as we try to transfer our learned weights and layers from the said model, to our own custom dataset. Why? We will unveil the mystery soon, but first keep in mind two important concepts:</p>
<ol>
<li>
<p>Convolutional Layers are independent of the input size/shape.</p>
</li>
<li>
<p>Dense or Fully Connected Layers are dependent on the input size/shape.</p>
</li>
<li>
<p>Conclusion: As long as the pretrained model has Dense/FC layers, then how do we reconcile the fact that our input shape may be different from the ones that were trained on?</p>
</li>
</ol>
<p>Below: I present the source code of <code>vgg16</code> and we will use it later.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="c1"># from .utils import load_state_dict_from_url</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">cast</span>

<span class="n">model_urls</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;vgg11&#39;</span><span class="p">:</span> <span class="s1">&#39;https://download.pytorch.org/models/vgg11-bbd30ac9.pth&#39;</span><span class="p">,</span>
    <span class="s1">&#39;vgg13&#39;</span><span class="p">:</span> <span class="s1">&#39;https://download.pytorch.org/models/vgg13-c768596a.pth&#39;</span><span class="p">,</span>
    <span class="s1">&#39;vgg16&#39;</span><span class="p">:</span> <span class="s1">&#39;https://download.pytorch.org/models/vgg16-397923af.pth&#39;</span><span class="p">,</span>
    <span class="s1">&#39;vgg19&#39;</span><span class="p">:</span> <span class="s1">&#39;https://download.pytorch.org/models/vgg19-dcbb9e9d.pth&#39;</span><span class="p">,</span>
    <span class="s1">&#39;vgg11_bn&#39;</span><span class="p">:</span> <span class="s1">&#39;https://download.pytorch.org/models/vgg11_bn-6002323d.pth&#39;</span><span class="p">,</span>
    <span class="s1">&#39;vgg13_bn&#39;</span><span class="p">:</span> <span class="s1">&#39;https://download.pytorch.org/models/vgg13_bn-abd245e5.pth&#39;</span><span class="p">,</span>
    <span class="s1">&#39;vgg16_bn&#39;</span><span class="p">:</span> <span class="s1">&#39;https://download.pytorch.org/models/vgg16_bn-6c64b313.pth&#39;</span><span class="p">,</span>
    <span class="s1">&#39;vgg19_bn&#39;</span><span class="p">:</span> <span class="s1">&#39;https://download.pytorch.org/models/vgg19_bn-c79401a0.pth&#39;</span><span class="p">,</span>
<span class="p">}</span>


<span class="n">cfgs</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;A&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">],</span>
    <span class="s1">&#39;B&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">],</span>
    <span class="s1">&#39;D&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">],</span>
    <span class="s1">&#39;E&#39;</span><span class="p">:</span> <span class="p">[</span><span class="mi">64</span><span class="p">,</span> <span class="mi">64</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">],</span>
<span class="p">}</span>


<span class="k">def</span> <span class="nf">make_layers</span><span class="p">(</span><span class="n">cfg</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]],</span> <span class="n">batch_norm</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">:</span>
    <span class="n">layers</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">]</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">in_channels</span> <span class="o">=</span> <span class="mi">3</span>
    <span class="k">for</span> <span class="n">feature_map_type</span> <span class="ow">in</span> <span class="n">cfg</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">feature_map_type</span> <span class="o">==</span> <span class="s1">&#39;MaxPool&#39;</span><span class="p">:</span>
            <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">feature_map_type</span> <span class="o">=</span> <span class="n">cast</span><span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">feature_map_type</span><span class="p">)</span>
            <span class="n">conv2d</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="n">feature_map_type</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">batch_norm</span><span class="p">:</span>
                <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">(</span><span class="n">feature_map_type</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">layers</span> <span class="o">+=</span> <span class="p">[</span><span class="n">conv2d</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)]</span>
            <span class="n">in_channels</span> <span class="o">=</span> <span class="n">feature_map_type</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">layers</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">VGG</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">features</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
        <span class="n">init_weights</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VGG</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="c1"># Feature Maps, where the layers here are mostly Conv2d, serving as a feature extractor.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="c1"># AdaptiveAvgPool2d ensures that whatever your input image size is, it will come out the same output before it cotorch.nnects to the dense layer.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>
        <span class="c1"># Classifier Layers, usually the densely fully cotorch.nnected layers whereby your prediction is being made.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="mi">4096</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(),</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">init_weights</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_neurons</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">feature_map_output_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">)</span>
        <span class="n">adaptive_pool_output_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">feature_map_output_neurons</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Before Flattening Shape </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">adaptive_pool_output_neurons</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
        <span class="c1"># flatten vs view, I think around the same.</span>
        <span class="n">flattened_neurons</span> <span class="o">=</span> <span class="n">adaptive_pool_output_neurons</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">adaptive_pool_output_neurons</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1">#flattened_neurons = torch.flatten(adaptive_pool_output_neurons, 1)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;After Flattening Shape </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">flattened_neurons</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
        <span class="n">output_logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">flattened_neurons</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">output_logits</span>

    <span class="k">def</span> <span class="nf">_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_out&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_vgg</span><span class="p">(</span><span class="n">arch</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">cfg</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_norm</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VGG</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">&#39;init_weights&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">VGG</span><span class="p">(</span><span class="n">make_layers</span><span class="p">(</span><span class="n">cfgs</span><span class="p">[</span><span class="n">cfg</span><span class="p">],</span> <span class="n">batch_norm</span><span class="o">=</span><span class="n">batch_norm</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">pretrained</span><span class="p">:</span>
        <span class="n">state_dict</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load_state_dict_from_url</span><span class="p">(</span><span class="n">model_urls</span><span class="p">[</span><span class="n">arch</span><span class="p">],</span>
                                              <span class="n">progress</span><span class="o">=</span><span class="n">progress</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">state_dict</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

<span class="k">def</span> <span class="nf">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">VGG</span><span class="p">:</span>
<span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;VGG 16-layer model (configuration &quot;D&quot;)</span>
<span class="sd">    `&quot;Very Deep Convolutional Networks For Large-Scale Image Recognition&quot; &lt;https://arxiv.org/pdf/1409.1556.pdf&gt;`._</span>
<span class="sd">    Args:</span>
<span class="sd">        pretrained (bool): If True, returns a model pre-trained on ImageNet</span>
<span class="sd">        progress (bool): If True, displays a progress bar of the download to stderr</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">_vgg</span><span class="p">(</span><span class="s1">&#39;vgg16&#39;</span><span class="p">,</span> <span class="s1">&#39;D&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</code></pre></div>
<ol>
<li>These are the last few fully connected layers of VGG16, <code>Sequential</code> in this manner means that, we have the first linear layer where the tensor inputs called <span class="arithmatex">\(x\)</span> will go through a linear transformation <span class="arithmatex">\(z=w^T \cdot x+b\)</span>, then apply an <code>activation</code> function <span class="arithmatex">\(a=\text{ReLU}(z)\)</span> such as <code>ReLU</code> , and lastly apply a dropout to make the tensor <span class="arithmatex">\(a\)</span> to have 0s randomly - for every value <span class="arithmatex">\(t \in a\)</span>, with a probability <span class="arithmatex">\(p\)</span>, set <span class="arithmatex">\(t=0\)</span>. <div class="highlight"><pre><span></span><code>nn.Sequential(
            nn.Linear(512 * 7 * 7, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, 4096),
            nn.ReLU(True),
            nn.Dropout(),
            nn.Linear(4096, num_classes),
        )
</code></pre></div>
</li>
</ol>
<div class="highlight"><pre><span></span><code><span class="c1"># NOT RECOMMENDED, using the source code&#39;s method is better.</span>
<span class="k">class</span> <span class="nc">VGG16</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">init_weights</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">VGG16</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv4</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv5</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv6</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv7</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv8</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv9</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv10</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv11</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv12</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv13</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">out_channels</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">3</span><span class="p">),</span> <span class="n">stride</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">),</span> <span class="n">padding</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
        <span class="c1"># Sequential Linear (fully-connected) Layers with affine operations y=Wx+b</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">25088</span><span class="p">,</span><span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span><span class="n">out_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># last layer before softmax - usually called include_top in Keras.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span><span class="n">out_features</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># completed 16 layers, hence the name VGG16</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">(</span><span class="n">inplace</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">init_weights</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_initialize_weights</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_neurons</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span><span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="c1"># note here we are using maxpooling with stride 2 on conv2 layer before we proceed to conv3</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv3</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv4</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv5</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv6</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv7</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv7</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv8</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv9</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv10</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv10</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv11</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv12</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv13</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">padding</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">dilation</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ceil_mode</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv13</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">))</span>
        <span class="c1"># Adaptive Layer</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">)</span>
        <span class="c1"># Flatten</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>
        <span class="c1"># or</span>
        <span class="c1"># input_neurons = torch.view(input_neurons, -1)</span>
        <span class="c1"># Fully Connected Layers Below</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">)))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">activation</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">)))</span>
        <span class="n">input_neurons</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">input_neurons</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">input_neurons</span>

    <span class="k">def</span> <span class="nf">_initialize_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">modules</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">kaiming_normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;fan_out&#39;</span><span class="p">,</span> <span class="n">nonlinearity</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">)</span>
                <span class="k">if</span> <span class="n">m</span><span class="o">.</span><span class="n">bias</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">BatchNorm2d</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
            <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">):</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">normal_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">weight</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>
                <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">init</span><span class="o">.</span><span class="n">constant_</span><span class="p">(</span><span class="n">m</span><span class="o">.</span><span class="n">bias</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div>
<h3 id="nnadaptiveavgpool2d">nn.AdaptiveAvgPool2d</h3>
<p><strong>Reference 2:</strong></p>
<p>As stated in https://github.com/pytorch/vision/releases:</p>
<blockquote>
<p>Since, most of the pretrained models provided in <code>torchvision</code> (the newest version) already added <code>self.avgpool = nn.AdaptiveAvgPool2d((size, size))</code> to resolve the incompatibility with input size. So you don't have to care about it so much.</p>
</blockquote>
<p>Below is the code, very short.</p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">alexnet</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="c1"># replace the last classifier</span>
<span class="n">model</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># now you can trained it with your dataset of size (3, 448, 224)</span>
</code></pre></div>
<h3 id="two-ways-of-transfer-learning">Two ways of Transfer learning</h3>
<p>There are two popular ways to do transfer learning. Suppose that we trained a model <code>M</code> in very large dataset <code>D_large</code>, now we would like to transfer the "knowledge" learned by the model <code>M</code> to our new model, <code>M'</code>, on other datasets such as <code>D_other</code> (which has a smaller size than that of <code>D_large</code>).</p>
<ol>
<li>
<p>Use (most) parts of <code>M</code> as the architecture of our new <code>M'</code> and initialize those parts with the weights trained on <code>D_large</code>. We can start training the model <code>M'</code> on the dataset <code>D_other</code> and let it learn the weights of those above parts from <code>M</code> to find the optimal weights on our new dataset. This is usually referred as fine-tuning the model <code>M'</code>. </p>
</li>
<li>
<p>Same as the above method except that before training <code>M'</code> we freeze all the parameters of those parts and start training <code>M'</code> on our dataset <code>D_other</code>. In both cases, those parts from <code>M</code> are mostly the first components in the model <code>M'</code> (the base). However, in this case, we refer those parts of <code>M</code> as the model to extract the features from the input dataset (or feature extractor). The accuracy obtained from the two methods may differ a little to some extent. However, this method guarantees the model doesn't overfit on the small dataset. It's a good point in terms of accuracy. On the other hands, when we freeze the weights of <code>M</code>, we don't need to store some intermediate values (the hidden outputs from each hidden layer) in the forward pass and also don't need to compute the <code>gradients</code> during the backward pass. This improves the speed of training and reduces the memory required during training. </p>
</li>
</ol>
<h3 id="the-implementation">The implementation</h3>
<p>Along with <code>Alexnet</code>, a lot of pretrained models on ImageNet is already provided by Facebook team such as ResNet, VGG. </p>
<p>To fit your requirements the most in the aspect of model size, it would be nice to use VGG11, and ResNet which have fewest parameters in their model family.</p>
<p>I just pick VGG11 as an example:</p>
<ol>
<li>Obtain a pretrained model from <code>torchvision</code>.</li>
<li>Freeze the all the parameters of this model.</li>
<li>Replace the last layer in the model by your new <code>Linear</code> layer to perform your classification. This means that you can reuse all most everything of <code>M</code> to <code>M'</code>. </li>
</ol>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torchvision</span>

<span class="c1"># obtain the pretrained model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vgg11</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="c1"># freeze the params</span>
<span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># replace with your classifier</span>
<span class="n">num_classes</span> <span class="o">=</span> <span class="mi">8</span>
<span class="n">net</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="mi">6</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">in_features</span><span class="o">=</span><span class="mi">4096</span><span class="p">,</span> <span class="n">out_features</span><span class="o">=</span><span class="n">num_classes</span><span class="p">)</span>

<span class="c1"># start training with your dataset</span>
</code></pre></div>
<h3 id="warnings">Warnings</h3>
<p>In the old <code>torchvision</code> package version, there is no <code>self.avgpool = nn.AdaptiveAvgPool2d((size, size))</code> which makes harder to train on our input size which is different from <code>[3, 224, 224]</code> used in training ImageNet. You can do a little effort as below:</p>
<p><div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">OurVGG11</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">OurVGG11</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vgg11</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">vgg11</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">vgg11</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
            <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="c1"># Add a avgpool here</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">AdaptiveAvgPool2d</span><span class="p">((</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">))</span>

        <span class="c1"># Replace the classifier layer</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">vgg11</span><span class="o">.</span><span class="n">classifier</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4096</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vgg11</span><span class="o">.</span><span class="n">features</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">avgpool</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">512</span> <span class="o">*</span> <span class="mi">7</span> <span class="o">*</span> <span class="mi">7</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">vgg11</span><span class="o">.</span><span class="n">classifier</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">OurVGG11</span><span class="p">()</span>

<span class="c1"># now start training `model` on our dataset.</span>
</code></pre></div>
Try out with different models in <code>torchvision.models</code>.</p>
<p><strong>Reference 3:</strong></p>
<p>The convolutional layers and pooling layers themselves are independent of the input dimensions. However, the output of the convolutional layers will have different spatial sizes for differently sized images, and this will cause an issue if we have a fully connected layer afterwards (since our fully connected layer requires a fixed size input). There are several solutions to this:</p>
<p><strong>1. Global Pooling:</strong> Avoid fully connected layers at the end of the convolutional layers, and instead use pooling (such as Global Average Pooling) to reduce your feature maps from a shape of (N,H,W,C) (before global pool) to shape (N,1,1,C) (after global pool), where:<br><br>
N = Number of minibatch samples<br>
H = Spatial height of feature map<br>
W = Spatial width of feature map<br>
C = Number of feature maps (channels)<br><br>
As can be seen, the output dimensionality (N*C) is now independent of the spatial size (H,W) of the feature maps. In case of classification, you can then proceed to use a fully connected layer on top to get the logits for your classes.<br><br></p>
<p><strong>2. Variable sized pooling:</strong> Use variable sized pooling regions to get the same feature map size for different input sizes.
<br><br></p>
<p><strong>3. Crop/Resize/Pad input images:</strong> You can try to rescale/crop/pad your input images to all have the same shape.
<br><br></p>
<hr>
<p>In the context of transfer learning, you might want to use differently sized inputs than the original inputs that the model was trained with. Here are some options for doing so:<br><br></p>
<p><strong>4. Create new fully connected layers:</strong> You can ditch the original fully connected layers completely and initialize a new fully connected layer with the dimensionality that you need, and train it from scratch.<br><br></p>
<p><strong>5. Treat the fully connected layer as a  convolution:</strong> Normally, we reshape the feature maps from (N,H,W,C) to (N,H*W*C) before feeding it to the fully connected layer. But you can also treat the fully connected layer as a convolution with a receptive field of (H,W). Then, you can just convolve this kernel with your feature maps regardless of their size (use zero padding if needed) [http://cs231n.github.io/transfer-learning/ ].</p>
<p><strong>Reference Hongnan (My own interpretation):</strong></p>
<p>The convolutional and pooling layers in a CNN network are independent of the image size (input shape), this is because the weights of each convolutional layers are calculated only on the number of filters (out_channels). Please refer to my image in Deep Learning Notes on how to calculate number of parameters (which is the number of weights). It is as simple as </p>
<div class="arithmatex">\[f^{\ell} \times f^{\ell} \times n_{c}^{\ell-1} \times n_{c}^{\ell} + n_{b}^{\ell}\]</div>
<p>where we denote </p>
<p><span class="arithmatex">\(f^{\ell} = \text{filter size in current layer}\)</span></p>
<p><span class="arithmatex">\(n_{c}^{\ell-1} = \text{number of filters/channels in previous layer}\)</span></p>
<p><span class="arithmatex">\(n_{c}^{\ell} = \text{number of filters in current layer}\)</span></p>
<p><span class="arithmatex">\(n_{b}^{\ell} = \text{number of bias in current layer}\)</span></p>
<p>So one can simply calculate the first layer's paramaters/weights as follows:</p>
<div class="arithmatex">\[\text{number of weights/paramaters} = 3\times 3 \times 3 \times 64 + 64 = 1792\]</div>
<p>and for the second layer it is:</p>
<div class="arithmatex">\[\text{number of weights/paramaters} = 3\times 3 \times 64 \times 64 + 64 = 36928\]</div>
<p>What I did just now is to make a point that when we calculate the weights/paramaters of each CNN layer, there is absolutely no input shape or image size involved. Thus, the implication is that the number of weights of a CNN layer is <strong>invariant of the input shape</strong>. However, the output shape of each CNN layer is not the same for varying image size, and this will pose a problem - which will be explained in the next part. Before we go, take a moment to run the code below and see that for 2 different input shape 224 vs 512 and you see the only changes are the output shape, the number of weights and parameters are not changed.</p>
<div class="highlight"><pre><span></span><code><span class="n">vgg16_hn</span> <span class="o">=</span> <span class="n">vgg16</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span><span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">twotwofour</span> <span class="o">=</span> <span class="n">torchsummary_wrapper</span><span class="p">(</span><span class="n">vgg16_hn</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="mi">224</span><span class="p">,</span><span class="mi">224</span><span class="p">))</span>
<span class="n">fiveonetwo</span> <span class="o">=</span> <span class="n">torchsummary_wrapper</span><span class="p">(</span><span class="n">vgg16_hn</span><span class="p">,</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">))</span>
</code></pre></div>
<p>The output of the convolutional layers will have different spatial sizes for differently sized images, and this will cause an issue if we have a fully connected layer afterwards (since our fully connected layer requires a fixed size input). So for example <strong>VGG16</strong> which is pretrained on <code>imagenet</code> with image sizes of 224x224, then when you load the <code>state dict</code>, the number of weights and parameters are already fixed. To be more verbose, the number of weights for the convolutional layers stay the same for any input image size, but the fully connected layers will not. For example, in the native resolution of 224x224, the layer before the fully connected layer is a convolutional layer and subsequent pooling layer - which has an output shape of <code>(-1, 512, 7, 7)</code>. We need to flatten this pooling layer into a dense layer first, one can imagine in a 3-dimensional perpective that we squashed a pool of 3-dimensional neurons into a vertical fully connected neurons. Refer to this image: </p>
<p>Now, some intuition needs to be provided here, for the absent minded (me), look further after the image pasted above for the math behind weights (pages after). </p>
<p>Continuing above, we know that the learnable weights of the flattened layer is <span class="arithmatex">\(512\times 7\times 7 = 25088\)</span>, and since we are connected to a pre-defined fully connected layer of 4096 neurons, then it follows that in this very fully connected layer, we will output <span class="arithmatex">\(<span class="arithmatex">\(25088\times 4096 + 4096 = 102764544\)</span>\)</span> weights. This is a fixed number and will change if you change the image input size.</p>
<p>For example, if I were to input a 512x512 image, see the code above, then the previous layer before the fully connected layer is actually <code>[-1, 512, 16, 16]</code> which is not the same as <span class="arithmatex">\(512\times 7 \times 7\)</span>. This will lead to our weights mismatched at the fully connected layer. So we can solve this problem by using <code>nn.AdaptiveAvgPooling</code>.</p>
<div class="highlight"><pre><span></span><code><span class="n">display_image</span><span class="p">(</span><span class="n">config</span><span class="p">,</span> <span class="n">page_num</span> <span class="o">=</span> <span class="s1">&#39;Deep learning-17.jpg&#39;</span><span class="p">)</span>
</code></pre></div>
<p><img alt="jpeg" src="../Deep_Learning_Notes_%28Important%29_files/Deep_Learning_Notes_%28Important%29_40_0.jpg" /></p>
<p>Side note: by fixing the <code>seed</code>, you will get deterministic results for every re-run of the model. For example, if I want to compare two implementations of <code>vgg16</code>, namely, <code>vgg16v1</code> and <code>vgg16v2</code> and see if they give deterministic outputs, then one should notrun <code>vgg16v1(rand_tensor)</code> and <code>vgg16v2(rand_tensor)</code> at the same time even though you would expect they yield the same results - since we are forward passing the <code>rand_tensor</code> across a fixed set of pretrained weights. But calling it twice in one run will indicate it's called twice, so to check if they really output the same tensor (deterministic), you need to run them on 2 separate runs.</p>
<h1 id="high-level-code-overview-on-image-classification">High Level Code Overview on Image Classification</h1>
<h1 id="tips-and-tricks-to-speed-up-training-in-pytorch">Tips and Tricks to speed up Training in PyTorch</h1>
<p><a href="https://efficientdl.com/faster-deep-learning-in-pytorch-a-guide/">1. Absolutely amazing article on speeding up training in PyTorch plus good practices</a></p>
<p>The wholesome article below is entirely based on this amazing article, and all credits should go to him. I did, however, repackaged it and included more details.</p>
<h2 id="the-choice-of-learning-rate-scheduler-matters">The choice of Learning Rate Scheduler Matters!</h2>
<p><a href="https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8">Hyper-parameter Tuning Techniques in Deep Learning</a></p>
<p><a href="https://github.com/davidtvs/pytorch-lr-finder">PyTorch LR Finder</a></p>
<p>The learning rate of the an optimizer has a large impact on the speed of convergence as well as the generalization performance of your model. This is why in almost all the cases, a learning rate scheduler is used in training as well.</p>
<p><strong>Cyclical Learning Rate</strong> and the <strong>One Cycle Learning Rate</strong> schedulers are both methods introduced by Leslie N. Smith (<a href="https://arxiv.org/pdf/1506.01186.pdf">here</a> and <a href="https://arxiv.org/abs/1708.07120">here</a>), and then popularised by fast.ai's Jeremy Howard and Sylvain Gugger (<a href="https://www.fast.ai/2018/07/02/adam-weight-decay/">here</a> and <a href="https://github.com/sgugger/Deep-Learning/blob/master/Cyclical%20LR%20and%20momentums.ipynb">here</a>). Essentially, the <strong>One Cycle Learning Rate</strong> scheduler looks something like this:</p>
<p><img alt="image info" src="https://github.com/ghnreigns/Deep-Learning-Notes/blob/main/pictures/one_cycle_lr.png?raw=1" /></p>
<p>Sylvain writes:</p>
<blockquote>
<p>[Onecycle consists of]  two steps of equal lengths, one going from a
lower learning rate to a higher one than go back to the minimum. The
maximum should be the value picked with the Learning Rate Finder, and
the lower one can be ten times lower. Then, the length of this cycle
should be slightly less than the total number of epochs, and, in the
last part of training, we should allow the learning rate to decrease
more than the minimum, by several orders of magnitude.</p>
</blockquote>
<p>In the best case this schedule achieves a massive speed-up – what Smith calls Superconvergence – as compared to conventional learning rate schedules. Using the 1Cycle policy he needs ~10x fewer training iterations of a ResNet-56 on ImageNet to match the performance of the original paper, for instance). The schedule seems to perform robustly well across common architectures and optimizers.</p>
<p>PyTorch implements both of these methods <code>torch.optim.lr_scheduler.CyclicLR</code> and <code>torch.optim.lr_scheduler.OneCycleLR</code>, see the <a href="https://pytorch.org/docs/stable/optim.html">documentation</a>.</p>
<p>One drawback of these schedulers is that they introduce a number of additional hyperparameters. <a href="https://towardsdatascience.com/hyper-parameter-tuning-techniques-in-deep-learning-4dad592c63c8">hyper-parameter-tuning-techniques-in-deep-learning</a> and <a href="https://github.com/davidtvs/pytorch-lr-finder">PyTorch learning rate finder</a>, offer a nice overview and implementation of how good hyper-parameters can be found including the Learning Rate Finder mentioned above. In conclusion, this is related to hyper-parameter tuning and should not be neglected.</p>
<p>Why does this work? It doesn't seem entirely clear but one <a href="https://arxiv.org/pdf/1506.01186.pdf">possible explanation</a> might be that regularly increasing the learning rate helps to traverse <a href="https://papers.nips.cc/paper/2015/file/430c3626b879b4005d41b8a46172e0c0-Paper.pdf">saddle points in the loss landscape</a> more quickly.</p>
<h2 id="dataloader-tricks">DataLoader Tricks</h2>
<p>When using <code>torch.utils.data.DataLoader</code>, set <code>num_workers &gt; 0, rather than the default value of 0, and</code>pin_memory=True<code>, rather than the default value of</code>False`. Details of this are explained in <a href="https://pytorch.org/docs/stable/data.html">documentation</a>.</p>
<p><a href="https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/szymon_migacz-pytorch-performance-tuning-guide.pdf">Szymon Micacz</a> achieves a 2x speed-up for a single training epoch by using four workers and pinned memory.</p>
<p>A <a href="https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/5">rule of thumb</a> that people are using to choose the number of workers is to set it to four times the number of available GPUs with both a larger and smaller number of workers leading to a slow down.</p>
<p>Note that increasing num_workers will increase your CPU memory consumption.</p>
<h2 id="batch-size">Batch Size</h2>
<p>This is a somewhat contentious point. Generally, however, it seems like using the largest batch size your GPU memory permits will accelerate your training (see <a href="https://nvlabs.github.io/eccv2020-mixed-precision-tutorial/files/szymon_migacz-pytorch-performance-tuning-guide.pdf">NVIDIA's Szymon Migacz</a>, for instance). Note that you will also have to adjust other hyperparameters, such as the learning rate, if you modify the batch size. A rule of thumb here is to double the learning rate as you double the batch size.</p>
<p><a href="https://arxiv.org/pdf/1812.06162.pdf">OpenAI has a nice empirical paper</a> on the number of convergence steps needed for different batch sizes. <a href="https://towardsdatascience.com/implementing-a-batch-size-finder-in-fastai-how-to-get-a-4x-speedup-with-better-generalization-813d686f6bdf">Daniel Huynh</a> runs some experiments with different batch sizes (also using the 1Cycle policy discussed above) where he achieves a 4x speed-up by going from batch size 64 to 512.</p>
<p>One of the <a href="https://arxiv.org/pdf/1609.04836.pdf">downsides</a> of using large batch sizes, however, is that they might lead to solutions that generalize worse than those trained with smaller batches.</p>
<h2 id="use-automatic-mixed-precision-amp">Use Automatic Mixed Precision (AMP)</h2>
<p><a href="https://pytorch.org/docs/stable/notes/amp_examples.html">PyTorch Documentation Examples</a></p>
<p>The release of PyTorch 1.6 included a native implementation of Automatic Mixed Precision training to PyTorch. The main idea here is that certain operations can be run faster and without a loss of accuracy at semi-precision (FP16) rather than in the single-precision (FP32) used elsewhere. AMP, then, automatically decide which operation should be executed in which format. This allows both for faster training and a smaller memory footprint.</p>
<p>To be very honest with you, many people use AMP wrongly, so I am very confused at who to follow, so usually I try to follow documentation, or people on Kaggle.</p>
<h1 id="dissecting-the-train_one_epoch-code">Dissecting the train_one_epoch code</h1>
<p>PyTorch <strong>1.7</strong></p>
<h2 id="modeltrain-and-modeleval">model.train() and model.eval()</h2>
<ul>
<li><code>model.train()</code> and <code>model.eval()</code></li>
</ul>
<p><code>model.train()</code> tells your model that you are training the model. So effectively layers like <code>dropout</code>, <code>batchnorm</code> etc, which behave differently on the train and test procedures know what is going on and hence can behave accordingly. More details: It sets the mode to train (see <a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/module.html#Module.train">source code</a>). You can call either <code>model.eval()</code> or <code>model.train(mode=False)</code> to tell that you are testing/evaluating. It is somewhat intuitive to expect train function to train model but it does not do that. It just sets the mode. In case of <code>model.train()</code> the model knows it has to learn the layers and when we use <code>model.eval()</code> it indicates the model that nothing new is to be learnt and the model is used for testing. </p>
<p><a href="https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch">Reference 1</a> </p>
<p><a href="https://medium.com/jun-devpblog/pytorch-6-model-train-vs-model-eval-no-grad-hyperparameter-tuning-3812c216a3bd">Reference 2</a></p>
<h2 id="todevice">to(device)</h2>
<ul>
<li><code>to(device)</code></li>
</ul>
<p>First you have to set <code>device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')</code> to define your device, whether you are equipping your tensors/model on GPU/CPU. Subsequently, you can use the <code>tensor.to(device)</code> command to move a tensor to a device (either GPU or CPU). </p>
<div class="highlight"><pre><span></span><code>    for step, (images, labels, img_ids) in enumerate(sample_loader):
        # print(&#39;Before to device, image tensor is\n&#39;, images)
        # print(&#39;Before to device, labels tensor is\n&#39;, labels)
        images = images.to(device)
        labels = labels.to(device)
</code></pre></div>
<p>When you <code>print(images)</code>, the output tensors will end with <code>cuda:0</code> to signify you have moved your tensors to GPU. </p>
<p>Common Error: RuntimeError: <code>Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same</code>. You get this error because your <code>model</code> is on the GPU, but your <code>data/images/label tensors</code> are on the CPU. So, you need to send your input tensors to the GPU. Alternatively, The same error will be raised if your input tensors are on the GPU but your model weights aren't. In this case, you need to send your model weights to the GPU. So remember to do <code>model.cuda()</code> or <code>model.to(device)</code> as well when you train. In general, both tensors and model should have <code>tensor.to(device)</code> and <code>model.to(device)</code> so that both are synchronized, since <code>device</code> will be a constant variable.</p>
<div class="highlight"><pre><span></span><code>[Reference I on to(device)](https://stackoverflow.com/questions/50954479/using-cuda-with-pytorch)

[Reference II on RunTimeError](https://stackoverflow.com/questions/59013109/runtimeerror-input-type-torch-floattensor-and-weight-type-torch-cuda-floatte)
</code></pre></div>
<h2 id="batch_size">batch_size</h2>
<p><code>batch_size = images.shape[0]</code> vs <code>batch_size = images.shape[0]</code></p>
<p>Do not use <code>batch_size = config.batch_size</code>, this is because if you do not set <code>drop_last=True</code> in the <code>DataLoader</code>, then we will encounter a problem, if the total number of images is 30, and we set our <code>batch_size = 4</code>, then we will run into a problem when we iterate our data into the last iteration - we have only 2 images left, and if we still assume that our <code>batch_size</code> is 4, then our <code>Accuracy Score/Meter</code> will be affected, because those are dependent on the <code>batch_size</code>.</p>
<h2 id="y_predmodelimages">y_pred=model(images)</h2>
<h3 id="definition-of-logits">Definition of logits</h3>
<ul>
<li><code>y_pred = model(images)</code></li>
</ul>
<p><code>y_pred</code> is the value of the logits of a <code>forward</code> pass in the neural network. One would think the last layer in a classification problem would either be the <code>sigmoid</code> or <code>softmax</code> layer, however, <code>y_pred = model(images)</code> does not seem to sum up to 1, which is against the definition of <code>softmax</code>. The reason is because when you call <code>model(images)</code>, you are basically invoking <code>model.forward(images)</code> in the <code>model</code> class you instantiated, and this by default gives you logits, not softmax values.</p>
<p>With reference to <a href="https://discuss.pytorch.org/t/two-output-nodes-for-binary-classification/58703">this</a>: </p>
<p>For a binary classification use case, you could use a single output and a threshold or alternatively you could use a multi-class classification with just two classes, so that each class gets its output neuron. The loss functions for both approaches would be different. In the first case (single output), you would use e.g. <code>nn.BCEWithLogitsLoss</code> and the output tensor shape should match the target shape. In the latter case, you would use e.g. <code>nn.CrossEntropyLoss</code> and the target tensor shape should contain the class indices in the range <code>[0, num_classes-1]</code> and miss the “class dimension” (usually the channel dim). <strong>Both approaches expect logits, so you should remove your <code>softmax</code> layer and just pass the last output to the criterion.</strong> A final linear layer is not strictly necessary, if you make sure to work with the right shapes of your output and target.</p>
<p>So as we can see, the last <code>linear</code> layer of a PyTorch forward pass outputs <strong>logits</strong>, and subsequently, <strong>logits</strong> are expected to be passed in to the <code>loss</code> function.</p>
<p>Also, one reason that I kept forgetting what <code>logits</code> really are is because of my own incompetency, after revising through my notes, I have a better picture now. Referring to the attached images, one should recall there are two steps in each neuron, there should be a <span class="arithmatex">\(z = w^Tx+b\)</span> function where <span class="arithmatex">\(w\)</span> are the weights and <span class="arithmatex">\(x\)</span>, the inputs; further note that the number of weights is equals to the number of neurons in the previous layer; the second step is the activation function <span class="arithmatex">\(a = g(z)\)</span> where <span class="arithmatex">\(g\)</span> is the activation function. So in our scenario, when I get to the last layer, I necessarily thought that the last layer will be a layer with 5 output neurons (we have 5 classes), and each neuron's output should be <span class="arithmatex">\(a = g(z)\)</span> where <span class="arithmatex">\(g\)</span> is the softmax activation function in question. Apparently, I am wrong. In PyTorch, the last layer is only half the story, it stripped off the softmax "portion" and only presents us with the raw <strong>logits</strong>, or in other words, <span class="arithmatex">\(z = w^Tx+b\)</span>; in other words, the raw output of a neural network layer is <strong>the linear combination</strong> of the values that come from the neurons of the previous layer. An mental example is: if the layer before the last <code>linear layer</code> (last layer) has 20 neurons/output values, and my <code>linear layer</code> has 5 outputs/classes, I can expect the output of the <code>linear layer</code> to be an array with 5 values, each of which is the linear combination of the 20 values multiplied by the 20 weights + bias, corresponding to <span class="arithmatex">\(z = w^Tx+b\)</span>, but in vectorized form. These, are called <strong>logits</strong>, the unnormalized final scores of your model, without going through the <code>sotfmax</code> function.</p>
<div class="highlight"><pre><span></span><code>![neural network](https://github.com/ghnreigns/Deep-Learning-Notes/blob/main/images/neural_network_1.jpg?raw=1)
</code></pre></div>
<p>A last note before we proceed is that the input of <code>nn.CrossEntropyLoss</code> mathematically, should be the prediction (the output of model) in probability (not <strong>logits</strong>) and the label. <code>nn.CrossEntropyLoss</code> function in PyTorch will compute the probability of prediction of model automatically. From the <a href="https://pytorch.org/docs/master/_modules/torch/nn/functional.html#cross_entropy">source code</a>, this is confirmed to be true.</p>
<p><a href="https://datascience.stackexchange.com/questions/31041/what-does-logits-in-machine-learning-mean">what-does-logits-in-machine-learning-mean</a></p>
<p><a href="https://discuss.pytorch.org/t/two-output-nodes-for-binary-classification/58703/3">two-output-nodes-for-binary-classification</a></p>
<p><a href="http://seba1511.net/tutorials/beginner/blitz/neural_networks_tutorial.html">neural_networks_tutorial</a></p>
<p><a href="https://stackoverflow.com/questions/64987430/what-exactly-does-the-forward-function-output-in-pytorch?noredirect=1#comment114909082_64987430">what-does-the-forward-function-output-in-pytorch</a>   </p>
<p>Here is an extract of <a href="https://datascience.stackexchange.com/questions/31041/what-does-logits-in-machine-learning-mean">what-does-logits-in-machine-learning-mean</a>:</p>
<p><strong>Logits interpreted to be the unnormalised</strong> (or not-yet normalised) <strong>predictions</strong> (or outputs) <strong>of a model. These can give results, but we don't normally stop with logits, because interpreting their raw values is not easy.</strong></p>
<p>Have a look at <a href="https://pytorch.org/docs/master/autograd.html#torch.Tensor.grad">their definition</a> to help understand how <em>logits</em> are produced.</p>
<h3 id="example-of-logits">Example of logits</h3>
<p>Let me explain with an example:</p>
<p>We want to train a model that learns how to classify cats and dogs, using photos that each contain either one cat or one dog. You build a model give it some of the data you have to approximate a mapping between images and predictions. You then give the model some of the unseen photos in order to test its predictive accuracy on new data. As we have a classification problem (we are trying to put each photo into one of two classes), the model will give us two scores for each input image. A score for how likely it believes the image contains a cat, and then a score for its belief that the image contains a dog.</p>
<p>Perhaps for the first new image, you get logit values out of <code>16.917</code> for a cat and then <code>0.772</code> for a dog. Higher means better, or ('more likely'), so you'd say that a cat is the answer. The correct answer is a cat, so the model worked!</p>
<p>For the second image, the model may say the logit values are 1.004 for a cat and 0.709 for a dog. So once again, our model says we the image contains a cat. The correct answer is once again a cat, so the model worked again!</p>
<p>Now we want to compare the two result. One way to do this is to normalise the scores. That is, <strong>we normalise the logits</strong>! Doing this we gain some insight into the confidence of our model.</p>
<p>Let's using <a href="https://pytorch.org/docs/master/autograd.html#torch.Tensor.requires_grad">the softmax</a>, where all results sum to <code>1</code> and so allow us to think of them as probabilities:</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(\sigma (\mathbf {z} )_{j}={\frac {e^{z_{j}}}{\sum _{k=1}^{K}e^{z_{k}}}} \text{ for } j = 1, …, K.\)</span>\)</span></p>
<p>For the first test image, we get</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(prob(cat) = \frac{exp(16.917)}{exp(16.917) + exp(0.772)} = 0.9999\)</span>\)</span></p>
<p><span class="arithmatex">\(<span class="arithmatex">\(prob(dog) = \frac{exp(0.772)}{exp(16.917) + exp(0.772)} = 0.0001\)</span>\)</span></p>
<p>If we do the same for the second image, we get the results:</p>
<p><span class="arithmatex">\(<span class="arithmatex">\(prob(cat) = \frac{exp(1.004)}{exp(1.004) + exp(0.709)} = 0.5732\)</span>\)</span></p>
<p><span class="arithmatex">\(<span class="arithmatex">\(prob(dog) = \frac{exp(0.709)}{exp(1.004) + exp(0.709)} = 0.4268\)</span>\)</span></p>
<p>The model was not really sure about the second image, as it was very close to 50-50 - a guess!</p>
<p>The last part of the quote from your question likely refers to a neural network as the model. The layers of a neural network commonly take input data, multiply that by some parameters (weights) that we want to learn, then apply a <strong>non-linearity</strong> function, which provides the model with the power to learn non-linear relationships. Without this non-linearity, a neural network would simply be a list of linear operations, performed on some input data, which means it would only be able to learn linear relationships. This would be a massive constraint, meaning the model could always be reduced to a basic linear model.</p>
<p>That being said, it is not considered helpful to apply a non-linearity to the logit outputs of a model, as you are generally going to be cutting out some information, right before a final prediction is made. Have a look for <a href="https://stats.stackexchange.com/questions/163695/non-linearity-before-final-softmax-layer-in-a-convolutional-neural-network">related comments in this thread</a>.</p>
<h2 id="criterionloss-function">Criterion/Loss Function</h2>
<ul>
<li><code>criterion  = torch.nn.CrossEntropyLoss()</code>: </li>
</ul>
<p>This loss function is defined such that the input has to be a <code>Tensor</code> of size either <code>(minibatch, C)</code> or <code>(minibatch,C,d_1, d_2, ..., d_K)</code> with <span class="arithmatex">\(K \geq 1\)</span> for the K-dimensional case. But in this case it is <code>(minibatch, C)</code> where if your <code>minibatch</code> refers to your batch size, in our example the <code>minibatch = 4</code>, and class number <code>C = 5</code>. Also the expected inputs are the logits/outputs made by the model and the target labels both in Tensor format as shown in the source code: <code>def forward(self, input: Tensor, target: Tensor) -&gt; Tensor</code>; and also the input (logits/outputs of the model) is expected to contain raw, unnormalized scores for each class. </p>
<h2 id="lossesupdatelossitem-batch_size">losses.update(loss.item(), batch_size)</h2>
<ul>
<li><code>losses.update(loss.item(), batch_size)</code></li>
</ul>
<p>In fitting a neural network, backpropagation computes the gradient of the loss function with respect to the weights of the network for a single input–output or for a mini-batch of input-output (which is usually the case). So, next up is the <code>loss = criterion(y_preds, labels)</code> where we calculate the loss at the end of one forward pass. If our <code>DataLoader</code> has 24 images, and <code>batch_size=4</code> then there are <span class="arithmatex">\(\frac{24}{4} = 6\)</span> forward passes.</p>
<p>Something else you need to know here is <code>loss.item()</code>. In documentation, the <code>loss</code> or <code>loss.item()</code> (both are the same) given by <a href="https://pytorch.org/docs/stable/nn.html#torch.nn.CrossEntropyLoss"><code>CrossEntropy</code></a> or other loss functions are averaged across observations for each minibatch i.e. the reduction parameter in the loss function is <code>mean</code> by default. Therefore, for each forward pass, the <code>loss</code> or <code>loss.item()</code> you get is <strong>NOT the SUM of the LOSS of the 4 logits/outputs</strong>. Instead, <code>loss.item()</code> contains the loss of the entire mini-batch, but divided by the batch size. Which basically means the average loss. </p>
<div class="highlight"><pre><span></span><code>In the great example of [Transfer Learning from PyTorch](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html), it says:

    for ...:
        ...
        running_loss += loss.item() * inputs.size(0)
        running_corrects += torch.sum(preds == labels.data)
    if phase == &#39;train&#39;:
        scheduler.step()

    epoch_loss = running_loss / dataset_sizes[phase]
</code></pre></div>
<p><code>running_loss += loss.item() * inputs.size(0)</code> is saying that for each minibatch of 4 (since <code>batch_size=4</code> here), we calculate the <code>running_loss</code> to be the sum of the total loss of the 4 logits/outputs. Why is this important? Because, after each epoch, say after 6 forward passes (assuming 24 total images), we want to print out the <code>train_one_epoch_avg_loss</code> to be the <code>running_loss</code> (now this value holds the total loss for all 24 logits/outputs since the epoch is finished), divided by the total number of images in the <code>DataLoader</code>, in our case is 24, which is represented by <code>dataset_sizes['train']</code> in the example here. However, in general, we tend to use <code>AverageMeter()</code> to update and record our <code>loss</code> - something I learnt from Kaggle.</p>
<div class="highlight"><pre><span></span><code>[torch.nn.CrossEntropyLoss](https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html)

[Reference on loss.item()](https://stackoverflow.com/questions/61092523/what-is-running-loss-in-pytorch-and-how-is-it-calculated)

[what-is-running-loss-in-pytorch-and-how-is-it-calculated](https://stackoverflow.com/questions/61092523/what-is-running-loss-in-pytorch-and-how-is-it-calculated)
</code></pre></div>
<h2 id="averagelossmeter">AverageLossMeter</h2>
<ul>
<li><code>AverageLossMeter</code></li>
</ul>
<p>Now comes the <code>AverageLossMeter</code> class.</p>
<div class="highlight"><pre><span></span><code>    class AverageLossMeter:
        &quot;&quot;&quot;
        Computes and stores the average and current loss
        &quot;&quot;&quot;
        def __init__(self):
            self.reset()

        def reset(self):
            self.curr_batch_avg_loss = 0
            self.running_avg_loss = 0
            self.running_total_loss = 0
            self.count = 0

        def update(self, curr_batch_avg_loss, batch_size: str):
            self.curr_batch_avg_loss = curr_batch_avg_loss
            self.running_total_loss += curr_batch_avg_loss * batch_size
            self.count += batch_size
            self.running_avg_loss = self.running_total_loss / self.count


current batch average loss 1.5807217359542847  running total loss 6.322886943817139   accumalated number of images 4  running average loss 1.5807217359542847



current batch average loss 1.7063219547271729  running total loss 13.14817476272583   accumalated number of images 8  running average loss 1.6435218453407288



current batch average loss 1.6727746725082397  running total loss 19.83927345275879   accumalated number of images 12  running average loss 1.6532727877298992



current batch average loss 1.4499537944793701  running total loss 25.63908863067627   accumalated number of images 16  running average loss 1.6024430394172668



current batch average loss 1.6343439817428589  running total loss 32.176464557647705   accumalated number of images 20  running average loss 1.6088232278823853



current batch average loss 1.5512468814849854  running total loss 38.38145208358765   accumalated number of images 24  running average loss 1.5992271701494853
</code></pre></div>
<h2 id="lossbackward">loss.backward()</h2>
<h3 id="definition-of-backpropagation">Definition of backpropagation</h3>
<ul>
<li><code>loss.backward()</code> </li>
</ul>
<p>Refer to example below and <a href="https://stackoverflow.com/questions/53975717/pytorch-connection-between-loss-backward-and-optimizer-step">pytorch - connection between loss.backward() and optimizer.step()</a> and <a href="https://stackoverflow.com/questions/55543786/understanding-gradient-in-pytorch?rq=1">understanding-gradient-in-pytorch</a>. Backpropagation is based on the chain-rule for calculating derivatives. This means the gradients are computed step-by-step from tail to head and always passed back to the previous step ("previous" w.r.t. to the preceding forward pass). For scalar output the process is initiated by assuming a gradient of d (out1) / d (out1) = 1 to start the process. If you're calling backward on a (non-scalar) tensor though you need to provide the initial gradient since it is not unambiguous. Let's look at an example that involves more steps to compute the output:</p>
<p><code>loss.backward()</code> computes <span class="arithmatex">\(\dfrac{\text{d(loss)}}{dx}\)</span> for every parameter <code>x</code> which has <code>requires_grad=True</code>. These are accumulated into <code>x.grad</code> for every parameter <code>x</code>. In pseudo-code:</p>
<div class="highlight"><pre><span></span><code>`x.grad += dloss/dx`

`optimizer.step` updates the value of `x` using the gradient `x.grad`. For example, the SGD optimizer performs:

`x = x - lr * x.grad`

`optimizer.zero_grad()` clears `x.grad` for every parameter `x` in the optimizer. It’s important to call this before `loss.backward()`, otherwise you’ll accumulate the gradients from multiple passes.

If you have multiple losses (loss1, loss2) you can sum them and then call backwards once:

`loss3 = loss1 + loss2`

`loss3.backward()`

[Reference I](https://discuss.pytorch.org/t/what-does-the-backward-function-do/9944/18)

[Computation of loss.backward()](https://stackoverflow.com/questions/57248777/backward-function-in-pytorch/57249287#57249287)

[Reference II](https://stackoverflow.com/questions/63582590/why-do-we-call-detach-before-calling-numpy-on-a-pytorch-tensor/63869655#63869655)

[Reference III](https://stackoverflow.com/questions/53975717/pytorch-connection-between-loss-backward-and-optimizer-step#53975741)

[PyTorch Official Tutorial](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)
</code></pre></div>
<ol>
<li>
<p><code>optimizer.zero_grad()</code> clears <code>x.grad</code> for every parameter <code>x</code> in the optimizer. It’s important to call this before <code>loss.backward()</code>, otherwise you’ll accumulate the gradients from multiple passes. </p>
<p>In other words, one should use them in the following order - <code>opt.zero_grad()</code>, <code>loss.backward()</code>, <code>opt.step()</code>.</p>
<p><code>zero_grad</code> clears old gradients from the last step (otherwise you’d just accumulate the gradients from all <code>loss.backward()</code> calls). <code>loss.backward()</code> computes the derivative of the loss w.r.t. the parameters (or anything requiring gradients) using backpropagation. <code>opt.step()</code> causes the optimizer to take a step based on the gradients of the parameters, for example, <code>opt.step()</code> allows you to proceed with gradient descent, the updating of parameters or rather, <strong>weights and biases</strong> of each neuron, for us to minimize the <strong>loss function</strong>. For example, the consequence of not using <code>zero_grad</code> is that after each <strong>batch</strong> in the <code>for</code> loop of the <code>DataLoader</code>, the <strong>gradients</strong> that we computed previously are not cleared, and will affect our gradient value of the next batch's weight tensor values, which will skew our <code>loss</code> and <code>optimizer</code> ability to minimize loss.</p>
<p><a href="https://stackoverflow.com/questions/44732217/why-do-we-need-to-explicitly-call-zero-grad">Reference I</a></p>
<p><a href="https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch">Reference II</a>.</p>
<p><a href="https://discuss.pytorch.org/t/what-step-backward-and-zero-grad-do/33301">Reference III</a></p>
</li>
<li>
<p><code>optimizer.step()</code> Without delving too deep into the internals of pytorch, I can offer a simplistic answer: Recall that when initializing <code>optimizer</code> you explicitly tell it what parameters (tensors) of the model it should be updating. The gradients are "stored" by the tensors themselves (they have a <a href="https://pytorch.org/docs/master/autograd.html#torch.Tensor.grad"><code>grad</code></a> and a <a href="https://pytorch.org/docs/master/autograd.html#torch.Tensor.requires_grad"><code>requires_grad</code></a> attributes) once you call <code>backward()</code> on the loss. After computing the gradients for all tensors in the model, calling <code>optimizer.step()</code> makes the optimizer iterate over all parameters (tensors) it is supposed to update and use their internally stored <code>grad</code> to update their values.</p>
</li>
</ol>
<h2 id="example-of-lossbackward-and-optimstep">Example of loss.backward and optim.step</h2>
<p>Perhaps this will clarify a little the connection between <code>loss.backward</code> and <code>optim.step</code> (although the other answers are to the point). 
<div class="highlight"><pre><span></span><code># Our &quot;model&quot;
x = torch.tensor([1., 2.], requires_grad=True)
y = 100*x

# Compute loss
loss = y.sum()

# Compute gradients of the parameters w.r.t. the loss
print(x.grad)     # None
loss.backward()      
print(x.grad)     # tensor([100., 100.])

# MOdify the parameters by subtracting the gradient
optim = torch.optim.SGD([x], lr=0.001)
print(x)        # tensor([1., 2.], requires_grad=True)
optim.step()
print(x)        # tensor([0.9000, 1.9000], requires_grad=True)
</code></pre></div></p>
<p><code>loss.backward()</code> sets the <code>grad</code> attribute of all tensors with <code>requires_grad=True</code> 
in the computational graph of which loss is the leaf (only <code>x</code> in this case).</p>
<p>Optimizer just iterates through the list of parameters (tensors) it received on initialization and everywhere where a tensor has <code>requires_grad=True</code>, it subtracts the value of its gradient stored in its <code>.grad</code> property (simply multiplied by the learning rate in case of SGD). It doesn't need to know with respect to what loss the gradients were computed it just wants to access that <code>.grad</code> property so it can do <code>x = x - lr * x.grad</code></p>
<h2 id="important-point-to-remember-for-zero_grad">Important point to remember for zero_grad</h2>
<p><strong>Note</strong> that if we were doing this in a train loop we would call <code>optim.zero_grad()</code> because in each train step we want to compute new gradients - we don't care about gradients from the previous batch. Not zeroing grads would lead to gradient accumulation across <strong>batches</strong> <strong>batches</strong> <strong>batches</strong> <strong>batches</strong> <strong>batches</strong> <strong>batches</strong> <strong>batches</strong> in the <code>for</code> loop of the <code>DataLoader</code>.</p>
<h2 id="understanding-lossbackward-and-computational-graph">Understanding loss.backward() and Computational Graph</h2>
<p>Backpropagation is based on the chain-rule for calculating derivatives. This means the gradients are computed step-by-step from tail to head and always passed back to the previous step ("previous" w.r.t. to the preceding forward pass).</p>
<p>For scalar output the process is initiated by assuming a gradient of <code>d (out1) / d (out1) = 1</code> to start the process. If you're calling <code>backward</code> on a (non-scalar) tensor though you need to provide the initial gradient since it is not unambiguous.</p>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Create a tensor and set requires_grad=True to track computation with it&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;tensor x is</span><span class="se">\n\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Do a tensor operation on x to get tensor y=x+2&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">+</span> <span class="mi">2</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;tensor y is</span><span class="se">\n\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;y was created as a result of an operation, so it has a grad_fn.&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The grad_fn of y is</span><span class="se">\n\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Do more operations on y to get tensor z=3y^2&#39;</span><span class="p">)</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span> <span class="o">*</span> <span class="mi">3</span>
<span class="n">output</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The new tensor z is</span><span class="se">\n\n</span><span class="si">{}</span><span class="s1">,</span><span class="se">\n\n</span><span class="s1">and the new output when taking the mean of z is </span><span class="se">\n\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">output</span><span class="p">))</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span><span class="o">*</span><span class="mi">80</span><span class="p">)</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Let</span><span class="se">\&#39;</span><span class="s1">s backprop now. Because output contains a single scalar, out.backward() is equivalent to out.backward(torch.tensor(1.)).&#39;</span><span class="p">)</span>

<span class="n">output</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>


<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Now x</span><span class="se">\&#39;</span><span class="s1">s gradient is</span><span class="se">\n\n</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">grad</span><span class="p">))</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Create a tensor and set requires_grad=True to track computation with it
--------------------------------------------------------------------------------
tensor x is

tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Do a tensor operation on x to get tensor y=x+2
--------------------------------------------------------------------------------
tensor y is

tensor([[3., 3.],
        [3., 3.]], grad_fn=&lt;AddBackward0&gt;)
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
y was created as a result of an operation, so it has a grad_fn.
--------------------------------------------------------------------------------
The grad_fn of y is

&lt;AddBackward0 object at 0x7f64691db390&gt;
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Do more operations on y to get tensor z=3y^2
The new tensor z is

tensor([[27., 27.],
        [27., 27.]], grad_fn=&lt;MulBackward0&gt;),

and the new output when taking the mean of z is

27.0
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
--------------------------------------------------------------------------------
Let&#39;s backprop now. Because output contains a single scalar, out.backward() is equivalent to out.backward(torch.tensor(1.)).
Now x&#39;s gradient is

tensor([[4.5000, 4.5000],
        [4.5000, 4.5000]])
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1">#     loss = criterion(y_preds, labels)</span>
<span class="c1">#     # print(&#39;Loss between the predictions made by the model and the ground truth labels computed using our loss function is&#39;, loss)</span>

<span class="c1">#     losses.update(loss.item(), batch_size)</span>
<span class="c1">#     # this is the loss value of the total loss of 4 predictions divided by batch size</span>
<span class="c1">#     # this is the loss value of the total loss of 4 predictions</span>
<span class="c1">#     # this is the count?</span>
<span class="c1">#     # this is the average loss.</span>

<span class="c1">#     # losses.value, losses.sum, losses.count, losses.avg</span>
<span class="c1">#     print(loss.grad_fn)</span>
<span class="c1">#     print(loss.grad_fn.next_functions[0][0])</span>
<span class="c1">#     print(loss.grad_fn.next_functions[0][0].next_functions[0][0])</span>
<span class="c1">#     #loss.backward()</span>
</code></pre></div>
<p>You should have got a matrix of <code>4.5</code>. Let’s call the <code>out</code>
<em>Tensor</em> “<span class="arithmatex">\(o\)</span>”.
We have that <span class="arithmatex">\(o = \frac{1}{4}\sum_i z_i\)</span> where
<span class="arithmatex">\(z_i = 3(x_i+2)^2\)</span> and <span class="arithmatex">\(z_i\bigr\rvert_{x_i=1} = 27\)</span>.
Therefore,
<span class="arithmatex">\(\frac{\partial o}{\partial x_i} = \frac{3}{2}(x_i+2)\)</span>, hence
<span class="arithmatex">\(\frac{\partial o}{\partial x_i}\bigr\rvert_{x_i=1} = \frac{9}{2} = 4.5\)</span>.</p>
<p>Mathematically, if you have a vector valued function <span class="arithmatex">\(\vec{y}=f(\vec{x})\)</span>,
then the gradient of <span class="arithmatex">\(\vec{y}\)</span> with respect to <span class="arithmatex">\(\vec{x}\)</span>
is a Jacobian matrix:</p>
<div class="arithmatex">\[\begin{align}J=\left(\begin{array}{ccc}
   \frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{1}}{\partial x_{n}}\\
   \vdots &amp; \ddots &amp; \vdots\\
   \frac{\partial y_{m}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}
   \end{array}\right)\end{align}\]</div>
<p>Generally speaking, <code>torch.autograd</code> is an engine for computing
vector-Jacobian product. That is, given any vector
<span class="arithmatex">\(v=\left(\begin{array}{cccc} v_{1} &amp; v_{2} &amp; \cdots &amp; v_{m}\end{array}\right)^{T}\)</span>,
compute the product <span class="arithmatex">\(v^{T}\cdot J\)</span>. If <span class="arithmatex">\(v\)</span> happens to be
the gradient of a scalar function <span class="arithmatex">\(l=g\left(\vec{y}\right)\)</span>,
that is,
<span class="arithmatex">\(v=\left(\begin{array}{ccc}\frac{\partial l}{\partial y_{1}} &amp; \cdots &amp; \frac{\partial l}{\partial y_{m}}\end{array}\right)^{T}\)</span>,
then by the chain rule, the vector-Jacobian product would be the
gradient of <span class="arithmatex">\(l\)</span> with respect to <span class="arithmatex">\(\vec{x}\)</span>:</p>
<div class="arithmatex">\[\begin{align}J^{T}\cdot v=\left(\begin{array}{ccc}
   \frac{\partial y_{1}}{\partial x_{1}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{1}}\\
   \vdots &amp; \ddots &amp; \vdots\\
   \frac{\partial y_{1}}{\partial x_{n}} &amp; \cdots &amp; \frac{\partial y_{m}}{\partial x_{n}}
   \end{array}\right)\left(\begin{array}{c}
   \frac{\partial l}{\partial y_{1}}\\
   \vdots\\
   \frac{\partial l}{\partial y_{m}}
   \end{array}\right)=\left(\begin{array}{c}
   \frac{\partial l}{\partial x_{1}}\\
   \vdots\\
   \frac{\partial l}{\partial x_{n}}
   \end{array}\right)\end{align}\]</div>
<p>(Note that <span class="arithmatex">\(v^{T}\cdot J\)</span> gives a row vector which can be
treated as a column vector by taking <span class="arithmatex">\(J^{T}\cdot v\)</span>.)</p>
<p>This characteristic of vector-Jacobian product makes it very
convenient to feed external gradients into a model that has
non-scalar output.</p>
<p>I think the most crucial point to understand here is the difference between a torch.tensor and np.ndarray:
While both objects are used to store n-dimensional matrices (aka "Tensors"), torch.tensors has an additional "layer" - which is storing the computational graph leading to the associated n-dimensional matrix.</p>
<p>So, if you are only interested in efficient and easy way to perform mathematical operations on matrices np.ndarray or torch.tensor can be used interchangeably.</p>
<p>However, torch.tensors are designed to be used in the context of gradient descent optimization, and therefore they hold not only a tensor with numeric values, but (and more importantly) the computational graph leading to these values. This computational graph is then used (using the chain rule of derivatives) to compute the derivative of the loss function w.r.t each of the independent variables used to compute the loss.</p>
<p>As mentioned before, np.ndarray object does not have this extra "computational graph" layer and therefore, when converting a torch.tensor to np.ndarray you must explicitly remove the computational graph of the tensor using the detach() command.</p>
<p>Computational Graph
From your comments it seems like this concept is a bit vague. I'll try and illustrate it with a simple example.
Consider a simple function of two (vector) variables, x and w:</p>
<div class="highlight"><pre><span></span><code><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">y</span> <span class="o">=</span> <span class="n">x</span> <span class="o">@</span> <span class="n">w</span>  <span class="c1"># inner-product of x and w</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">y</span> <span class="o">**</span> <span class="mi">2</span>  <span class="c1"># square the inner product</span>
<span class="n">z</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor(0.5170, grad_fn=&lt;PowBackward0&gt;)
</code></pre></div>
<p>If we are only interested in the value of z, we need not worry about any graphs, we simply moving forward from the inputs, x and w, to compute y and then z.</p>
<p>However, what would happen if we do not care so much about the value of z, but rather want to ask the question "what is w that minimizes z for a given x"?
To answer that question, we need to compute the derivative of z w.r.t w.
How can we do that?
Using the chain rule we know that dz/dw = dz/dy * dy/dw. That is, to compute the gradient of z w.r.t w we need to move backward from z back to w computing the gradient of the operation at each step as we trace back our steps from z to w. This "path" we trace back is the computational graph of z and it tells us how to compute the derivative of z w.r.t the inputs leading to z:</p>
<div class="highlight"><pre><span></span><code><span class="n">z</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>  <span class="c1"># ask pytorch to trace back the computation of z</span>
</code></pre></div>
<p>We can now inspect the gradient of z w.r.t w:</p>
<div class="highlight"><pre><span></span><code><span class="n">w</span><span class="o">.</span><span class="n">grad</span>  <span class="c1"># the resulting gradient of z w.r.t w</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([0.5055, 1.0019, 0.4770, 1.3650])
</code></pre></div>
<p>Note that this is exactly equals to</p>
<div class="highlight"><pre><span></span><code><span class="mi">2</span><span class="o">*</span><span class="n">y</span><span class="o">*</span><span class="n">x</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor([0.5055, 1.0019, 0.4770, 1.3650], grad_fn=&lt;MulBackward0&gt;)
</code></pre></div>
<p>since dz/dy = 2*y and dy/dw = x. Each tensor along the path stores its "contribution" to the computation:</p>
<div class="highlight"><pre><span></span><code><span class="n">z</span>
<span class="n">y</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>tensor(0.5170, grad_fn=&lt;PowBackward0&gt;)






tensor(0.7191, grad_fn=&lt;DotBackward&gt;)
</code></pre></div>
<p>As you can see, y and z stores not only the "forward" value of <x, w> or y**2 but also the computational graph -- the grad_fn that is needed to compute the derivatives (using the chain rule) when tracing back the gradients from z (output) to w (inputs).</p>
<p>These grad_fn are essential components to torch.tensors and without them one cannot compute derivatives of complicated functions. However, np.ndarrays do not have this capability at all and they do not have this information.</p>
<h1 id="23-nov">23 Nov</h1>
<p><strong>IMPORTANT, THIS IS ALL UNDER THE ASSUMPTION THAT <code>shuffle=False</code> in our <code>DataLoader</code> because if <code>shuffle=True</code>, then we will mess up the <code>train_labels = subset_train_df['label'].values</code> and the predictions since the predictions will be made on SHUFFLED IMAGES!!!!!!! But I managed to fixed it, see point 4 and 5.</strong></p>
<ol>
<li>
<p>Take note that <code>softmax_preds = torch.nn.Softmax(dim=1)(input=logits).to('cpu').detach().numpy()</code> may give you an error called <a href="https://stackoverflow.com/questions/55466298/pytorch-cant-call-numpy-on-variable-that-requires-grad-use-var-detach-num/56023903"><strong>Pytorch: Can't call numpy() on Variable that requires grad. Use var.detach().numpy() instead</strong></a>. Basically, when you are in training phase, where <code>require_grad=True</code>, you need to use <code>tensor.detach().numpy()</code> instead of <code>tensor.numpy()</code>. So it is only needed when you set <code>model.train()</code> mode, and for <code>model.eval()</code> mode I think no need.</p>
</li>
<li>
<p>Refer to point 1, I rewrote it in a more suggestive manner as such: note that when you call <code>torch.nn.Softmax(dim=1)(input=y_preds)</code> you are essentially calling <code>torch.nn.Softmax(dim=1)(input=y_preds).forward(input)</code>. Refer to <a href="https://pytorch.org/docs/stable/_modules/torch/nn/modules/activation.html#Softmax">Source Code</a>.</p>
</li>
<li>
<p>So after getting the <code>softmax</code> predict for the batch size of 4 here, we append them to a list called <code>train_preds=[]</code>, and then we go out of the for loop after each epoch, and then call <code>predictions = np.concatenate(train_preds)</code> whereby you concatenate all the predictions into a 2d-np-array. After which, we get <code>train_labels = subset_train_df['label'].values</code> where these are the groud-truth labels. Subsequently, we compare these ground truth with the predicted values using the function <code>score = get_score(train_labels, predictions.argmax(1))</code> where <code>predictions.argmax(1)</code> returns an array of <strong>indices</strong> which tells us in each prediction, which indice has the largest number. This nicely corresponds with our class because our class is from 0 - 4, note in the event if our class is 1-5, a quick fix is to make the class into 0-4.</p>
</li>
<li>
<p>Made changes to the <code>Dataset</code> because I want to return <code>image_id</code> as well, but he called it <code>p</code> so I renamed it to <code>img_id</code>.</p>
</li>
<li>
<p>Successfully solved the problem of <code>shuffle = True</code> in <code>DataLoader</code>. </p>
</li>
<li>
<p>Moving on to <code>valid_fn</code>, we need to know that we need to write <code>model.eval()</code> </p>
</li>
</ol>
<p><code>model.eval()</code> is a kind of switch for some specific layers/parts of the model that behave differently during training and inference (evaluating) time. For example, Dropouts Layers, BatchNorm Layers etc. You need to turn off them during model evaluation, and <code>.eval()</code> will do it for you. In addition, the common practice for evaluating/validation is using <code>torch.no_grad()</code> in pair with <code>model.eval()</code> to turn off gradients computation:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># evaluate model:</span>
<span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="o">...</span>
    <span class="n">out_data</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
    <span class="o">...</span>
</code></pre></div>
<p>BUT, don't forget to turn back to <code>training</code> mode after eval step:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># training step</span>
<span class="o">...</span>
<span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
<span class="o">...</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">import</span> <span class="nn">torchvision.transforms</span> <span class="k">as</span> <span class="nn">transforms</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">transform</span> <span class="o">=</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">(</span>
    <span class="p">[</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
     <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">((</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">),</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))])</span>

<span class="n">trainset</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">CIFAR10</span><span class="p">(</span><span class="n">root</span><span class="o">=</span><span class="s1">&#39;./data&#39;</span><span class="p">,</span> <span class="n">train</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                        <span class="n">download</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="n">transform</span><span class="p">)</span>
<span class="n">trainloader</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">trainset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                          <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz



HBox(children=(FloatProgress(value=1.0, bar_style=&#39;info&#39;, max=1.0), HTML(value=&#39;&#39;)))


Extracting ./data/cifar-10-python.tar.gz to ./data
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># testset = torchvision.datasets.CIFAR10(root=&#39;./data&#39;, train=False,</span>
<span class="c1">#                                        download=True, transform=transform)</span>
<span class="c1"># testloader = torch.utils.data.DataLoader(testset, batch_size=4,</span>
<span class="c1">#                                          shuffle=False, num_workers=2)</span>

<span class="c1"># classes = (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;,</span>
<span class="c1">#            &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>


<span class="k">class</span> <span class="nc">Net</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">Net</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">pool</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MaxPool2d</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">120</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">120</span><span class="p">,</span> <span class="mi">84</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">84</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv1</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pool</span><span class="p">(</span><span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">conv2</span><span class="p">(</span><span class="n">x</span><span class="p">)))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">16</span> <span class="o">*</span> <span class="mi">5</span> <span class="o">*</span> <span class="mi">5</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc1</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">fc2</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc3</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>


<span class="n">net</span> <span class="o">=</span> <span class="n">Net</span><span class="p">()</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
<span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">):</span>  <span class="c1"># loop over the dataset multiple times</span>

    <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">trainloader</span><span class="p">,</span> <span class="mi">0</span><span class="p">):</span>
        <span class="c1"># get the inputs; data is a list of [inputs, labels]</span>
        <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">data</span>

        <span class="c1"># zero the parameter gradients</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

        <span class="c1"># forward + backward + optimize</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">The logits are</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">outputs</span><span class="p">)</span>

        <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">The loss is</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n\n</span><span class="s1">The loss avg is</span><span class="se">\n</span><span class="s1">&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="c1"># so basically loss == loss.item()</span>
        <span class="k">break</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

        <span class="c1"># print statistics</span>
        <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">i</span> <span class="o">%</span> <span class="mi">2000</span> <span class="o">==</span> <span class="mi">1999</span><span class="p">:</span>    <span class="c1"># print every 2000 mini-batches</span>
            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;[</span><span class="si">%d</span><span class="s1">, </span><span class="si">%5d</span><span class="s1">] loss: </span><span class="si">%.3f</span><span class="s1">&#39;</span> <span class="o">%</span>
                  <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="mi">2000</span><span class="p">))</span>
            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Finished Training&#39;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>The logits are
 tensor([[ 0.0878,  0.0786, -0.0898,  0.0612, -0.0639, -0.0529, -0.0973,  0.0149,
         -0.1152, -0.0745],
        [ 0.0868,  0.0975, -0.0728,  0.0374, -0.0802, -0.0677, -0.1017,  0.0022,
         -0.0963, -0.0782],
        [ 0.0780,  0.0960, -0.0788,  0.0655, -0.0611, -0.0639, -0.0985,  0.0128,
         -0.1240, -0.0759],
        [ 0.0604,  0.0839, -0.0712,  0.0642, -0.0808, -0.0629, -0.0866,  0.0055,
         -0.1157, -0.0830]], grad_fn=&lt;AddmmBackward&gt;)


The loss is
 tensor(2.2469, grad_fn=&lt;NllLossBackward&gt;)


The loss avg is
 2.246931552886963


The logits are
 tensor([[ 0.0920,  0.0988, -0.0781,  0.0741, -0.0729, -0.0437, -0.0753,  0.0017,
         -0.0969, -0.0751],
        [ 0.0822,  0.0904, -0.0852,  0.0491, -0.0769, -0.0646, -0.0970,  0.0130,
         -0.1071, -0.0702],
        [ 0.0768,  0.0865, -0.0799,  0.0551, -0.0681, -0.0570, -0.0914,  0.0002,
         -0.1133, -0.0707],
        [ 0.0814,  0.0849, -0.0938,  0.0467, -0.0732, -0.0569, -0.0966,  0.0104,
         -0.1145, -0.0769]], grad_fn=&lt;AddmmBackward&gt;)


The loss is
 tensor(2.2669, grad_fn=&lt;NllLossBackward&gt;)


The loss avg is
 2.266934871673584
Finished Training
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">print_function</span><span class="p">,</span> <span class="n">division</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">lr_scheduler</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torchvision</span>
<span class="kn">from</span> <span class="nn">torchvision</span> <span class="kn">import</span> <span class="n">datasets</span><span class="p">,</span> <span class="n">models</span><span class="p">,</span> <span class="n">transforms</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">copy</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="c1"># Data augmentation and normalization for training</span>
<span class="c1"># Just normalization for validation</span>
<span class="n">data_transforms</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;train&#39;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomResizedCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">RandomHorizontalFlip</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]),</span>
    <span class="s1">&#39;val&#39;</span><span class="p">:</span> <span class="n">transforms</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">256</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">CenterCrop</span><span class="p">(</span><span class="mi">224</span><span class="p">),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">(),</span>
        <span class="n">transforms</span><span class="o">.</span><span class="n">Normalize</span><span class="p">([</span><span class="mf">0.485</span><span class="p">,</span> <span class="mf">0.456</span><span class="p">,</span> <span class="mf">0.406</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.229</span><span class="p">,</span> <span class="mf">0.224</span><span class="p">,</span> <span class="mf">0.225</span><span class="p">])</span>
    <span class="p">]),</span>
<span class="p">}</span>

<span class="n">data_dir</span> <span class="o">=</span> <span class="s1">&#39;./data/hymenoptera_data&#39;</span>
<span class="n">image_datasets</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">datasets</span><span class="o">.</span><span class="n">ImageFolder</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span>
                                          <span class="n">data_transforms</span><span class="p">[</span><span class="n">x</span><span class="p">])</span>
                  <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dataloaders</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">utils</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">],</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
                                             <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
              <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">dataset_sizes</span> <span class="o">=</span> <span class="p">{</span><span class="n">x</span><span class="p">:</span> <span class="nb">len</span><span class="p">(</span><span class="n">image_datasets</span><span class="p">[</span><span class="n">x</span><span class="p">])</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]}</span>
<span class="n">class_names</span> <span class="o">=</span> <span class="n">image_datasets</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">classes</span>

<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda:0&quot;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>---------------------------------------------------------------------------

FileNotFoundError                         Traceback (most recent call last)

&lt;ipython-input-24-1f4b70a4f27c&gt; in &lt;module&gt;
     19 image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
     20                                           data_transforms[x])
---&gt; 21                   for x in [&#39;train&#39;, &#39;val&#39;]}
     22 dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,
     23                                              shuffle=True, num_workers=4)


&lt;ipython-input-24-1f4b70a4f27c&gt; in &lt;dictcomp&gt;(.0)
     19 image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),
     20                                           data_transforms[x])
---&gt; 21                   for x in [&#39;train&#39;, &#39;val&#39;]}
     22 dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=4,
     23                                              shuffle=True, num_workers=4)


/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py in __init__(self, root, transform, target_transform, loader, is_valid_file)
    227                                           transform=transform,
    228                                           target_transform=target_transform,
--&gt; 229                                           is_valid_file=is_valid_file)
    230         self.imgs = self.samples


/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py in __init__(self, root, loader, extensions, transform, target_transform, is_valid_file)
    106         super(DatasetFolder, self).__init__(root, transform=transform,
    107                                             target_transform=target_transform)
--&gt; 108         classes, class_to_idx = self._find_classes(self.root)
    109         samples = make_dataset(self.root, class_to_idx, extensions, is_valid_file)
    110         if len(samples) == 0:


/opt/conda/lib/python3.7/site-packages/torchvision/datasets/folder.py in _find_classes(self, dir)
    135             No class is a subdirectory of another.
    136         &quot;&quot;&quot;
--&gt; 137         classes = [d.name for d in os.scandir(dir) if d.is_dir()]
    138         classes.sort()
    139         class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}


FileNotFoundError: [Errno 2] No such file or directory: &#39;./data/hymenoptera_data/train&#39;
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;The number of images in the training set is&#39;</span><span class="p">,</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">])</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

&lt;ipython-input-25-281ff82a30a3&gt; in &lt;module&gt;
----&gt; 1 print(&#39;The number of images in the training set is&#39;, dataset_sizes[&#39;train&#39;])


NameError: name &#39;dataset_sizes&#39; is not defined
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">train_model</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">scheduler</span><span class="p">,</span> <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">):</span>
    <span class="n">since</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

    <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>
    <span class="n">best_acc</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Epoch </span><span class="si">{}</span><span class="s1">/</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">,</span> <span class="n">num_epochs</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;-&#39;</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>

        <span class="c1"># Each epoch has a training and validation phase</span>
        <span class="k">for</span> <span class="n">phase</span> <span class="ow">in</span> <span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;val&#39;</span><span class="p">]:</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>  <span class="c1"># Set model to training mode</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">model</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>   <span class="c1"># Set model to evaluate mode</span>

            <span class="n">running_loss</span> <span class="o">=</span> <span class="mf">0.0</span>
            <span class="n">running_corrects</span> <span class="o">=</span> <span class="mi">0</span>

            <span class="c1"># Iterate over data.</span>
            <span class="k">for</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="ow">in</span> <span class="n">dataloaders</span><span class="p">[</span><span class="n">phase</span><span class="p">]:</span>
                <span class="n">inputs</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
                <span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

                <span class="c1"># zero the parameter gradients</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>

                <span class="c1"># forward</span>
                <span class="c1"># track history if only in train</span>
                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">set_grad_enabled</span><span class="p">(</span><span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">):</span>
                    <span class="n">outputs</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
                    <span class="n">_</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">labels</span><span class="p">)</span>

                    <span class="c1"># backward + optimize only if in training phase</span>
                    <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
                        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

                <span class="c1"># statistics</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span>
                <span class="n">running_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">*</span> <span class="n">inputs</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
                <span class="n">running_corrects</span> <span class="o">+=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">preds</span> <span class="o">==</span> <span class="n">labels</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;train&#39;</span><span class="p">:</span>
                <span class="n">scheduler</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>

            <span class="n">epoch_loss</span> <span class="o">=</span> <span class="n">running_loss</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>
            <span class="n">epoch_acc</span> <span class="o">=</span> <span class="n">running_corrects</span><span class="o">.</span><span class="n">double</span><span class="p">()</span> <span class="o">/</span> <span class="n">dataset_sizes</span><span class="p">[</span><span class="n">phase</span><span class="p">]</span>

            <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">{}</span><span class="s1"> Loss: </span><span class="si">{:.4f}</span><span class="s1"> Acc: </span><span class="si">{:.4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
                <span class="n">phase</span><span class="p">,</span> <span class="n">epoch_loss</span><span class="p">,</span> <span class="n">epoch_acc</span><span class="p">))</span>

            <span class="c1"># deep copy the model</span>
            <span class="k">if</span> <span class="n">phase</span> <span class="o">==</span> <span class="s1">&#39;val&#39;</span> <span class="ow">and</span> <span class="n">epoch_acc</span> <span class="o">&gt;</span> <span class="n">best_acc</span><span class="p">:</span>
                <span class="n">best_acc</span> <span class="o">=</span> <span class="n">epoch_acc</span>
                <span class="n">best_model_wts</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">state_dict</span><span class="p">())</span>

        <span class="nb">print</span><span class="p">()</span>

    <span class="n">time_elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">since</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Training complete in </span><span class="si">{:.0f}</span><span class="s1">m </span><span class="si">{:.0f}</span><span class="s1">s&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span>
        <span class="n">time_elapsed</span> <span class="o">//</span> <span class="mi">60</span><span class="p">,</span> <span class="n">time_elapsed</span> <span class="o">%</span> <span class="mi">60</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Best val Acc: </span><span class="si">{:4f}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">best_acc</span><span class="p">))</span>

    <span class="c1"># load best model weights</span>
    <span class="n">model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">best_model_wts</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">model_ft</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
<span class="c1"># Here the size of each output sample is set to 2.</span>
<span class="c1"># Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).</span>
<span class="n">model_ft</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="n">model_ft</span> <span class="o">=</span> <span class="n">model_ft</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>

<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>

<span class="c1"># Observe that all parameters are being optimized</span>
<span class="n">optimizer_ft</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">model_ft</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>

<span class="c1"># Decay LR by a factor of 0.1 every 7 epochs</span>
<span class="n">exp_lr_scheduler</span> <span class="o">=</span> <span class="n">lr_scheduler</span><span class="o">.</span><span class="n">StepLR</span><span class="p">(</span><span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">step_size</span><span class="o">=</span><span class="mi">7</span><span class="p">,</span> <span class="n">gamma</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Downloading: &quot;https://download.pytorch.org/models/resnet18-5c106cde.pth&quot; to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth



HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value=&#39;&#39;)))
</code></pre></div>
<div class="highlight"><pre><span></span><code><span class="n">model_ft</span> <span class="o">=</span> <span class="n">train_model</span><span class="p">(</span><span class="n">model_ft</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">optimizer_ft</span><span class="p">,</span> <span class="n">exp_lr_scheduler</span><span class="p">,</span>
                       <span class="n">num_epochs</span><span class="o">=</span><span class="mi">25</span><span class="p">)</span>
</code></pre></div>
<div class="highlight"><pre><span></span><code>Epoch 0/24
----------



---------------------------------------------------------------------------

NameError                                 Traceback (most recent call last)

&lt;ipython-input-28-cc88ea5f8bd3&gt; in &lt;module&gt;
      1 model_ft = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler,
----&gt; 2                        num_epochs=25)


&lt;ipython-input-26-9af9c454ae56&gt; in train_model(model, criterion, optimizer, scheduler, num_epochs)
     20 
     21             # Iterate over data.
---&gt; 22             for inputs, labels in dataloaders[phase]:
     23                 inputs = inputs.to(device)
     24                 labels = labels.to(device)


NameError: name &#39;dataloaders&#39; is not defined
</code></pre></div>
<div class="highlight"><pre><span></span><code>
</code></pre></div>

              
            </article>
          </div>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2021-2022 Gao Hongnan
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
      
      
    
    <a href="https://sg.linkedin.com/in/reighnss" target="_blank" rel="noopener" title="sg.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
    
    
    <a href="https://github.com/gao-hongnan" target="_blank" rel="noopener" title="gaohn" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.1.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    <script id="__config" type="application/json">{"base": "../../..", "features": ["content.code.annotate"], "search": "../../../assets/javascripts/workers/search.2a1c317c.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.ed9748b7.min.js"></script>
      
        <script src="../../../javascript/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>