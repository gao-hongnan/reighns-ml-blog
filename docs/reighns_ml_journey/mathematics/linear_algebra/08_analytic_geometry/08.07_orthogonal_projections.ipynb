{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a90a907f-309d-4211-8ff9-4437ac1e5a7e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\F}{\\mathbb{F}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\a}{\\mathbf{a}}\n",
    "\\newcommand{\\b}{\\mathbf{b}}\n",
    "\\newcommand{\\c}{\\mathbf{c}}\n",
    "\\newcommand{\\r}{\\mathbf{r}}\n",
    "\\newcommand{\\u}{\\mathbf{u}}\n",
    "\\newcommand{\\w}{\\mathbf{w}}\n",
    "\\newcommand{\\v}{\\mathbf{v}}\n",
    "\\newcommand{\\x}{\\mathbf{x}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\z}{\\mathbf{z}}\n",
    "\\newcommand{\\0}{\\mathbf{0}}\n",
    "\\newcommand{\\1}{\\mathbf{1}}\n",
    "\\newcommand{\\A}{\\mathbf{A}}\n",
    "\\newcommand{\\B}{\\mathbf{B}}\n",
    "\\newcommand{\\C}{\\mathbf{C}}\n",
    "\\newcommand{\\P}{\\mathbf{P}}\n",
    "\\newcommand{\\U}{\\mathbf{U}}\n",
    "\\newcommand{\\V}{\\mathbf{V}}\n",
    "\\newcommand{\\rank}{\\textbf{rank}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89745bd2-d10f-48d9-956a-562562eff205",
   "metadata": {},
   "source": [
    "## Orthogonal Projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2fe6b62-a187-4d6e-ae7d-993577b6cfd3",
   "metadata": {},
   "source": [
    "### Algebraic Definition (Orthogonal Projections)\n",
    "\n",
    "Let $\\V$ be the ambient vector space. A **projection** on a vector subspace $\\U \\subseteq \\V$ is a linear mapping $\\pi: \\V \\to \\U$ such that $\\pi^2 = \\pi$. If $\\V$ is an **inner product space**, then $\\pi$ can be called an **orthogonal projection**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a32318e-9e80-4733-85cd-7e4664667a08",
   "metadata": {},
   "source": [
    "### Definition (Projection Matrix)\n",
    "\n",
    "We can verify that $\\pi$ is indeed a **linear transformaton**. Recall that **linear transformation** can be expressed by **transformation matrices**. Thus we define **projection matrices** to be $\\P_\\pi$ such that $\\P_\\pi^2 = \\P$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173ce45d-d563-4dfe-b8c4-cc9ce26668aa",
   "metadata": {},
   "source": [
    "### Derivation of Projection onto a Line $U$[^mml_Derivation of Projection onto a Line]\n",
    "\n",
    "\n",
    "#### Projection onto the x-axis\n",
    "\n",
    "**In page 84, the author said if the vector $\\x$ is of unit length, then projecting on the horizontal axis yields a projection vector to be $\\cos(\\omega)$**. This may be confusing at first if you derive it using formula since we see that\n",
    "\n",
    "$$\n",
    "\\pi_{U}(\\x) = \\dfrac{\\b^\\top\\x}{|| \\b ||^2}\\b = \\dfrac{||\\b|| ||\\x|| \\cos(\\omega)}{||\\b||^2} \\b = \\cos(\\omega) ||\\x|| \\dfrac{\\b}{||\\b||} \\overset{||\\x|| = 1}{=} \\cos(\\omega) \\dfrac{\\b}{||\\b||} \n",
    "$$\n",
    "\n",
    "where did the unit vector $\\hat{\\b} = \\frac{\\b}{||\\b||}$ go? The confusion lies in two folds, one is author mentioned that this is only true when projecting onto the horizontal axis (x-axis), and secondly, the abuse of notation of vector where I misunderstood $\\cos(\\omega)$ as the \"projection vector\". In fact, if we are projecting on the horizontal axis, then the basis vector $\\b$ is just $\\begin{bmatrix}1 \\\\0 \\end{bmatrix}$ and we have the projection vector to be actually \n",
    "\n",
    "$$\n",
    "\\pi_{U}(\\x) = \\cos(\\omega) \\dfrac{\\b}{||\\b||} = \\cos(\\omega) \\begin{bmatrix}1 \\\\0 \\end{bmatrix} = \\begin{bmatrix}\\cos(\\omega) \\\\0 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "and so when mentioned loosely, we can say that the projection vector is just $\\cos(\\omega)$.\n",
    "\n",
    "[^mml_Derivation of Projection onto a Line]: Derivation of Projection onto a Line: **Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 82-85)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50c08a2-9b82-490c-b98a-0c3c3ccb32bc",
   "metadata": {},
   "source": [
    "### Derivation of Projection onto a General Subspace $U$[^mml_Derivation of Projection onto a General Subspace][^khan_academy_Derivation of Projection onto a General Subspace]\n",
    "\n",
    "The derivation using orthogonal complement provides a more intuitive understanding!\n",
    "\n",
    "[^mml_Derivation of Projection onto a General Subspace]: Derivation of Projection onto a a General Subspace: **Cambridge University Press: Mathematics for Machine Learning, 2020. (pp. 85-88)**\n",
    "[^khan_academy_Derivation of Projection onto a General Subspace]: Derivation of Projection onto a General Subspace: **https://www.khanacademy.org/math/linear-algebra/alternate-bases/orthogonal-projections/v/lin-alg-a-projection-onto-a-subspace-is-a-linear-transforma**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
