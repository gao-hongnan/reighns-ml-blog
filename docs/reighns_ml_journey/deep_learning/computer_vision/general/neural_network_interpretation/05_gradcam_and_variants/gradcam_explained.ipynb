{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a97bf2fd-b7da-41fc-93c6-ffcf5e47f513",
   "metadata": {},
   "source": [
    "$$\n",
    "\\newcommand{\\F}{\\mathbb{F}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\A}{\\mathbf{A}}\n",
    "\\newcommand{\\L}{\\mathbf{L}}\n",
    "\\newcommand{\\X}{\\mathbf{X}}\n",
    "\\newcommand{\\y}{\\mathbf{y}}\n",
    "\\newcommand{\\v}{\\mathbf{v}}\n",
    "\\newcommand{\\a}{\\mathbf{a}}\n",
    "\\newcommand{\\b}{\\mathbf{b}}\n",
    "\\newcommand{\\c}{\\mathbf{c}}\n",
    "\\newcommand{\\w}{\\mathbf{w}}\n",
    "\\newcommand{\\u}{\\mathbf{u}}\n",
    "\\newcommand{\\0}{\\mathbf{0}}\n",
    "\\newcommand{\\1}{\\mathbf{1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d26f186-47e8-4da6-a300-c49b2314de8b",
   "metadata": {},
   "source": [
    "## Terminologies\n",
    "\n",
    "### Feature Maps\n",
    "\n",
    "[Feature Maps](https://stats.stackexchange.com/questions/291820/what-is-the-definition-of-a-feature-map-aka-activation-map-in-a-convolutio) has an [intuitive interpretation](https://www.quora.com/What-is-meant-by-feature-maps-in-convolutional-neural-networks). Imagine a 32 by 32 image, consider that a convolutional layer applied on the input and we assume only 1 single filter, then only 1 single feature map is obtained, this feature map's corresponding filter can be [sobel's filter](https://en.wikipedia.org/wiki/Sobel_operator) where it detects edges. Then assume this single filter is 5 by 5, then after applying to the 32 by 32 image, the resulting output is 28 by 28, although \"downsampled\", this feature map should still capture valueble spatial information of the 32 by 32 image, and in this case, all edges of the input image (say a cat) will be shown in the feature map.\n",
    "\n",
    "### Global Average Pooling (GAP)\n",
    "\n",
    "One might wonder the step where the paper applied **GAP** over each feature map $\\A_k$. One can refer to [here](https://machinelearningmastery.com/pooling-layers-for-convolutional-neural-networks/) to understand the intuition here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bf51ec-29c4-4a80-b815-934b831d5668",
   "metadata": {},
   "source": [
    "## The Intuition\n",
    "\n",
    "> This part is referenced from **Interpretable Machine Learning by Christoph Molnar**. He started off with an intuitive description of Grad-CAM.\n",
    "\n",
    "- **High level idea:** Grad-CAM is to understand at which parts of an image a convolutional layer \"looks\" for a certain classification.\n",
    "- As a reminder, the first convolutional layer of a CNN takes as input the images and outputs feature maps that encode learned features (see the chapter on [Learned Features](#cnn-features)).\n",
    "    - The higher-level convolutional layers do the same, but take as input the feature maps of the previous convolutional layers.\n",
    "- To understand how the CNN makes decisions, Grad-CAM analyzes which regions are activated in the feature maps of the last convolutional layers.\n",
    "- There are $k$ feature maps in the last convolutional layer, and I will call them $\\A^1, \\A^2, \\ldots, \\A^k$.\n",
    "- How can we \"see\" from the feature maps how the convolutional neural network has made a certain classification?\n",
    "    - In the first approach, we could simply visualize the raw values of each feature map, average over the feature maps and overlay this over our image. This is the method of visualization feature map activations.\n",
    "    - This would not be helpful since the feature maps encode information for **all classes**, but we are interested in a particular class.\n",
    "    - Grad-CAM has to decide how important each of the k feature map was to our class c that we are interested in.\n",
    "- We have to weight each pixel of each feature map with the gradient before we average over the feature maps.\n",
    "- This gives us a heatmap which highlights regions that positively or negatively affect the class of interest.\n",
    "- This heatmap is send through the `ReLU` function, which is a fancy way of saying that we set all negative values to zero.\n",
    "    - Grad-CAM removes all negative values by using a ReLU function, with the argument that we are only interested in the parts that contribute to the selected class c and not to other classes.\n",
    "- The word pixel might be misleading here as the feature map is smaller than the image (because of the pooling units) but is mapped back to the original image.\n",
    "- We then scale the Grad-CAM map to the interval [0,1] for visualization purposes and overlay it over the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8494295-cd76-434a-adbe-f039f4768024",
   "metadata": {},
   "source": [
    "## The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047489d-a757-4bf4-8d88-de98dfd6fe9c",
   "metadata": {},
   "source": [
    "### Notation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896af9a1-140f-4d48-ab40-09e48adb5c0c",
   "metadata": {},
   "source": [
    "- Input image: $\\X$\n",
    "\n",
    "- **Feature Maps** of the last convolutional layer in a CNN is denoted as:\n",
    "\n",
    "    $$\\A_1, \\A_2, \\ldots, \\A_k$$\n",
    "    \n",
    "    The $k$ is an arbitrary number for the number of feature maps.\n",
    "\n",
    "- The **Feature Logits** of a particular **class $c$** is denoted as:\n",
    "    \n",
    "    $$\\y^{c}$$\n",
    "    \n",
    "    In other words, in **ImageNet**, the elephant class is indexed $386$, and is denoted $\\y^{386}$. This is also the raw feature logits output of the last convolutional layer.\n",
    "    \n",
    "- The **gradient of the fully-connected logits for class $c$, $\\y^{c}$ (before the softmax), with respect to feature map activations $\\A_k$ of a convolutional layer**:\n",
    "    \n",
    "    $$\\dfrac{d\\y^{c}}{d\\A^{k}}$$\n",
    "    \n",
    "- It follows that the **gradient of the fully-connected for each class $c$, $\\y^{c}$, with respect to each pixel on the feature map activations $\\A_k$ is denoted as**:\n",
    "    \n",
    "    $$\\dfrac{d\\y^{c}}{d\\A^{k}_{ij}}$$\n",
    "    \n",
    "- Denote the `ReLU` function as:\n",
    "    \n",
    "    $$\\textbf{ReLU}$$\n",
    "\n",
    "- The final heatmap, also called the localization map of Grad-CAM is denoted as:\n",
    "\n",
    "    $$\\L^{c}_{Grad-CAM} \\in \\R^{w \\times h}$$\n",
    "    \n",
    "    where $w$ and $h$ is the width and height of the final output localization map.\n",
    "    \n",
    "    and is equals to\n",
    "    \n",
    "    $$\\L^{c}_{Grad-CAM} \\in \\R^{w \\times h} = \\textbf{ReLU} \\left(\\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f404c3b8-20b4-4c49-8816-9c9c485cfaf8",
   "metadata": {},
   "source": [
    "### The Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d54f3c-3c55-4635-8c2f-8fd5e0bfd75b",
   "metadata": {},
   "source": [
    "<!-- Pseudo code-->\n",
    "Let us look at the recipe for Grad-CAM.\n",
    "Our goal is to find the localization map, which is defined as:\n",
    "\n",
    "$$L^c_{Grad-CAM} \\in \\mathbb{R}^{u\\times v} = \\underbrace{ReLU}_{\\text{Pick positive values}}\\left(\\sum_{k} \\alpha_k^c A^k\\right)$$\n",
    "\n",
    "\n",
    "Here, u is the width, v the height of the explanation and c the class of interest.\n",
    "\n",
    "1. Forward-propagate the input image through the convolutional neural network.\n",
    "1. Obtain the raw score for the class of interest, meaning the activation of the neuron before the softmax layer.\n",
    "1. Set all other class activations to zero.\n",
    "1. Back-propagate the gradient of the class of interest to the last convolutional layer before the fully connected layers: $\\frac{\\delta{}y^c}{\\delta{}A^k}$.\n",
    "1. Weight each feature map \"pixel\" by the gradient for the class. Indices i and j refer to the width and height dimensions:\n",
    "   $$\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}$$\n",
    "This means that the gradients are globally pooled.\n",
    "1. Calculate an average of the feature maps, weighted per pixel by the gradient.\n",
    "1. Apply ReLU to the averaged feature map.\n",
    "1. For visualization: Scale values to the interval between 0 and 1. Upscale the image and overlay it over the original image.\n",
    "1. Additional step for Guided Grad-CAM: Multiply heatmap with guided backpropagation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c7e9e6-17c3-4430-b490-4b564311c22a",
   "metadata": {},
   "source": [
    "#### Step 1: Forward-propagate the input image through the convolutional neural network\n",
    "\n",
    "This step just takes in **one single image** $\\X$ and perform a forward pass through the CNN."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8108e92-fef2-41e1-9d22-8591048f2d68",
   "metadata": {},
   "source": [
    "- `last_conv_layer_output`\n",
    "    - Shape: $2 \\times 2 \\times 3$ with 3 filters of 2 by 2 shape.\n",
    "    - Note this is just $\\A^1, \\A^2, \\A^3$ where each $\\A^k \\in \\R^{2 \\times 2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e4247c-7e1e-4b9e-9ac5-1e948b00b6e5",
   "metadata": {},
   "source": [
    "- `y_logits`\n",
    "    - Shape: $1 \\times 1000$ since there are 1000 classes in ImageNet.\n",
    "    - Note that this is our $\\y$. If we are interested in the elephant class at index 386, then we denote it as $\\y^{c} = \\y^{386}$.\n",
    "    - Thus, $\\y \\in \\R^{1 \\times 1000}$ but $\\y^{c} \\in \\R^{1 \\times 1}$.\n",
    "    - Note carefully this is the logits output of **all the layers** of the CNN, and is just right before the **softmax** where we transform the logits to probabilities.\n",
    "    - We can imagine that among these 1000 logits, the highest number means the model thinks that this index is the most probable class.\n",
    "    - Theoretically speaking, there is no difference in differentiation of the logits wrt to the feature maps versus the softmax probs wrt to the feature maps. This is because **softmax is monotonic**, and the pre-softmax logits output will tell us already which class is most probable, and so will the softmax. So there should not be any confusion here on why we did not differentiate softmax probs wrt to the feature maps instead since the ranking is preserved in the sense that values in logits the highest is the most probable when transformed by softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0bb186-932e-4b97-8981-e64c7310668d",
   "metadata": {},
   "source": [
    "- `target_category`\n",
    "    - This is an optional argument in the function. \n",
    "    - If `None`, we will automatically assign it to the highest logit's index.\n",
    "    - In this example, the highest logit in $\\y$ is at index 386 with a value of $23.632$, corresponding to the target class of elephant.\n",
    "    - If specified, then the $\\y^{c}$ will change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42de00-1dbf-4994-8d75-58f74ac84857",
   "metadata": {},
   "source": [
    "- `target_category_logits`\n",
    "    - Once our `target_category` is defined, we will just slice `y_logits[:, target_category]` to get the logit value of that particular class.\n",
    "    - This variable is just $\\y^{c}$ if you look carefully."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c3a13b-d768-42c8-9e6f-b80ae417ab95",
   "metadata": {},
   "source": [
    "- `grads = tape.gradient(target_category_logits, last_conv_layer_output)`\n",
    "    - This is the gradient of the output neuron (top predicted or chosen) with regard to the output feature map of the last conv layer.\n",
    "    - This has shape $2 \\times 2 \\times 3$ in our simple example. In the python example, the shape at this moment has an additional axis like $1 \\times 2 \\times 2 \\times 3$ which we will eventually squeeze it anyways.\n",
    "    - Notice it has the same shape as `last_conv_layer_output` aka the feature maps.\n",
    "    - In other words, this variable has 3 feature maps stacked together and can be visualized as:     \n",
    "    \n",
    "        $$\\begin{bmatrix} \\dfrac{d\\y^{c}}{d\\A^{1}} & \\dfrac{d\\y^{c}}{d\\A^{2}} & \\dfrac{d\\y^{c}}{d\\A^{3}} \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff3457f-46c5-4ed2-9dc5-a8559f2e10d6",
   "metadata": {},
   "source": [
    "- `pooled_grads`\n",
    "    - Shape: $3 \\times 1$\n",
    "    - This is a vector where each entry is the mean intensity of the gradient over a specific feature map channel.\n",
    "    - In other words, in `grads[0]` we have $\\frac{d\\y^c}{d\\A^1}$ which is of shape $2 \\times 2$. What we do not is **Global Average Pooling** on these gradients where we just take the average of all available pixels in this $2 \\times 2$ gradient map for feature map 1. You can find more intuition of GAP above, but in general this is similar logic to how you perform GAP on the output of the feature logits from the last conv layer.\n",
    "    \n",
    "        $$\\alpha_k^c = \\overbrace{\\frac{1}{Z}\\sum_{i}\\sum_{j}}^{\\text{global average pooling}} \\underbrace{\\frac{\\delta y^c}{\\delta A_{ij}^k}}_{\\text{gradients via backprop}}$$\n",
    "        \n",
    "        where $Z$ is the total number of pixels in this gradient map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac12ac-b46a-4396-872f-1f81de0c901b",
   "metadata": {},
   "source": [
    "- `heatmap`\n",
    "    - Shape: $2 \\times 2$ which is also the filter size and also the feature map size.\n",
    "    - This is the weighted sum of all feature maps $\\A^1, \\A^2, \\A^3$ and is\n",
    "        \n",
    "        $$\\textbf{Localized_Map} = \\left(\\sum_{k} \\alpha_k^c A^k\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bd5cb7-da9e-49ac-844e-4d58aad49b76",
   "metadata": {},
   "source": [
    "### The big picture\n",
    "\n",
    "The big picture is when you \"reduce\" the 3 feature maps into 1 single new \"feature map\" (localization map) by way of a linear sum where each feature map $\\A^k$ is multiplied by the global average pooled gradients $\\alpha_k^c$. In the example on my drawings, it can be seen that feature maps $\\A^1$ and $\\A^2$ are more important for the model to distinguish the elephant class than that of $\\A^3$. \n",
    "\n",
    "By design, I made $\\A^3$ in itself already look different in terms of values from $\\A^1$ and $\\A^2$ on the get go. But at this point in time, even though we know the values in feature map $\\A^3$ are vastly different, we cannot say for sure whether $\\A^3$ in itself contributed to the prediction of our class elephant or not. It could also be the case that $\\A^1$ and $\\A^2$ are bonkers. Thus, the concept of taking the **gradient** of the class $\\y^c$ with respect to each of these feature maps $\\A^k$ becomes increasingly important as now we have a mathematical way to assign some importance to each of these feature maps.\n",
    "\n",
    "Now to even further bring out the intuition, imagine the 3 feature maps for the input image elephant as follows:\n",
    "\n",
    "- Feature map $\\A^1$ corresponds to Sobel Filter where it detect edges in particular their **trunk** of the **elephants**.\n",
    "- Feature map $\\A^2$ corresponds to Another Filter where it detects the **ear** of the **elephants**.\n",
    "- Feature map $\\A^3$ corresponds to a Background Filter where it detect the background and in particular the grass patch under the **elephants**.\n",
    "\n",
    "---\n",
    "\n",
    "Now this is apparent why $\\A^3$ is vastly different in terms of values since it is actually representing the background and grass. We know that grass is a non-factor in determining an elephant since the african grass field can hold many other animals as well. We really do not want the model to assign important to the grass, if any at all. \n",
    "\n",
    "We can then compute the gradient of $\\y^c$ wrt each feature map and we can intuitively understand it as (see my diagrams):\n",
    "\n",
    "- Gradient map $\\frac{d\\y^{386}}{d\\A^1}$ has values $[2, 3, 4, 2]$ \n",
    "    - These values are the gradients of feature map $\\A^1$ at a pixel level. We may find it difficult to comprehend these gradients and we want a quick summary of how feature map $\\A^1$ changes our model's decision for $\\y^{386}$. Thus we use GAP.\n",
    "    - and when we perform GAP on them, we have $\\alpha_{1}^{386} = 2.75$. \n",
    "    - This value roughly translates to a pertubation of $2.75$ in feature map $\\A^1$ will result in a unit change in our class $\\y^{386}$.\n",
    "- Gradient map $\\frac{d\\y^{386}}{d\\A^2}$ has values $[3, 5, 6, 3]$ and when we perform GAP on them, we have $4.25$. \n",
    "    - The same logic applies.\n",
    "- Gradient map $\\frac{d\\y^{386}}{d\\A^3}$ has values $[0.1, -0.1, 0.2, 0.2]$ and when we perform GAP on them, we have $0.1$.\n",
    "    - The same logic applies and we see that the gradient is small here and hence we can deduce that this feature map is not very important.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b256896-0e73-4ec8-863f-b996798da261",
   "metadata": {},
   "source": [
    "Ultimately however, we want to know how the change in **all feature maps $\\A^k$** affects our final decision. This is where we perform a linear sum of $\\left(\\sum_{k} \\alpha_k^c A^k\\right)$ of all feature maps with the weight coefficient being their global average pooled gradient map. Just like our good old linear regression model, the intuition is the same as in $y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ...$. The coefficients (the gradient values of $2.75, 4.25, 0.1$ decides which feature map are important and gets \"activated and highlighted\").\n",
    "\n",
    "- We get the weighted sum heatmap to be the shape $(2, 2)$ of values $[8.925, -2.025, 16.125, 2.6]$. Now this is a very small map and is likely not going to happen in real life. More often the map at this stage is of size $(10, 10)$ and beyond. Imagine once more how $\\A^3$ played almost no role.\n",
    "---\n",
    "\n",
    "Lastly, an elementwise `ReLU` operation is applied to the heatmap to get $[8,925, 0, 16.125, 2.6]$ and from the paper: We apply a `ReLU` to the linear combination of maps because we are only interested in the features that have a positive influence on the class of interest, i.e. pixels whose intensity should be increased in order to increase `y^{c}`. Intuitively, the idea is that negative values contribute to other classes and we should not really care about it.\n",
    "\n",
    "We can scale back the heatmap to overlay on the original image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cea817-3181-4724-ba5e-fdfef8076094",
   "metadata": {},
   "source": [
    "From [here](https://medium.com/@stepanulyanin/implementing-grad-cam-in-pytorch-ea0937c31e82), author said:\n",
    "\n",
    "> Another potential question that can arise is why wouldn’t we just compute the gradient of the class logit with respect to the input image. Remember that a convolutional neural network works as a feature extractor and deeper layers of the network operate in increasingly abstract spaces. We want to see which of the features actually influenced the model’s choice of the class rather than just individual image pixels. That is why it is crucial to take the activation maps of deeper convolutional layers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
